<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Benchmarking CookBook • gstest</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Benchmarking CookBook">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">gstest</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">3.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/gstest.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/benchmarking-cookbook.html">Benchmarking CookBook</a></li>
    <li><a class="dropdown-item" href="../articles/benchmarking-demo-script.html">A Beginner's Benchmarking Demo Script</a></li>
    <li><a class="dropdown-item" href="../articles/osqp-settings-sequence-dataframe.html">OSQP Settings Sequence Data Frame</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-news" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">News</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-news">
<li><h6 class="dropdown-header" data-toc-skip>Releases</h6></li>
    <li><a class="external-link dropdown-item" href="https://github.com/ferlmic/gstest/tree/main/">G-Series 3.0 (latest - R package gstest 3.0.0)</a></li>
    <li><a class="external-link dropdown-item" href="https://github.com/ferlmic/gstest/releases/tag/v2.0/">G-Series 2.0 (SAS® version)</a></li>
    <li><a class="external-link dropdown-item" href="https://github.com/ferlmic/gstest/releases/tag/v1.04/">G-Series 1.04 (SAS® version)</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../news/index.html">Changelog</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ferlmic/gstest/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>

    <ul class="navbar-nav"><li class="nav-item"><a class="nav-link" href="#" onclick="window.location = location.href.replace('/en/','/fr/');"><span class="fa fa-language fa-lg"></span> Français</a></li></ul>
</div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Benchmarking CookBook</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ferlmic/gstest/tree/main/vignettes/benchmarking-cookbook.Rmd" class="external-link"><code>vignettes/benchmarking-cookbook.Rmd</code></a></small>
      <div class="d-none name"><code>benchmarking-cookbook.Rmd</code></div>
    </div>

    
    
<!-- Display the link to the French web page only when rendering an HTML document
     (e.g., not when rendering the PDF version)
     
     => the Pandoc "fenced_div" below (::: {.pkgdown-devel} <...> :::) is used to avoid 
        having the link generated in the pkgdown website vignette page
     => the link would only show in the "development" version of the pkgdown website
        (`development: mode: devel` in `_pkdown.yml` or `development: mode: auto` with a 4-level 
        version number in the DESCRIPTION file), which we do not use for gstest (we set 
        `development: mode: release` in `_pkdown.yml`, resulting in a single "release" website 
        regardless of the version number -->

<p>Description of the steps of a typical benchmarking project with
G-Series (R package gstest).</p>
<p>Other useful resources related to the time series benchmarking
problem discussed here and solved using the G-Series benchmarking
functions (<code><a href="../reference/benchmarking.html">benchmarking()</a></code> and
<code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code>), in ascending order of technical
complexity:</p>
<ul>
<li><p>Fortier and Quenneville (2007), in
<strong><em>References</em></strong> for function
<code><a href="../reference/benchmarking.html">benchmarking()</a></code>, for an overview of the time series
benchmarking methodology implemented in G-Series including detailed
examples. This document is available in GCdocs for Statistics Canada
employees (search for “ICES2007_Fortier.pdf” in GCDocs).</p></li>
<li><p>Course 0436, “Theory and Application of Benchmarking”, in
<strong><em>References</em></strong> for function
<code><a href="../reference/benchmarking.html">benchmarking()</a></code> and <code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code>. Visit
the <a href="https://www.statcan.gc.ca/en/training/statistical/0436" class="external-link">Course
0436</a> web page (Statistics Canada general public website) for more
details.</p></li>
<li><p>Dagum and Cholette (2006), in
<strong><em>References</em></strong> for function
<code><a href="../reference/benchmarking.html">benchmarking()</a></code>, for a complete technical discussion and
presentation of time series benchmarking problems and their
solution.</p></li>
</ul>
<p><br></p>
<hr>
<p><br></p>
<div class="section level3">
<h3 id="prepare-the-input-data">1. Prepare the input data<a class="anchor" aria-label="anchor" href="#prepare-the-input-data"></a>
</h3>
<p>The first step usually involves converting “ts” or “mts” objects
(stats package) into the proper format for the G-Series benchmarking
functions with the following two utility functions;</p>
<ul>
<li><p><code><a href="../reference/ts_to_tsDF.html">ts_to_tsDF()</a></code> for the indicator series</p></li>
<li><p><code><a href="../reference/ts_to_bmkDF.html">ts_to_bmkDF()</a></code> for the benchmarks</p></li>
</ul>
<p>It is possible to benchmark multiple series in a single call to the
benchmarking functions. This can be done by specifying the appropriate
list of data frame variables with arguments <code>var</code> and
<code>with</code>, which can be cumbersome and make your code look
<em>cluttered</em>. A more convenient option to achieve the same result
would be to use the <code>allCols</code> argument. However, these two
alternatives have important limitations as they both require that all
the indicator series are of the same length (same number of periods) and
have the same set (number) of benchmarks. The values of the benchmarks
can obviously differ for each indicator series, but their coverage must
be the same.</p>
<p>A more flexible approach, which doesn’t suffer from the
aforementioned limitations, is to use the <em>BY-group</em> mode
(argument <code>by</code>) of the benchmarking functions after having
converted the input data frames into <em>stacked</em> (tall) versions
with the following utility functions:</p>
<ul>
<li><p><code><a href="../reference/stack_tsDF.html">stack_tsDF()</a></code> for the indicator series</p></li>
<li><p><code><a href="../reference/stack_bmkDF.html">stack_bmkDF()</a></code> for the benchmarks</p></li>
</ul>
<p>Stacked versions of the data frames use only two variables to specify
information about the different indicator series or benchmarks: one
variable for the identifiers and another for the values. A stacked data
frame therefore contains more rows but fewer variables (columns) than a
non-stacked data frame as the time series are <em>stacked</em> on top of
each other instead of being <em>layed out</em> side by side.
<em>BY-group</em> processing with stacked data frames is the recommended
approach to benchmark several series in a single benchmarking function
call, unless the number of series to benchmark is extremely large and
processing time is a really important issue (processing multiple time
series with arguments <code>var</code> or <code>allCols</code> should be
slightly faster than the BY-group approach with argument
<code>by</code>).</p>
<p><br></p>
</div>
<div class="section level3">
<h3 id="run-benchmarking">2. Run benchmarking<a class="anchor" aria-label="anchor" href="#run-benchmarking"></a>
</h3>
<p>The number of calls to the benchmarking functions depends on the
values of arguments <code>rho</code>, <code>lambda</code>,
<code>biasOption</code> and <code>bias</code> (plus
<code>low_freq_periodicity</code>, <code>n_low_freq_proj</code> and
<code>proj_knots_rho_bd</code> for function
<code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code>). One call is necessary for each
distinct combination of these argument values. In practice, however,
only argument <code>lambda</code> will usually require distinct values
to process the entire set of series: <code>lambda = 1</code> for
proportional benchmarking and <code>lambda = 0</code> for additive
benchmarking. Two calls to the benchmarking functions are therefore
often enough.</p>
<p>When more than one call is required, the input indicator series and
benchmarks data frames need to be split into distinct data frames: one
for each call with the relevant set of indicator series and benchmarks.
Alternatively, one can add one or several columns to the stacked
versions of the input data frames in order to identify (and extract) the
indicator series and benchmarks of each call.</p>
<p><strong>Note on proportional and additive benchmarking</strong><br>
Proportional benchmarking
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda \ne 0</annotation></semantics></math>)
is normally used when the main focus is the preservation of
period-to-period ratios (relative differences) and additive benchmarking
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda = 0</annotation></semantics></math>)
for the preservation of period-to-period differences. Focusing on
period-to-period ratios is usually preferable for time series for which
the amplitude (e.g., seasonal and irregular components) changes with the
level of the series. On the other hand, if the amplitude of the series
stays relatively constant regardless of the level of the series, then
looking at period-to-period differences is appropriate.</p>
<center>
<div class="float">
<img src="amplitude.png" style="width:80.0%" alt="Series Amplitude"><div class="figcaption"><strong>Series Amplitude</strong></div>
</div>
</center>
<p line-height:> </p>
<p>The most common <em>pitfall</em> would likely be using an additive
benchmarking approach when changes in the amplitude of the indicator
series are important and follow the level (the amplitude
increases/decreases with the level). The main advantage of additive
benchmarking is that it <em>works</em> (returns <em>a solution</em>) in
all contexts while proportional benchmarking will fail in some
particular cases (e.g., nonzero benchmark with zero indicator series
values for all periods covered by the benchmark). Proportional
benchmarking with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\rho &lt; 1</annotation></semantics></math>
(regression-based benchmarking) generally works well in practice
(provides <em>reasonable</em> solutions) with problems involving values
of zero for the indicator series and/or the benchmarks. Some people may
actually appreciate (find appealing) the fact that values of zero in the
initial indicator series always remain zero in proportionally
benchmarked series, which is not the case for additively benchmarked
series. As for proportional benchmarking with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\rho = 1</annotation></semantics></math>
(Denton benchmarking), the indicator series must be strictly positive.
However, one could try using argument <code>constant</code> in order to
add a (relatively small) temporary constant to the input data and solve
cases that involve values of zero in the indicator series. In practice,
note that proportional Denton benchmarking could also be
<em>approximated</em> with the regression-based approach by using a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
value that is smaller than, but very close to,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1.0</mn><annotation encoding="application/x-tex">1.0</annotation></semantics></math>
(e.g.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>0.999</mn></mrow><annotation encoding="application/x-tex">\rho = 0.999</annotation></semantics></math>).
Finally, although proportional benchmarking
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≠</mo><mn>0</mn><mo>,</mo><mo>∀</mo><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\lambda \ne 0, \forall \rho</annotation></semantics></math>)
is not allowed by default in presence of negative values, this behaviour
can be modified with argument <code>negInput_option</code>. In any case,
one should closely monitor proportionally benchmarked series involving
negative values or values of zero (or almost zero) where ratios may be
undefined, unstable or difficult to interpret. The resulting
proportionally benchmarked data should be carefully analyzed and
validated in such cases to make sure they correspond to reasonable,
interpretable solutions.</p>
<p><br></p>
</div>
<div class="section level3">
<h3 id="validate-the-results">3. Validate the results<a class="anchor" aria-label="anchor" href="#validate-the-results"></a>
</h3>
<p>Any warning and error message generated by the benchmarking functions
should be investigated in order to fix the corresponding issue(s). Once
clean executions of the benchmarking functions (free of warning and
error messages) are obtained, one should validate the resulting
benchmarked series data. Utility function <code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code>
generates useful graphics to perform such a task.</p>
<p>Examples of things to look for in the benchmarking results:</p>
<ul>
<li><p><strong>Inadequate projected benchmarking adjustments</strong>.
The benchmarking solution for periods not covered by a benchmark at the
end of the series is driven by parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
(argument <code>rho</code>) and the specified bias adjustment (arguments
<code>biasOption</code>and <code>bias</code>). Bias adjustment is
generally recommended when the levels of the benchmarks and the
indicator series are systematically different (e.g., benchmarks always,
or almost always, larger than the indicator series or vice versa). Not
correcting for an (important) bias may result in poor results for the
benchmarked series for periods not covered by a benchmark (poor
projected benchmarking adjustments), which may then lead to large
revisions as new benchmarks become available in the future. Correcting
for the bias should help in such cases. An exception is <em>Denton
benchmarking</em>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\rho = 1</annotation></semantics></math>)
where bias adjustment has no impact on the benchmarking solution.
Changing the value of parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>,
which dictates the speed at which the projected adjustments converge to
the bias for periods not covered by a benchmark, may also improve the
situation. The smaller the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
the faster the convergence, with immediate convergence when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\rho = 0</annotation></semantics></math>
and no convergence at all (the adjustment of the last period covered by
a benchmark is repeated) when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\rho = 1</annotation></semantics></math>
(Denton benchmarking). A general recommendation that works reasonably
well in most cases is to adjust with the estimated average bias
(<code>biasOption = 3</code> and <code>bias = NA</code>) and use
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\rho = 0.9</annotation></semantics></math>
for monthly indicators and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo>=</mo><msup><mn>0.9</mn><mn>3</mn></msup><mo>=</mo><mn>0.729</mn></mrow><annotation encoding="application/x-tex">\rho = 0.9^3 = 0.729</annotation></semantics></math>
for quarterly indicators. Specifying a user-defined bias (argument
<code>bias</code>) may be relevant if the discrepancies between the two
sources of data have changed over time (e.g., specifying a value more
representative of the <em>recent bias</em>). An alternative would be to
use <em>explicit</em> forecasts for the benchmarks at the end of the
series instead of relying on the <em>implicit</em> projected benchmarks
associated to the bias adjustment and parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>.
For example, available auxiliary information could be used to generate
explicit benchmarks and (if the projections are good) reduce revisions
once the true benchmark values are known. The first two benchmarking
graphs (<em>Original Scale Plot</em> and <em>Adjustment Scale Plot</em>)
of function <code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code> should help identify
potential issues with the projections.</p></li>
<li><p><strong>Inadequate autoregressive parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
(argument <code>rho</code>)</strong>. The goal of benchmarking usually
is to preserve the period to period movements of the indicator series,
to which correspond values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
relatively close to 1 and smooth benchmarking adjustments. This being
said, some particular cases may warrant small values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
corresponding to <em>less smooth</em> adjustments and reduced movement
preservation. The 2<sup>nd</sup> benchmarking graph (<em>Adjustment
Scale Plot</em>) of function <code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code> shows the
benchmarking adjustments and can therefore be used to assess the
<em>smoothness</em> of the adjustments and modify, if necessary, the
value of parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>.
The corresponding degree of movement preservation is illustrated by the
3<sup>rd</sup> and 4<sup>th</sup> benchmarking graphs (<em>Growth Rates
Plot</em> and <em>Table</em>) of function
<code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code>. Note that the benchmarking adjustments
can also be plotted using utility function
<code><a href="../reference/plot_benchAdj.html">plot_benchAdj()</a></code>.</p></li>
<li><p><strong>Inadequate adjustment model parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
(argument <code>lambda</code>)</strong>. Additive benchmarking is
implemented when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda = 0</annotation></semantics></math>
and proportional benchmarking otherwise (when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda \ne 0</annotation></semantics></math>).
Choosing the <em>ideal</em> adjustment model may not necessarily be
obvious. Refer to the <em>Note on proportional and additive
benchmarking</em> above for some insights. Trying both an additive and a
proportional benchmarking approach and comparing the benchmarking
graphics may help choose the benchmarking adjustment model. For example,
the approach that generates a more natural looking benchmarked series in
the <em>Original Scale Plot</em> (1<sup>st</sup> graph), smoother
benchmarking adjustments in the <em>Adjustment Scale Plot</em>
(2<sup>nd</sup> graph) and better movement preservation in the
<em>Growth Rates Plot</em> and <em>Table</em> (3<sup>rd</sup> and
4<sup>th</sup> graphs) should be favoured. Looking at the benchmarking
graphics of function <code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code> should also help
identify problematic solutions that may require a change of adjustment
model. For example, problematic cases of proportional benchmarking
problems with negative values (see argument
<code>negInput_option</code>) or values of zero or almost zero for the
benchmarks or the indicator series would most likely generate <em>odd
looking</em> benchmarked series in the <em>Original Scale Plot</em>,
extreme or non-smooth adjustments in the <em>Adjustment Scale Plot</em>
or poor movement preservation in the <em>Growth Rates Plot</em> and
<em>Table</em>. An additive benchmarking approach may be a better
alternative in such cases.</p></li>
</ul>
<p>Systematically looking at all the graphics may not necessarily be
feasible in practice for large benchmarking projects involving many
series. A (crude) classification analysis of the benchmarking functions’
<strong>graphTable</strong> output data frame (the input of function
<code><a href="../reference/plot_graphTable.html">plot_graphTable()</a></code>) may help identify cases requiring
further investigation and a <em>closer look</em> at the benchmarking
graphics.</p>
<p><strong>Note on stock series</strong><br>
Benchmarking stock series with the <code><a href="../reference/benchmarking.html">benchmarking()</a></code> function
generates non smooth adjustments (<em>kinks</em>) around each benchmark,
regardless of the values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.
This is due to the nature of the benchmarks, i.e., discrete values
covering a single period (anchor points). Function
<code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code>, specifically aimed at benchmarking
stock series, usually provides better results (i.e., improved movement
preservation and smoother adjustments). Function
<code><a href="../reference/plot_benchAdj.html">plot_benchAdj()</a></code> is especially useful to compare (overlay)
the adjustments of stock series generated by functions
<code><a href="../reference/benchmarking.html">benchmarking()</a></code> and <code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code>. See
<strong><em>Details</em></strong> for the
<code><a href="../reference/stock_benchmarking.html">stock_benchmarking()</a></code> function for more information on the
benchmarking of stock series.</p>
<p><br></p>
</div>
<div class="section level3">
<h3 id="process-the-benchmarked-data">4. Process the benchmarked data<a class="anchor" aria-label="anchor" href="#process-the-benchmarked-data"></a>
</h3>
<p>The final step usually involves converting the output benchmarked
series data (benchmarking functions’ <strong>series</strong> output data
frame) into “ts” (or “mts”) objects with utility function
<code><a href="../reference/tsDF_to_ts.html">tsDF_to_ts()</a></code>. When <em>BY-group</em> processing
(<code>by</code> argument) is used, one would first need to
<em>unstack</em> the benchmarked series data using utility function
<code><a href="../reference/unstack_tsDF.html">unstack_tsDF()</a></code> before calling the <code><a href="../reference/tsDF_to_ts.html">tsDF_to_ts()</a></code>
function.</p>
<p><strong>Nonbinding benchmarks</strong><br>
Although benchmarking problems involving nonbinding benchmarks
(benchmarking alterability coefficients greater than 0) are relatively
rare in practice, it’s important to remember that the benchmarking
functions’ output <strong>benchmarks</strong> data frame always contains
the original (unmodified) benchmarks provided as input. In such cases,
the modified nonbinding benchmarks would be recovered (calculated) from
the output <strong>series</strong> data frame instead. For example,
flows resulting from a <code><a href="../reference/benchmarking.html">benchmarking()</a></code> call can be
aggregated using function <code><a href="https://rdrr.io/r/stats/aggregate.html" class="external-link">stats::aggregate.ts()</a></code> after
having converted the <strong>series</strong> output data frame into a
“ts” object with utility function <code><a href="../reference/tsDF_to_ts.html">tsDF_to_ts()</a></code>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Michel Ferland, Statistics Canada.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
