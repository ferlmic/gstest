[{"path":"https://ferlmic.github.io/gstest/en/articles/benchmarking-cookbook.html","id":"prepare-the-input-data","dir":"Articles","previous_headings":"","what":"1. Prepare the input data","title":"Benchmarking CookBook","text":"first step usually involves converting “ts” “mts” objects (stats package) proper format G-Series benchmarking functions following two utility functions; ts_to_tsDF() indicator series ts_to_bmkDF() benchmarks possible benchmark multiple series single call benchmarking functions. can done specifying appropriate list data frame variables arguments var , can cumbersome make code look cluttered. convenient option achieve result use allCols argument. However, two alternatives important limitations require indicator series length (number periods) set (number) benchmarks. values benchmarks can obviously differ indicator series, coverage must . flexible approach, doesn’t suffer aforementioned limitations, use -group mode (argument ) benchmarking functions converted input data frames stacked (tall) versions following utility functions: stack_tsDF() indicator series stack_bmkDF() benchmarks Stacked versions data frames use two variables specify information different indicator series benchmarks: one variable identifiers another values. stacked data frame therefore contains rows fewer variables (columns) non-stacked data frame time series stacked top instead layed side side. -group processing stacked data frames recommended approach benchmark several series single benchmarking function call, unless number series benchmark extremely large processing time really important issue (processing multiple time series arguments var allCols slightly faster -group approach argument ).","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/benchmarking-cookbook.html","id":"run-benchmarking","dir":"Articles","previous_headings":"","what":"2. Run benchmarking","title":"Benchmarking CookBook","text":"number calls benchmarking functions depends values arguments rho, lambda, biasOption bias (plus low_freq_periodicity, n_low_freq_proj proj_knots_rho_bd function stock_benchmarking()). One call necessary distinct combination argument values. practice, however, argument lambda usually require distinct values process entire set series: lambda = 1 proportional benchmarking lambda = 0 additive benchmarking. Two calls benchmarking functions therefore often enough. one call required, input indicator series benchmarks data frames need split distinct data frames: one call relevant set indicator series benchmarks. Alternatively, one can add one several columns stacked versions input data frames order identify (extract) indicator series benchmarks call. Note proportional additive benchmarking Proportional benchmarking (λ≠0\\lambda \\ne 0) normally used main focus preservation period--period ratios (relative differences) additive benchmarking (λ=0\\lambda = 0) preservation period--period differences. Focusing period--period ratios usually preferable time series amplitude (e.g., seasonal irregular components) changes level series. hand, amplitude series stays relatively constant regardless level series, looking period--period differences appropriate.  common pitfall likely using additive benchmarking approach changes amplitude indicator series important follow level (amplitude increases/decreases level). main advantage additive benchmarking works (returns solution) contexts proportional benchmarking fail particular cases (e.g., nonzero benchmark zero indicator series values periods covered benchmark). Proportional benchmarking ρ<1\\rho < 1 (regression-based benchmarking) generally works well practice (provides reasonable solutions) problems involving values zero indicator series /benchmarks. people may actually appreciate (find appealing) fact values zero initial indicator series always remain zero proportionally benchmarked series, case additively benchmarked series. proportional benchmarking ρ=1\\rho = 1 (Denton benchmarking), indicator series must strictly positive. However, one try using argument constant order add (relatively small) temporary constant input data solve cases involve values zero indicator series. practice, note proportional Denton benchmarking also approximated regression-based approach using ρ\\rho value smaller , close , 1.01.0 (e.g., ρ=0.999\\rho = 0.999). Finally, although proportional benchmarking (λ≠0,∀ρ\\lambda \\ne 0, \\forall \\rho) allowed default presence negative values, behaviour can modified argument negInput_option. case, one closely monitor proportionally benchmarked series involving negative values values zero (almost zero) ratios may undefined, unstable difficult interpret. resulting proportionally benchmarked data carefully analyzed validated cases make sure correspond reasonable, interpretable solutions.","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/benchmarking-cookbook.html","id":"validate-the-results","dir":"Articles","previous_headings":"","what":"3. Validate the results","title":"Benchmarking CookBook","text":"warning error message generated benchmarking functions investigated order fix corresponding issue(s). clean executions benchmarking functions (free warning error messages) obtained, one validate resulting benchmarked series data. Utility function plot_graphTable() generates useful graphics perform task. Examples things look benchmarking results: Inadequate projected benchmarking adjustments. benchmarking solution periods covered benchmark end series driven parameter ρ\\rho (argument rho) specified bias adjustment (arguments biasOptionand bias). Bias adjustment generally recommended levels benchmarks indicator series systematically different (e.g., benchmarks always, almost always, larger indicator series vice versa). correcting (important) bias may result poor results benchmarked series periods covered benchmark (poor projected benchmarking adjustments), may lead large revisions new benchmarks become available future. Correcting bias help cases. exception Denton benchmarking (ρ=1\\rho = 1) bias adjustment impact benchmarking solution. Changing value parameter ρ\\rho, dictates speed projected adjustments converge bias periods covered benchmark, may also improve situation. smaller value ρ\\rho faster convergence, immediate convergence ρ=0\\rho = 0 convergence (adjustment last period covered benchmark repeated) ρ=1\\rho = 1 (Denton benchmarking). general recommendation works reasonably well cases adjust estimated average bias (biasOption = 3 bias = NA) use ρ=0.9\\rho = 0.9 monthly indicators ρ=0.93=0.729\\rho = 0.9^3 = 0.729 quarterly indicators. Specifying user-defined bias (argument bias) may relevant discrepancies two sources data changed time (e.g., specifying value representative recent bias). alternative use explicit forecasts benchmarks end series instead relying implicit projected benchmarks associated bias adjustment parameter ρ\\rho. example, available auxiliary information used generate explicit benchmarks (projections good) reduce revisions true benchmark values known. first two benchmarking graphs (Original Scale Plot Adjustment Scale Plot) function plot_graphTable() help identify potential issues projections. Inadequate autoregressive parameter ρ\\rho (argument rho). goal benchmarking usually preserve period period movements indicator series, correspond values ρ\\rho relatively close 1 smooth benchmarking adjustments. said, particular cases may warrant small values ρ\\rho corresponding less smooth adjustments reduced movement preservation. 2nd benchmarking graph (Adjustment Scale Plot) function plot_graphTable() shows benchmarking adjustments can therefore used assess smoothness adjustments modify, necessary, value parameter ρ\\rho. corresponding degree movement preservation illustrated 3rd 4th benchmarking graphs (Growth Rates Plot Table) function plot_graphTable(). Note benchmarking adjustments can also plotted using utility function plot_benchAdj(). Inadequate adjustment model parameter λ\\lambda (argument lambda). Additive benchmarking implemented λ=0\\lambda = 0 proportional benchmarking otherwise (λ≠0\\lambda \\ne 0). Choosing ideal adjustment model may necessarily obvious. Refer Note proportional additive benchmarking insights. Trying additive proportional benchmarking approach comparing benchmarking graphics may help choose benchmarking adjustment model. example, approach generates natural looking benchmarked series Original Scale Plot (1st graph), smoother benchmarking adjustments Adjustment Scale Plot (2nd graph) better movement preservation Growth Rates Plot Table (3rd 4th graphs) favoured. Looking benchmarking graphics function plot_graphTable() also help identify problematic solutions may require change adjustment model. example, problematic cases proportional benchmarking problems negative values (see argument negInput_option) values zero almost zero benchmarks indicator series likely generate odd looking benchmarked series Original Scale Plot, extreme non-smooth adjustments Adjustment Scale Plot poor movement preservation Growth Rates Plot Table. additive benchmarking approach may better alternative cases. Systematically looking graphics may necessarily feasible practice large benchmarking projects involving many series. (crude) classification analysis benchmarking functions’ graphTable output data frame (input function plot_graphTable()) may help identify cases requiring investigation closer look benchmarking graphics. Note stock series Benchmarking stock series benchmarking() function generates non smooth adjustments (kinks) around benchmark, regardless values ρ\\rho λ\\lambda. due nature benchmarks, .e., discrete values covering single period (anchor points). Function stock_benchmarking(), specifically aimed benchmarking stock series, usually provides better results (.e., improved movement preservation smoother adjustments). Function plot_benchAdj() especially useful compare (overlay) adjustments stock series generated functions benchmarking() stock_benchmarking(). See Details stock_benchmarking() function information benchmarking stock series.","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/benchmarking-cookbook.html","id":"process-the-benchmarked-data","dir":"Articles","previous_headings":"","what":"4. Process the benchmarked data","title":"Benchmarking CookBook","text":"final step usually involves converting output benchmarked series data (benchmarking functions’ series output data frame) “ts” (“mts”) objects utility function tsDF_to_ts(). -group processing (argument) used, one first need unstack benchmarked series data using utility function unstack_tsDF() calling tsDF_to_ts() function. Nonbinding benchmarks Although benchmarking problems involving nonbinding benchmarks (benchmarking alterability coefficients greater 0) relatively rare practice, ’s important remember benchmarking functions’ output benchmarks data frame always contains original (unmodified) benchmarks provided input. cases, modified nonbinding benchmarks recovered (calculated) output series data frame instead. example, flows resulting benchmarking() call can aggregated using function stats::aggregate.ts() converted series output data frame “ts” object utility function tsDF_to_ts().","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"G-Series","text":"G-Series Statistics Canada’s (StatCan) generalized system devoted time series benchmarking reconciliation. methods used G-Series essentially come Dagum, E. B., P. Cholette (2006). Benchmarking, Temporal Distribution Reconciliation Methods Time Series. Springer-Verlag, New York, Lecture Notes Statistics, #186.","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"time-series-benchmarking","dir":"Articles","previous_headings":"Description","what":"Time Series Benchmarking","title":"G-Series","text":"Goal: restore coherence time series data target variable measured different frequencies (e.g., sub-annually annually). family topics included benchmarking umbrella G-Series includes, among others, temporal distribution (reciprocal action benchmarking: disaggregation benchmark series frequent observations), calendarization (special case temporal distribution) linking (connection different time series segments single consistent time series).","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"time-series-reconciliation","dir":"Articles","previous_headings":"Description","what":"Time Series Reconciliation","title":"G-Series","text":"Goal: restore cross-sectional (contemporaneous) constraints system time series measured frequency (e.g., provincial national series) optional preservation temporal constraints. reconciliation aggregation tables (data cubes) involving additivity constraints called raking G-Series balancing refers general class reconciliation problems involving type linear constraints (including inequality constraints).","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"software-availability","dir":"Articles","previous_headings":"","what":"Software Availability","title":"G-Series","text":"early versions G-Series (v1.04 v2.0) developed SAS®, software became open-source tool release G-Series 3.0 (R package gstest 3.0.0). project devoted open-source version G-Series (R package gstest). Email us g-series@statcan.gc.ca information SAS® versions. StatCan employees can also visit G-Series Confluence page agency’s intranet (search “G-Series | G-Séries” Confluence).","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"training","dir":"Articles","previous_headings":"","what":"Training","title":"G-Series","text":"StatCan offers training topics. Visit following pages agency’s website information: Theory Application Benchmarking (Course code 0436) Theory Application Reconciliation (Course code 0437)","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/gstest.html","id":"contact---support","dir":"Articles","previous_headings":"","what":"Contact - Support","title":"G-Series","text":"G-Series support provided Time Series Research Analysis Centre (TSRAC) Economic Statistics Methods Division (ESMD) Digital Processing Solutions Division (DPSD). Email us g-series@statcan.gc.ca information help using G-Series. GitHub account holders can also request information, ask questions report problems G-Series GitHub project Issues page. StatCan employees can Issues page G-Series GitLab development project hosted agency’s intranet (search “G-Series R - G-Séries en R” GitLab).","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/osqp-settings-sequence-dataframe.html","id":"data-frame-default_osqp_sequence","dir":"Articles","previous_headings":"","what":"Data frame default_osqp_sequence","title":"OSQP Settings Sequence Data Frame","text":"Fast effective sequence OSQP settings suitable accurately solving time series balancing problems. default value tsbalancing() argument osqp_settings_df.","code":"#>   max_iter    sigma  eps_abs  eps_rel eps_prim_inf eps_dual_inf polish scaling #> 1    4,000 1.00e-09 1.00e-06 1.00e-06     1.00e-07     1.00e-07   TRUE       0 #> 2   10,000 1.00e-15 1.00e-12 1.00e-12     1.00e-13     1.00e-13   TRUE       0 #> 3   10,000 1.00e-15 1.00e-12 1.00e-12     1.00e-13     1.00e-13   TRUE       0 #> 4   10,000 2.22e-16 2.22e-16 2.22e-16     2.22e-16     2.22e-16   TRUE       0 #>   prior_scaling require_polished #> 1          TRUE             TRUE #> 2          TRUE             TRUE #> 3         FALSE            FALSE #> 4          TRUE            FALSE"},{"path":"https://ferlmic.github.io/gstest/en/articles/osqp-settings-sequence-dataframe.html","id":"data-frame-alternate_osqp_sequence","dir":"Articles","previous_headings":"","what":"Data frame alternate_osqp_sequence","title":"OSQP Settings Sequence Data Frame","text":"Alternative slower sequence OSQP settings help achieve precision, needed, especially combined argument full_sequence = TRUE.","code":"#>    max_iter    sigma  eps_abs  eps_rel eps_prim_inf eps_dual_inf polish scaling #> 1    10,000 1.00e-15 1.00e-12 1.00e-12     1.00e-13     1.00e-13   TRUE       0 #> 2    10,000 1.00e-15 1.00e-12 1.00e-12     1.00e-13     1.00e-13   TRUE      10 #> 3    10,000 1.00e-12 1.00e-09 1.00e-09     1.00e-10     1.00e-10   TRUE       0 #> 4    10,000 1.00e-12 1.00e-09 1.00e-09     1.00e-10     1.00e-10   TRUE      10 #> 5    10,000 1.00e-09 1.00e-06 1.00e-06     1.00e-07     1.00e-07   TRUE       0 #> 6    10,000 1.00e-09 1.00e-06 1.00e-06     1.00e-07     1.00e-07   TRUE      10 #> 7    10,000 1.00e-06 1.00e-03 1.00e-03     1.00e-04     1.00e-04   TRUE       0 #> 8    10,000 1.00e-06 1.00e-03 1.00e-03     1.00e-04     1.00e-04   TRUE      10 #> 9    10,000 2.22e-16 2.22e-16 2.22e-16     2.22e-16     2.22e-16   TRUE       0 #> 10   10,000 2.22e-16 2.22e-16 2.22e-16     2.22e-16     2.22e-16   TRUE      10 #> 11   10,000 1.00e-15 1.00e-12 1.00e-12     1.00e-13     1.00e-13   TRUE       0 #> 12   10,000 1.00e-12 1.00e-09 1.00e-09     1.00e-10     1.00e-10   TRUE       0 #> 13   10,000 1.00e-09 1.00e-06 1.00e-06     1.00e-07     1.00e-07   TRUE       0 #> 14   10,000 1.00e-06 1.00e-03 1.00e-03     1.00e-04     1.00e-04   TRUE       0 #> 15   10,000 2.22e-16 2.22e-16 2.22e-16     2.22e-16     2.22e-16   TRUE       0 #>    prior_scaling require_polished #> 1          FALSE             TRUE #> 2          FALSE             TRUE #> 3          FALSE             TRUE #> 4          FALSE             TRUE #> 5          FALSE             TRUE #> 6          FALSE             TRUE #> 7          FALSE             TRUE #> 8          FALSE             TRUE #> 9          FALSE             TRUE #> 10         FALSE             TRUE #> 11          TRUE             TRUE #> 12          TRUE             TRUE #> 13          TRUE             TRUE #> 14          TRUE             TRUE #> 15          TRUE             TRUE"},{"path":"https://ferlmic.github.io/gstest/en/articles/osqp-settings-sequence-dataframe.html","id":"details","dir":"Articles","previous_headings":"","what":"Details","title":"OSQP Settings Sequence Data Frame","text":"exception prior_scaling require_polished, columns data frame must correspond OSQP setting. Default OSQP values used setting specified data frame. Visit https://osqp.org/docs/interfaces/solver_settings.html available OSQP settings. Note OSQP verbose setting actually controlled tsbalancing() arguments quiet display_level (.e., column verbose OSQP settings sequence data frame ignored). row OSQP settings sequence data frame represents one attempt solving balancing problem corresponding OSQP settings. solving sequence stops soon valid solution obtained (solution constraint discrepancies smaller equal tolerance specified tsbalancing() argument validation_tol) unless column require_polished = TRUE, case polished solution OSQP (status_polish = 1) also required stop sequence. Constraint discrepancies correspond max(0,l−Ax,Ax−u)\\mathrm{max}(0, l - Ax, Ax - u) constraints defined l≤Ax≤ul \\le Ax \\le u. event satisfactory solution obtained gone entire sequence, tsbalancing() returns solution generated smallest total constraint discrepancies among valid solutions, , among solutions, otherwise. Note running entire solving sequence can enforced specifying tsbalancing() argument full_sequence = TRUE. Rows column prior_scaling = TRUE problem data scaled prior solving OSQP, using average free (nonbinding) problem values scaling factor. addition specifying custom-made OSQP settings sequence data frame argument osqp_settings_df, one can also specify osqp_settings_df = NULL result single solving attempt default OSQP values settings along prior_scaling = FALSE require_polished = FALSE. Note recommended, however, first try data frames default_osqp_sequence alternate_osqp_sequence, along full_sequence = TRUE necessary, considering alternatives.","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/osqp-settings-sequence-dataframe.html","id":"recommended-approach","dir":"Articles","previous_headings":"","what":"Recommended Approach","title":"OSQP Settings Sequence Data Frame","text":"Start default tsbalancing() solving sequence (osqp_settings_df = default_osqp_sequence full_sequence = FALSE). , precision needed, try : full_sequence = TRUE osqp_settings_df = alternate_osqp_sequence osqp_settings_df = alternate_osqp_sequence full_sequence = TRUE practice, specifying full_sequence = TRUE enough precision needed (expense execution time, obviously). rare occasions need use alternate_osqp_sequence data frame, often even costly terms execution time especially combined full_sequence = TRUE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/articles/osqp-settings-sequence-dataframe.html","id":"guiding-principles","dir":"Articles","previous_headings":"","what":"Guiding Principles","title":"OSQP Settings Sequence Data Frame","text":"following summary lessons learned developing tsbalancing() experimenting OSQP solver. guiding principles lead OSQP settings sequence data frames presented earlier. Note observations apply time series balancing problems solved tsbalancing() may directly apply types quadratic problems. Data preconditioning options available OSQP (scaling setting) sufficient (badly scaled) problems. External (prior) data scaling (prior_scaling = TRUE) sometimes necessary OSQP converge decent pace generate precise enough solutions reasonable number iterations. Prior data scaling often reduces execution time (required number iterations achieve specified precision) greatly increases likelihood polished solutions. Polished solutions always precise, even prior data scaling performed (.e., solution original scale usually still precise enough). polished solutions prior-scaled data usually precise unpolished solutions non prior-scaled data, precise solutions correspond polished solutions non prior-scaled data. Smaller sigma tolerance (eps_*) settings result precise solutions take longer run (require iterations). Enough precision usually obtained 10,000 iterations small values sigma tolerance (eps_*) settings. default OSQP values alpha various settings associated ρ\\rho (*rho*) sufficient (work well). Reducing sigma tolerance (eps_*) settings performing prior data scaling sufficient obtain precise solutions reasonable number iterations. eps_abs = eps_rel = 1,000 * sigma eps_prim_inf = eps_dual_inf = 100 * sigma (consequently) eps_abs = eps_rel = 10 * eps_prim_inf = 10 * eps_dual_inf machine epsilon (.Machine$double.eps) sigma tolerance (eps_*) settings, basically forces maximum number iterations, used last resort OSQP settings sequence data frames. Summary - default sequence (data frame default_osqp_sequence) Geared towards achieving fast precise solutions. First try get (fast) polished solutions prior-scaled data attempting solving original (non-scaled) problem data. Make final attempt prior-scaled data machine epsilon sigma tolerance (eps_*) settings. Summary - alternative sequence (data frame alternate_osqp_sequence) Geared towards achieving precise solutions expense execution time. Somewhat similar brute force try approach. Small sigma tolerance (eps_*) settings gradually increase, machine epsilon last attempt. Polished solutions required every step sequence (best unpolished solution returned polished solution obtained end entire sequence). Maximum 10,000 iterations every step sequence First try get polished solutions non prior-scaled data (precise solutions), try prior-scaled data.","code":""},{"path":"https://ferlmic.github.io/gstest/en/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michel Ferland. Author, maintainer. Statistics Canada. Copyright holder, funder.","code":""},{"path":"https://ferlmic.github.io/gstest/en/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ferland M (2025). gstest: (EN) 'G-Series' 'R' | (FR) 'G-Séries' en 'R'. R package version 3.0.0, https://ferlmic.github.io/gstest/fr/, https://ferlmic.github.io/gstest/en/.","code":"@Manual{,   title = {gstest: (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R'},   author = {Michel Ferland},   year = {2025},   note = {R package version 3.0.0,     https://ferlmic.github.io/gstest/fr/},   url = {https://ferlmic.github.io/gstest/en/}, }"},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Covenant Code of Conduct for the gstest project","title":"Contributor Covenant Code of Conduct for the gstest project","text":"(Français) Contributors repositories hosted gstest expected follow Contributor Covenant Code Conduct, working within Government also expected follow Values Ethics Code Public Sector.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct for the gstest project","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best department Showing empathy towards members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Code Conduct applies within project spaces public spaces individual representing project, members Statistics Canada. Examples representing project, members Statistics Canada include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team g-series@statcan.gc.ca. complaints reviewed investigated result response deemed necessary appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"attribution-en","dir":"","previous_headings":"","what":"Attribution [EN]","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Code Conduct adapted Contributor Covenant, version 1.4, available https://www.contributor-covenant.org/version/1/4/code--conduct.html Code Conduct also inspired GDS’ alphagov Code conduct","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"code-de-conduite-pour-le-projet-gstest","dir":"","previous_headings":"","what":"Code de conduite pour le projet gstest","title":"Contributor Covenant Code of Conduct for the gstest project","text":"(English) Les contributeurs aux dépôts hébergés dans gstest sont tenus de respecter le Code de conduite du Pacte des contributeurs, et ceux qui travaillent au sein du gouvernement sont également tenus de respecter le Code de valeurs et d’éthique du secteur public.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"notre-engagement","dir":"","previous_headings":"","what":"Notre engagement","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Dans le de favoriser un environnement ouvert et accueillant, nous nous engageons, en tant que collaborateurs et responsables, à faire de la participation à notre projet et à notre communauté une expérience sans harcèlement pour tous, quels que soient leur âge, leur taille, leur handicap, leur origine ethnique, leurs caractéristiques sexuelles, leur identité et expression sexuelles, leur niveau d’expérience, leur éducation, leur statut socio-économique, leur nationalité, leur apparence, leur race, leur religion et leur orientation sexuelle et leur identité.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"nos-normes","dir":"","previous_headings":"","what":"Nos normes","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Exemples de comportements qui contribuent à créer un environnement positif incluent : Utiliser un langage accueillant et inclusif Être respectueux des différents points de vue et expériences Accepter gracieusement les critiques constructives Se concentrer sur ce qui est le mieux pour la communauté Faire preuve d’empathie envers les autres membres de la communauté Voici des exemples de comportements inacceptables de la part des participants : L’utilisation d’un langage ou d’images sexualisés et d’une attention sexuelle importunée, ou percées Trollage, commentaires insultants ou méprisants, et attaques personnelles ou politiques Harcèlement public ou privé La publication d’informations privées d’autrui, telles que des informations physiques ou électroniques. adresse, sans autorisation explicite Tout autre comportement qui pourrait raisonnablement être considéré comme inapproprié dans le cadre d’une enquête du contexte professionnel","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"nos-responsabilités","dir":"","previous_headings":"","what":"Nos responsabilités","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Les responsables de la mise à jour du projet ont la responsabilité de clarifier les normes d’acceptabilité du et s’attend à ce qu’ils prennent des mesures correctives appropriées et équitables en cas de comportement inacceptable. Les responsables de projet ont le droit et la responsabilité de supprimer, d’éditer ou de rejeter les commentaires, les soumissions (commits), le code, les éditions du wiki, les problèmes et autres contributions qui ne sont pas conformes au présent Code de conduite, ou d’interdire temporairement ou définitivement tout contributeur pour d’autres comportements qu’ils jugent inappropriés, menaçant, offensant ou nuisible.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"portée","dir":"","previous_headings":"","what":"Portée","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Ce Code de conduite s’applique dans tous les espaces du projet, et il s’applique également lorsque une personne représente le projet ou sa communauté dans les espaces publics. Des exemples de représentation d’un projet ou d’une collectivité comprennent l’utilisation d’un représentant officiel de la l’adresse électronique du projet, l’affichage par l’entremise d’un compte officiel de médias sociaux ou le fait d’agir à titre intérimaire en tant que représentant désigné lors d’un événement en ligne ou hors ligne. La représentation d’un projet peut être mieux défini et clarifié par les responsables du projet.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"application-des-règles","dir":"","previous_headings":"","what":"Application des règles","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Les cas de comportement abusif, de harcèlement ou d’autres comportements inacceptables peuvent être rapportés en communiquant avec l’équipe de projet à l’adresse suivante : g-series@statcan.gc.ca. Toutes les plaintes feront l’objet d’un examen et d’une enquête et donneront lieu à une réponse qui est jugée nécessaire et appropriée dans les circonstances. L’équipe de projet est dans l’obligation de respecter la confidentialité à l’égard du déclarant d’un incident. De plus amples détails sur les politiques d’application spécifiques peuvent être affichés séparément. Les responsables de projet qui ne respectent pas ou n’appliquent pas le Code de conduite en bonne et due formepeuvent faire face à des répercussions temporaires ou permanentes déterminées par d’autres membres de la les membres de la direction du projet.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CODE_OF_CONDUCT.html","id":"attribution-fr","dir":"","previous_headings":"","what":"Attribution [FR]","title":"Contributor Covenant Code of Conduct for the gstest project","text":"Le présent Code de conduite est adapté de la version 1.4 du Pacte du contributeur, disponible à l’adresse https://www.contributor-covenant.org/version/1/4/code--conduct.html Le présent Code de conduite s’inspire également du « Code de conduite » du alphaGov de GDS.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"(Français)","code":""},{"path":"https://ferlmic.github.io/gstest/en/CONTRIBUTING.html","id":"how-to-contribute","dir":"","previous_headings":"","what":"How to Contribute","title":"Contributing","text":"contributing, post comments discuss changes wish make via Issues. Feel free propose changes creating Pull Requests. don’t write access, editing file create Fork project save proposed changes . Submitting change file write new Branch Fork, can send Pull Request. first time contributing GitHub, don’t worry! Let us know questions.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CONTRIBUTING.html","id":"security","dir":"","previous_headings":"How to Contribute","what":"Security","title":"Contributing","text":"post security issues public repository! See SECURITY.md","code":""},{"path":"https://ferlmic.github.io/gstest/en/CONTRIBUTING.html","id":"comment-contribuer","dir":"","previous_headings":"","what":"Comment contribuer","title":"Contributing","text":"Lorsque vous contribuez, veuillez également publier des commentaires et discuter des modifications que vous souhaitez apporter par l’entremise des enjeux (Issues). N’hésitez pas à proposer des modifications en créant des demandes de tirage (Pull Requests). Si vous n’avez pas accès au mode de rédaction, la modification d’un fichier créera une copie (Fork) de ce projet afin que vous puissiez enregistrer les modifications que vous proposez. Le fait de proposer une modification à un fichier l’écrira dans une nouvelle branche dans votre copie (Fork), de sorte que vous puissiez envoyer une demande de tirage (Pull Request). Si c’est la première fois que vous contribuez à GitHub, ne vous en faites pas! Faites-nous part de vos questions.","code":""},{"path":"https://ferlmic.github.io/gstest/en/CONTRIBUTING.html","id":"sécurité","dir":"","previous_headings":"Comment contribuer","what":"Sécurité","title":"Contributing","text":"Ne publiez aucun problème de sécurité sur le dépôt publique! Voir SECURITY.md","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"R version Statistics Canada’s (StatCan) generalized system G-Series initially developed SAS®. website devoted G-Series R (package gstest). Email us g-series@statcan.gc.ca information SAS® versions. Note - StatCan intranet StatCan employees can also visit G-Series Confluence page agency’s intranet (search “G-Series | G-Séries” Confluence) well G-Series GitLab development project also hosted agency’s intranet (search “G-Series R - G-Séries en R” GitLab). latter includes version information instructions contained page specific StatCan infrastructure (e.g., Artifactory GitLab); see file index_StatCan.md GitLab project root folder. G-Series 3.0 (package gstest 3.0.0) initial open-source version software. includes rewriting R SAS® G‑Series 2.0 functionalities, PROC BENCHMARKING, PROC TSRAKING macro GSeriesTSBalancing along function benchmarking stocks using spline interpolation approach spline knots correspond benchmark--indicator ratios differences. includes following core functions: benchmarking() stock_benchmarking() tsraking(), tsraking_driver() tsbalancing() utility functions also included package. Visit Reference page (top bar) complete list available functions.","code":""},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"<release-tag> refers values listed GitHub project Tags (≥\\geqv3.0.0).","code":"# Release version from CRAN  # (coming soon...) #install.packages(\"gstest\")  # Development version from GitHub install.packages(\"remotes\") remotes::install_github(\"ferlmic/gstest\")  # A specific release version from GitHub remotes::install_github(\"ferlmic/gstest@<release-tag>\")"},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"alternative","dir":"","previous_headings":"Installation","what":"Alternative","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"package can also installed downloaded source files. approach requires prior installation packages gstest depends (repos = NULL install.packages() call). Access relevant GitHub repository (main branch tag ≥\\geqv3.0.0) Download repository files (Code > Download ZIP) Decompress downloaded repository files Install gstest package (dependent packages):","code":"install.packages(c(\"ggplot2\", \"ggtext\", \"gridExtra\", \"lifecycle\", \"osqp\", \"rlang\", \"xmpdf\")) install.packages(\"<name & path of the decompressed downloaded repository files>\",                  repos = NULL, type = \"source\")"},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"vignettes","dir":"","previous_headings":"Installation","what":"Vignettes","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"Installing gstest CRAN (install.packages(\"gstest\")) automatically builds installs package vignettes. However, case default installing package GitHub (remotes::install_github()) downloaded source files (install.packages(..., repos = NULL, type = \"source\")). Although vignettes necessary package functional, contain useful complementary documentation. gstest package vignettes available Articles drop-menu (top bar) website pdf/ folder GitHub repository. Installing vignettes package makes accessible within R well (e.g., browseVignettes(\"gstest\") vignette(\"<vignette-name>\")). Building gstest package vignettes requires (free) Pandoc software, included RStudio, LaTeX distribution (e.g., TinyTex). therefore avoid trying build gstest package vignettes basic R GUI (unless standalone installation Pandoc) without working LaTeX distribution. Building vignettes also requires R packages knitr rmarkdown. installing GitHub, use argument build_vignettes = TRUE: installing downloaded source files, build bundle package first devtools::build(): Note: packages knitr, lifecycle, rlang rmarkdown automatically installed devtools.","code":"install.packages(c(\"knitr\", \"remotes\", \"rmarkdown\")) remotes::install_github(\"ferlmic/gstest\", build_vignettes = TRUE) install.packages(c(\"devtools\", \"ggplot2\", \"ggtext\", \"gridExtra\", \"osqp\", \"xmpdf\")) bndl_pkg_path <- devtools::build(\"<name & path of the decompressed downloaded repository files>\") install.packages(bndl_pkg_path, repos = NULL, type = \"source\")"},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"bilingual (French-English) gstest package documentation available website also accessible within R (English ). help(\"gstest\") R displays general package information including link (URL) website. Clicking Index link bottom gstest package help page RStudio (help(package = \"gstest\")) displays list documentation elements available package, including: topic/function help pages (top bar’s Reference page); vignettes, installed (top bar’s Articles drop-menu); package news (Changelog page top bar’s News drop-menu). individual function help pages found Reference page (top bar) can accessed directly R help(\"<function-name>\"). contain comprehensive information function including useful examples primary source information. vignettes found Articles drop-menu (top bar) complementary source information , installed package, can also accessed within R browseVignettes(\"gstest\") vignette(\"<vignette-name>\"). include: Benchmarking CookBook (vignette(\"benchmarking-cookbook\")) going steps typical benchmarking project; Beginner’s Benchmarking Demo Script (vignette(\"benchmarking-demo-script\")) illustrating usage benchmarking functions practical context; OSQP Settings Sequence Data Frame page (vignette(\"osqp-settings-sequence-dataframe\")) describing solving sequence implemented tsbalancing() explaining can customized. Finally, Get started page (top bar) provides general information G-Series available vignette R (vignette(\"gstest\")).","code":""},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"local-copy-of-the-package-website","dir":"","previous_headings":"Documentation","what":"Local copy of the package website","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"docs/ folder GitHub repository (main branch tag ≥\\geqv3.0.0) contains package website files can therefore downloaded obtain local copy website. can useful offline consultation accessing documentation specific version package (e.g., development version earlier release). downloaded (Code > Download ZIP) decompressed repository files, open file docs/en/index.html web browser access local copy (current) home page. Alternatively, one can use GitHub tool Download GitHub directory download contents docs/ folder instead entire repository: Open docs/ folder relevant GitHub repository (main branch tag ≥\\geqv3.0.0). Copy folder URL (address bar) Download GitHub directory tool’s text field press Enter. Decompress downloaded directory. Open file en/index.html web browser. Note: Search box (top bar) functional local copies package website.","code":""},{"path":"https://ferlmic.github.io/gstest/en/index.html","id":"pdf-format","dir":"","previous_headings":"Documentation","what":"PDF format","title":"(EN) G-Series in R | (FR) G-Séries en R","text":"G-Series documentation PDF format, also useful offline consultation specific version G-Series, available pdf/ folder GitHub repository (main branch tag ≥\\geqv3.0.0 R versions tag ≤\\leqv2.0 SAS® versions). , GitHub tool Download GitHub directory can used download contents pdf/ folder instead entire repository. Decompressing downloaded directory unveil individual PDF files.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://ferlmic.github.io/gstest/en/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://ferlmic.github.io/gstest/en/reference/aliases.html","id":null,"dir":"Reference","previous_headings":"","what":"Function aliases — aliases","title":"Function aliases — aliases","text":"proc_benchmarking() alias benchmarking() proc_tsraking() alias tsraking() macro_gseriestsbalancing() alias tsbalancing()","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/aliases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function aliases — aliases","text":"","code":"proc_benchmarking(...)  proc_tsraking(...)  macro_gseriestsbalancing(...)"},{"path":"https://ferlmic.github.io/gstest/en/reference/aliases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function aliases — aliases","text":"... Corresponding function arguments.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/aliases.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function aliases — aliases","text":"name aliases reminiscent corresponding function's SAS\\(^\\circledR\\) origin (PROC BENCHMARKING, PROC TSRAKING macro GSeriesTSBalancing G-Series 2.0). aliases also ensure backward compatibility early development versions R package. See corresponding function examples description arguments returned value: benchmarking() alias proc_benchmarking() tsraking() alias proc_tsraking() tsbalancing() alias macro_gseriestsbalancing()","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore temporal constraints — benchmarking","title":"Restore temporal constraints — benchmarking","text":"Replication G-Series 2.0 SAS\\(^\\circledR\\) BENCHMARKING procedure (PROC BENCHMARKING). See G-Series 2.0 documentation details (Statistics Canada 2016). function ensures coherence time series data target variable measured different frequencies (e.g., sub-annually annually). Benchmarking consists imposing level benchmark series (e.g., annual data) minimizing revisions observed movement indicator series (e.g.,  sub-annual data) much possible. function also allows nonbinding benchmarking benchmark series can also revised. function may also used benchmarking-related topics temporal distribution (reciprocal action benchmarking: disaggregation benchmark series frequent observations), calendarization (special case temporal distribution) linking (connection different time series segments single consistent time series). Several series can benchmarked single function call.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore temporal constraints — benchmarking","text":"","code":"benchmarking(   series_df,   benchmarks_df,   rho,   lambda,   biasOption,   bias = NA,   tolV = 0.001,   tolP = NA,   warnNegResult = TRUE,   tolN = -0.001,   var = \"value\",   with = NULL,   by = NULL,   verbose = FALSE,    # New in G-Series 3.0   constant = 0,   negInput_option = 0,   allCols = FALSE,   quiet = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore temporal constraints — benchmarking","text":"series_df (mandatory) Data frame, object coerced one, contains indicator time series data benchmarked. addition series data variable(s), specified argument var, data frame must also contain two numeric variables, year period, identifying periods indicator time series. benchmarks_df (mandatory) Data frame, object coerced one, contains benchmarks. addition benchmarks data variable(s), specified argument , data frame must also contain four numeric variables, startYear, startPeriod, endYear endPeriod, identifying indicator time series periods covered benchmark. rho (mandatory) Real number \\([0,1]\\) interval specifies value autoregressive parameter \\(\\rho\\). See section Details information effect parameter \\(\\rho\\). lambda (mandatory) Real number, suggested values \\([-3,3]\\) interval, specifies value adjustment model parameter \\(\\lambda\\). Typical values lambda = 0.0 additive model lambda = 1.0 proportional model. biasOption (mandatory) Specification bias estimation option: 1: estimate bias. bias used correct indicator series value specified argument bias. 2: Estimate bias, display result, use . bias used correct indicator series value specified argument bias. 3: Estimate bias, display result use estimated bias correct indicator series. value specified argument bias ignored. Argument biasOption ignored rho = 1.0. See section Details information bias. bias (optional) Real number, NA, specifying value user-defined bias used correction indicator series prior benchmarking. bias added indicator series additive model (argument  lambda = 0.0) multiplied otherwise (argument lambda != 0.0). bias correction applied bias = NA, equivalent specifying bias = 0.0 lambda = 0.0 bias = 1.0 otherwise. Argument bias ignored biasOption = 3 rho = 1.0. See section Details information bias. Default value bias = NA (user-defined bias). tolV, tolP (optional) Nonnegative real number, NA, specifying tolerance, absolute value percentage, used validation output binding benchmarks (alterability coefficient \\(0.0\\)). validation compares input binding benchmark values equivalent values calculated benchmarked series (output) data. Arguments tolV tolP specified (one must specified must NA). Example: set tolerance 10 units, specify tolV = 10, tolP = NA; set tolerance 1%, specify tolV = NA, tolP = 0.01. Default values tolV = 0.001 tolP = NA. warnNegResult (optional) Logical argument specifying whether warning message generated negative value created function benchmarked (output) series smaller threshold specified argument tolN. Default value warnNegResult = TRUE. tolN (optional) Negative real number specifying threshold identification negative values. value considered negative smaller threshold. Default value tolN = -0.001. var (optional) String vector (minimum length 1) specifying variable name(s) indicator series data frame (argument series_df) containing values (optionally) user-defined alterability coefficients series benchmarked. variables must numeric. syntax var = c(\"series1 <\/ alt_ser1>\", \"series2 <\/ alt_ser2>\", ...). Default alterability coefficients \\(1.0\\) used user-defined alterability coefficients variable specified alongside indicator series variable. See section Details information alterability coefficients. Example: var = \"value / alter\" benchmark indicator series data frame variable value alterability coefficients contained variable alter var = c(\"value / alter\", \"value2\") additionally benchmark variable value2 default alterability coefficients \\(1.0\\). Default value var = \"value\" (benchmark variable value using default alterability coefficients \\(1.0\\)). (optional) String vector (length argument var), NULL, specifying variable name(s) benchmarks data frame (argument benchmarks_df) containing values (optionally) user-defined alterability coefficients benchmarks. variables must numeric. Specifying = NULL results using benchmark variable(s) names(s) specified argument var without user-defined benchmark alterability coefficients (.e., default alterability coefficients \\(0.0\\) corresponding binding benchmarks). syntax = NULL = c(\"bmk1 <\/ alt_bmk1>\", \"bmk2 <\/ alt_bmk2>\", ...). Default alterability coefficients \\(0.0\\) (binding benchmarks) used user-defined alterability coefficients variable specified alongside benchmark variable. See section Details information alterability coefficients. Example: = \"val_bmk\" use benchmarks data frame variable val_bmk default benchmark alterability coefficients \\(0.0\\) benchmark indicator series = c(\"val_bmk\", \"val_bmk2 / alt_bmk2\") additionally benchmark second indicator series using benchmark variable val_bmk2 benchmark alterability coefficients contained variable alt_bmk2. Default value = NULL (benchmark variable(s) argument var using default benchmark alterability coefficients \\(0.0\\)). (optional) String vector (minimum length 1), NULL, specifying variable name(s) input data frames (arguments series_df benchmarks_df) used form groups (-group processing) allow benchmarking multiple series single function call. -group variables can numeric character (factors ), must present input data frames appear three output data frames (see section Value). -group processing  implemented = NULL. See \"Benchmarking Multiple Series\" section Details information. Default value = NULL (-group processing). verbose (optional) Logical argument specifying whether information intermediate steps execution time (real time, CPU time) displayed. Note specifying argument quiet = TRUE nullify argument verbose. Default value verbose = FALSE. constant (optional) Real number specifies value temporarily added indicator series benchmarks solving proportional benchmarking problems (lambda != 0.0). temporary constant removed final output benchmarked series. E.g., specifying (small) constant allow proportional benchmarking rho = 1 (e.g., proportional Denton benchmarking) indicator series include values 0. Otherwise, proportional benchmarking values 0 indicator series possible rho < 1. Specifying constant additive benchmarking (lambda = 0.0) impact resulting benchmarked data. data variables graphTable output data frame include constant, corresponding benchmarking problem actually solved. Default value constant = 0 (temporary additive constant). negInput_option (optional) Handling negative values input data proportional benchmarking (lambda != 0.0): 0: allow negative values proportional benchmarking. error message displayed presence negative values input indicator series benchmarks missing (NA) values returned benchmarked series. corresponds G-Series 2.0 behaviour. 1: Allow negative values proportional benchmarking display warning message. 2: Allow negative values proportional benchmarking without displaying message. Default value negInput_option = 0 (allow negative values proportional benchmarking). allCols (optional) Logical argument specifying whether variables indicator series data frame (argument series_df), year period, determine set series benchmark. Values specified arguments var ignored allCols = TRUE, automatically implies default alterability coefficients, variables names indicator series must exist benchmarks data frame (argument benchmarks_df). Default value allCols = FALSE. quiet (optional) Logical argument specifying whether display essential information warning messages, error messages variable (series) -group information multiple series benchmarked single call function. advise wrapping benchmarking() call suppressMessages() suppress display variable (series) -group information processing multiple series make troubleshooting difficult case issues individual series. Note specifying quiet = TRUE also nullify argument verbose. Default value quiet = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore temporal constraints — benchmarking","text":"function returns list three data frames: series: data frame containing benchmarked data (primary function output). variables specified argument included data frame alterability coefficient variables specified argument var. benchmarks: copy input benchmarks data frame (excluding invalid benchmarks applicable). variables specified argument included data frame alterability coefficient variables specified argument . graphTable: data frame containing supplementary data useful producing analytical tables graphs (see function plot_graphTable()). contains following variables addition variables specified argument : varSeries: Name indicator series variable varBenchmarks: Name benchmark variable altSeries: Name user-defined indicator series alterability coefficients variable altSeriesValue: Indicator series alterability coefficients altbenchmarks: Name user-defined benchmark alterability coefficients variable altBenchmarksValue: Benchmark alterability coefficients t: Indicator series period identifier (1 \\(T\\)) m: Benchmark coverage periods identifier (1 \\(M\\)) year: Data point calendar year period: Data point period (cycle) value (1 periodicity) constant: Temporary additive constant (argument constant) rho: Autoregressive parameter \\(\\rho\\) (argument rho) lambda: Adjustment model parameter \\(\\lambda\\) (argument lambda) bias: Bias adjustment (default, user-defined estimated bias according arguments biasOption bias) periodicity: maximum number periods year (e.g. 4 quarterly indicator series) date: Character string combining values variables year period subAnnual: Indicator series values benchmarked: Benchmarked series values avgBenchmark: Benchmark values divided number coverage periods avgSubAnnual: Indicator series values (variable subAnnual) averaged benchmark coverage period subAnnualCorrected: Bias corrected indicator series values benchmarkedSubAnnualRatio: Difference (\\(\\lambda = 0\\)) ratio (\\(\\lambda \\ne 0\\)) values variables benchmarked subAnnual avgBenchmarkSubAnnualRatio: Difference (\\(\\lambda = 0\\)) ratio (\\(\\lambda \\ne 0\\)) values variables avgBenchmark avgSubAnnual growthRateSubAnnual: Period period difference (\\(\\lambda = 0\\)) relative difference (\\(\\lambda \\ne 0\\)) indicator series values (variable subAnnual) growthRateBenchmarked: Period period difference (\\(\\lambda = 0\\)) relative difference (\\(\\lambda \\ne 0\\)) benchmarked series values (variable benchmarked) Notes: output benchmarks data frame always contains original benchmarks provided input benchmarks data frame. Modified nonbinding benchmarks, applicable, can recovered (calculated) output series data frame. function returns NULL object error occurs data processing start. Otherwise, execution gets far enough data processing start, incomplete object returned case errors (e.g., output series data frame NA values benchmarked data). function returns \"data.frame\" objects can explicitly coerced types objects appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restore temporal constraints — benchmarking","text":"\\(\\rho < 1\\), function returns generalized least squared solution special case general regression-based benchmarking model proposed Dagum Cholette (2006). model, matrix form, : $$\\displaystyle \\begin{bmatrix} s^\\dagger \\\\ \\end{bmatrix} = \\begin{bmatrix} \\\\ J \\end{bmatrix} \\theta + \\begin{bmatrix} e \\\\ \\varepsilon \\end{bmatrix} $$ \\(\\) vector length \\(M\\) benchmarks. \\(s^\\dagger = \\left\\{     \\begin{array}{cl}       s + b & \\text{} \\lambda = 0 \\\\       s \\cdot b  & \\text{otherwise}     \\end{array} \\right.   \\) vector length \\(T\\) bias corrected indicator series values, \\(s\\) denoting initial (input) indicator series. \\(b\\) bias, specified argument bias argument bias_option != 3 , bias_option = 3, estimated \\(\\hat{b} = \\left\\{     \\begin{array}{cl}       \\frac{{1_M}^\\mathrm{T} (- Js)}{{1_M}^\\mathrm{T} J 1_T} & \\text{} \\lambda = 0 \\\\       \\frac{{1_M}^\\mathrm{T} }{{1_M}^\\mathrm{T} Js} & \\text{otherwise}     \\end{array} \\right.   \\), \\(1_X = (1, ..., 1)^\\mathrm{T}\\) vector \\(1\\) length \\(X\\). \\(J\\) \\(M \\times T\\) matrix temporal aggregation constraints elements \\(j_{m, t} = \\left\\{     \\begin{array}{cl}       1 & \\text{benchmark } m \\text{ covers period } t \\\\       0 & \\text{otherwise}     \\end{array} \\right.   \\). \\(\\theta\\) vector final (benchmarked) series values. \\(e \\sim \\left( 0, V_e \\right)\\) vector measurement errors \\(s^\\dagger\\) covariance matrix \\(V_e = C \\Omega_e C\\). \\(C = \\mathrm{diag} \\left( \\sqrt{c_{s^\\dagger}} \\left| s^\\dagger \\right|^\\lambda \\right)\\) \\(c_{s^\\dagger}\\) vector alterability coefficients \\(s^\\dagger\\), assuming \\(0^0 = 1\\). \\(\\Omega_e\\) \\(T \\times T\\) matrix elements \\(\\omega_{e_{,j}} = \\rho^{|-j|}\\) representing autocorrelation AR(1) process, assuming \\(0^0 = 1\\). \\(\\varepsilon \\sim (0, V_\\varepsilon)\\) vector measurement errors benchmarks \\(\\) covariance matrix \\(V_\\varepsilon = \\mathrm{diag} \\left( c_a \\right)\\) \\(c_a\\) vector alterability coefficients benchmarks \\(\\). generalized least squared solution : $$\\displaystyle \\hat{\\theta} = s^\\dagger + V_e J^{\\mathrm{T}} \\left( J V_e J^{\\mathrm{T}} + V_\\varepsilon \\right)^+ \\left( - J s^\\dagger \\right) $$ \\(^{+}\\) designates Moore-Penrose inverse matrix \\(\\). \\(\\rho = 1\\), function returns solution (modified) Denton method: $$\\displaystyle \\hat{\\theta} = s + W \\left( - J s \\right) $$ \\(W\\) upper-right corner matrix following matrix product $$     \\left[\\begin{array}{cc}       D^{+} \\Delta^{\\mathrm{T}} \\Delta D^{+} & J^{\\mathrm{T}} \\\\       J & 0     \\end{array} \\right]^{+}     \\left[\\begin{array}{cc}       D^{+} \\Delta^{\\mathrm{T}} \\Delta D^{+} & 0 \\\\       J & I_M     \\end{array} \\right] =     \\left[\\begin{array}{cc}       I_T & W \\\\       0 & W_\\nu     \\end{array} \\right]   $$ \\(D = \\mathrm{diag} \\left( \\left| s \\right|^\\lambda \\right)\\), assuming \\(0^0 = 1\\). Note \\(D\\) corresponds \\(C\\) \\(c_{s^\\dagger} = 1.0\\) without bias correction (arguments bias_option = 1 bias = NA). \\(\\Delta\\) \\(T-1 \\times T\\) matrix elements \\(\\delta_{,j} = \\left\\{     \\begin{array}{cl}       -1 & \\text{} =j \\\\       1 & \\text{} j=+1 \\\\       0 & \\text{otherwise}     \\end{array} \\right.   \\). \\(W_\\nu\\) \\(M \\times M\\) matrix associated Lagrange multipliers corresponding minimization problem, expressed : $$\\displaystyle \\begin{aligned} & \\underset{\\theta}{\\text{minimize}} & & \\sum_{t \\ge 2} \\left[ \\frac{\\left( s_t - \\theta_t \\right)}{\\left| s_t\\right|^\\lambda}       - \\frac{\\left( s_{t-1} - \\theta_{t-1} \\right)}{\\left| s_{t-1}\\right|^\\lambda} \\right]^2 \\\\ & \\text{subject } & & = J \\theta \\end{aligned} $$ See Quenneville et al. (2006) Dagum Cholette (2006) details.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"autoregressive-parameter-rho-and-bias","dir":"Reference","previous_headings":"","what":"Autoregressive Parameter \\(\\rho\\) and bias","title":"Restore temporal constraints — benchmarking","text":"Parameter \\(\\rho\\) (argument rho) associated change (input) indicator (output) benchmarked series two consecutive periods often called movement preservation parameter. larger value \\(\\rho\\), indicator series period period movements preserved benchmarked series. \\(\\rho = 0\\), period period movement preservation enforced resulting benchmarking adjustments smooth, case prorating (\\(\\rho = 0\\) \\(\\lambda = 0.5\\)) adjustments take shape step function. end spectrum \\(\\rho = 1\\), referred Denton benchmarking, period period movement preservation maximized, results smoothest possible set benchmarking adjustments available function. bias represents expected discrepancies benchmarks indicator series. can used pre-adjust indicator series order reduce, average, discrepancies two sources data. Bias correction, specified arguments biasOption bias, can particularly useful periods covered benchmarks \\(\\rho < 1\\). context, parameter \\(\\rho\\) dictates speed projected benchmarking adjustments converge bias (converge adjustment without bias correction) periods covered benchmark. smaller value \\(\\rho\\), faster convergence bias, immediate convergence \\(\\rho = 0\\) convergence (adjustment last period covered benchmark repeated) \\(\\rho = 1\\) (Denton benchmarking). Arguments biasOption bias actually ignored \\(\\rho = 1\\) since correcting bias impact Denton benchmarking solutions. suggested value \\(\\rho\\) \\(0.9\\) monthly indicators \\(0.9^3 = 0.729\\) quarterly indicators, representing reasonable compromise maximizing movement preservation reducing revisions new benchmarks become available future (benchmarking timeliness issue). practice, note Denton benchmarking approximated regression-based model using \\(\\rho\\) value smaller , close , \\(1.0\\) (e.g., \\(\\rho = 0.999\\)). See Dagum Cholette (2006) complete discussion topic.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"alterability-coefficients","dir":"Reference","previous_headings":"","what":"Alterability Coefficients","title":"Restore temporal constraints — benchmarking","text":"Alterability coefficients \\(c_{s^\\dagger}\\) \\(c_a\\) conceptually represent measurement errors associated (bias corrected) indicator time series values \\(s^\\dagger\\) benchmarks \\(\\) respectively. nonnegative real numbers , practice, specify extent initial value can modified relation values. Alterability coefficients \\(0.0\\) define fixed (binding) values alterability coefficients greater \\(0.0\\) define free (nonbinding) values. Increasing alterability coefficient intial value results changes value benchmarking solution , conversely, less changes decreasing alterability coefficient. default alterability coefficients \\(0.0\\) benchmarks (binding benchmarks) \\(1.0\\) indicator series values (nonbinding indicator series). Important notes: value \\(\\rho = 1\\) (argument rho = 1, associated Denton Benchmarking), default alterability coefficients (\\(0.0\\) benchmark \\(1.0\\) indicator series value) valid. specification user-defined alterability coefficients variables therefore allowed. variables specified (see arguments var ), function ignores displays warning message console. Alterability coefficients \\(c_{s^\\dagger}\\) come play indicator series corrected bias, applicable (\\(c_{s^\\dagger}\\) associated \\(s^\\dagger\\), \\(s\\)). means specifying alterability coefficient \\(0.0\\) given indicator series value result unchanged value benchmarking bias correction (see arguments biasOption bias). Nonbinding benchmarks, applicable, can recovered (calculated) benchmarked series (see output data frame series section Value). output benchmarks data frame always contains original benchmarks provided input benchmarks data frame (argument benchmarks_df).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"benchmarking-multiple-series","dir":"Reference","previous_headings":"","what":"Benchmarking Multiple Series","title":"Restore temporal constraints — benchmarking","text":"Multiple series can benchmarked single benchmarking() call, specifying allCols = TRUE, (manually) specifying multiple variables argument var (argument ) -group processing (argument != NULL). important distinction indicator series specified allCols = TRUE argument var (benchmarks argument ) expected length, .e., set periods set (number) benchmarks. Benchmarking series different lengths (different sets periods) different sets (number) benchmarks must done -group processing stacked indicator series benchmarks input data frames (see utility functions stack_tsDF() stack_bmkDF()). Arguments var can combined order implement -group processing multiple series illustrated Example 2 Examples section. multiple variables argument var (allCols = TRUE) without -group processing (argument = NULL) slightly efficient (faster), -group approach single series variable usually recommended general (works contexts). latter illustrated Example 3 Examples section. variables specified argument appear three output data frames.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"arguments-constant-and-neginput-option","dir":"Reference","previous_headings":"","what":"Arguments constant and negInput_option","title":"Restore temporal constraints — benchmarking","text":"arguments extend usage proportional benchmarking larger set problems. default values correspond G-Series 2.0 behaviour (SAS\\(^\\circledR\\) PROC BENCHMARKING) equivalent options defined. Although proportional benchmarking may necessarily appropriate approach (additive benchmarking may appropriate) values indicator series approach 0 (unstable period--period ratios) \"cross 0 line\" can therefore go positive negative vice versa (confusing, difficult interpret period--period ratios), cases invalid mathematically speaking (.e., associated proportional benchmarking problem can solved). strongly recommended, however, carefully analyze validate resulting benchmarked data situations make sure correspond reasonable, interpretable solutions.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"treatment-of-missing-na-values","dir":"Reference","previous_headings":"","what":"Treatment of Missing (NA) Values","title":"Restore temporal constraints — benchmarking","text":"missing value appears one variables benchmarks input data frame (variables), observations missing values dropped, warning message displayed function executes. missing value appears year /period variables indicator series input data frame variables specified, corresponding -group skipped, warning message displayed function moves next -group. variables specified, warning message displayed processing done. missing value appears one indicator series variables indicator series input data frame variables specified, corresponding -group skipped, warning message displayed function moves next -group. variables specified, affected indicator series processed, warning message displayed function moves next indicator series (applicable).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Restore temporal constraints — benchmarking","text":"Dagum, E. B. P. Cholette (2006). Benchmarking, Temporal Distribution Reconciliation Methods Time Series. Springer-Verlag, New York, Lecture Notes Statistics, Vol. 186 Fortier, S. B. Quenneville (2007). \"Theory Application Benchmarking Business Surveys\". Proceedings Third International Conference Establishment Surveys (ICES-III). Montréal, June 2007. Latendresse, E., M. Djona S. Fortier (2007). \"Benchmarking Sub-Annual Series Annual Totals – Concepts SAS\\(^\\circledR\\) Procedure Enterprise Guide\\(^\\circledR\\) Custom Task\". Proceedings SAS\\(^\\circledR\\) Global Forum 2007 Conference. Cary, NC: SAS Institute Inc. Quenneville, B., S. Fortier, Z.-G. Chen E. Latendresse (2006). \"Recent Developments Benchmarking Annual Totals X-12-ARIMA Statistics Canada\". Proceedings Eurostat Conference Seasonality, Seasonal Adjustment Implications Short-Term Analysis Forecasting. Luxembourg, May 2006. Quenneville, B., P. Cholette, S. Fortier J. Bérubé (2010). \"Benchmarking Sub-Annual Indicator Series Annual Control Totals (Forillon v1.04.001)\". Internal document. Statistics Canada, Ottawa, Canada. Quenneville, B. S. Fortier (2012). \"Restoring Accounting Constraints Time Series – Methods Software Statistical Agency\". Economic Time Series: Modeling Seasonality. Chapman & Hall, New York. Statistics Canada (2012). Theory Application Benchmarking (Course code 0436). Statistics Canada, Ottawa, Canada. Statistics Canada (2016). \"BENCHMARKING Procedure\". G-Series 2.0 User Guide. Statistics Canada, Ottawa, Canada.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/benchmarking.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore temporal constraints — benchmarking","text":"","code":"# Set the working directory (for the PDF files) iniwd <- getwd()  setwd(tempdir())   ########### # Example 1: Simple case with a single quarterly series to benchmark to annual values  # Quarterly indicator series my_series1 <- ts_to_tsDF(ts(c(1.9, 2.4, 3.1, 2.2, 2.0, 2.6, 3.4, 2.4, 2.3),                             start = c(2015, 1),                             frequency = 4)) my_series1 #>   year period value #> 1 2015      1   1.9 #> 2 2015      2   2.4 #> 3 2015      3   3.1 #> 4 2015      4   2.2 #> 5 2016      1   2.0 #> 6 2016      2   2.6 #> 7 2016      3   3.4 #> 8 2016      4   2.4 #> 9 2017      1   2.3  # Annual benchmarks for quarterly data my_benchmarks1 <- ts_to_bmkDF(ts(c(10.3, 10.2),                                  start = 2015,                                  frequency = 1),                               ind_frequency = 4) my_benchmarks1 #>   startYear startPeriod endYear endPeriod value #> 1      2015           1    2015         4  10.3 #> 2      2016           1    2016         4  10.2  # Benchmarking using... #   - recommended `rho` value for quarterly series (`rho = 0.729`) #   - proportional model (`lambda = 1`) #   - bias-corrected indicator series with the estimated bias (`biasOption = 3`) out_bench1 <- benchmarking(my_series1,                            my_benchmarks1,                            rho = 0.729,                            lambda = 0,                            biasOption = 3) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> benchmarking() function: #>     series_df          = my_series1 #>     benchmarks_df      = my_benchmarks1 #>     rho                = 0.729 #>     lambda             = 0 #>     biasOption         = 3 (Calculate bias, use calculated bias) #>     bias               (ignored) #>     tolV               = 0.001 (default) #>     warnNegResult      = TRUE (default) #>     tolN               = -0.001 (default) #>     var                = value (default) #>     with               = NULL (default) #>     by                 = NULL (default) #>     verbose            = FALSE (default) #>     (*)constant        = 0 (default) #>     (*)negInput_option = 0 (default) #>     (*)allCols         = FALSE (default) #>     (*)quiet           = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #> Number of observations in the BENCHMARKS data frame .............: 2 #> Number of valid observations in the BENCHMARKS data frame .......: 2 #> Number of observations in the SERIES data frame .................: 9 #> Number of valid observations in the SERIES data frame ...........: 9 #> BIAS = 0.0625 (calculated)  # Generate the benchmarking graphs plot_graphTable(out_bench1$graphTable, \"Ex1_graphs.pdf\") #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 1 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\Ex1_graphs.pdf   ########### # Example 2: Two quarterly series to benchmark to annual values, #            with BY-groups and user-defined alterability coefficients  # Sales data (same sales for groups A and B; only alter coefs for van sales differ) qtr_sales <- ts(matrix(c(# Car sales                          1851, 2436, 3115, 2205, 1987, 2635, 3435, 2361, 2183, 2822,                          3664, 2550, 2342, 3001, 3779, 2538, 2363, 3090, 3807, 2631,                          2601, 3063, 3961, 2774, 2476, 3083, 3864, 2773, 2489, 3082,                          # Van sales                          1900, 2200, 3000, 2000, 1900, 2500, 3800, 2500, 2100, 3100,                          3650, 2950, 3300, 4000, 3290, 2600, 2010, 3600, 3500, 2100,                          2050, 3500, 4290, 2800, 2770, 3080, 3100, 2800, 3100, 2860),                        ncol = 2),                 start = c(2011, 1),                 frequency = 4,                 names = c(\"car_sales\", \"van_sales\"))  ann_sales <- ts(matrix(c(# Car sales                          10324, 10200, 10582, 11097, 11582, 11092,                          # Van sales                          12000, 10400, 11550, 11400, 14500, 16000),                        ncol = 2),                 start = 2011,                 frequency = 1,                 names = c(\"car_sales\", \"van_sales\"))  # Quarterly indicator series (with default alter coefs for now) my_series2 <- rbind(cbind(data.frame(group = rep(\"A\", nrow(qtr_sales)),                                      alt_van = rep(1, nrow(qtr_sales))),                           ts_to_tsDF(qtr_sales)),                     cbind(data.frame(group = rep(\"B\", nrow(qtr_sales)),                                      alt_van = rep(1, nrow(qtr_sales))),                           ts_to_tsDF(qtr_sales)))  # Set binding van sales (alter coef = 0) for 2012 Q1 and Q2 in group A (rows 5 and 6) my_series2$alt_van[c(5,6)] <- 0 head(my_series2, n = 10) #>    group alt_van year period car_sales van_sales #> 1      A       1 2011      1      1851      1900 #> 2      A       1 2011      2      2436      2200 #> 3      A       1 2011      3      3115      3000 #> 4      A       1 2011      4      2205      2000 #> 5      A       0 2012      1      1987      1900 #> 6      A       0 2012      2      2635      2500 #> 7      A       1 2012      3      3435      3800 #> 8      A       1 2012      4      2361      2500 #> 9      A       1 2013      1      2183      2100 #> 10     A       1 2013      2      2822      3100 tail(my_series2) #>    group alt_van year period car_sales van_sales #> 55     B       1 2017      1      2476      2770 #> 56     B       1 2017      2      3083      3080 #> 57     B       1 2017      3      3864      3100 #> 58     B       1 2017      4      2773      2800 #> 59     B       1 2018      1      2489      3100 #> 60     B       1 2018      2      3082      2860   # Annual benchmarks for quarterly data (without alter coefs) my_benchmarks2 <- rbind(cbind(data.frame(group = rep(\"A\", nrow(ann_sales))),                               ts_to_bmkDF(ann_sales, ind_frequency = 4)),                         cbind(data.frame(group = rep(\"B\", nrow(ann_sales))),                               ts_to_bmkDF(ann_sales, ind_frequency = 4))) my_benchmarks2 #>    group startYear startPeriod endYear endPeriod car_sales van_sales #> 1      A      2011           1    2011         4     10324     12000 #> 2      A      2012           1    2012         4     10200     10400 #> 3      A      2013           1    2013         4     10582     11550 #> 4      A      2014           1    2014         4     11097     11400 #> 5      A      2015           1    2015         4     11582     14500 #> 6      A      2016           1    2016         4     11092     16000 #> 7      B      2011           1    2011         4     10324     12000 #> 8      B      2012           1    2012         4     10200     10400 #> 9      B      2013           1    2013         4     10582     11550 #> 10     B      2014           1    2014         4     11097     11400 #> 11     B      2015           1    2015         4     11582     14500 #> 12     B      2016           1    2016         4     11092     16000  # Benchmarking using... #   - recommended `rho` value for quarterly series (`rho = 0.729`) #   - proportional model (`lambda = 1`) #   - without bias correction (`biasOption = 1` and `bias` not specified) #   - `quiet = TRUE` to avoid generating the function header out_bench2 <- benchmarking(my_series2,                            my_benchmarks2,                            rho = 0.729,                            lambda = 1,                            biasOption = 1,                            var = c(\"car_sales\", \"van_sales / alt_van\"),                            with = c(\"car_sales\", \"van_sales\"),                            by = \"group\",                            quiet = TRUE) #>  #> Benchmarking by-group 1 (group=A) #> ================================= #>  #> Benchmarking indicator series [car_sales] with benchmarks [car_sales] #> --------------------------------------------------------------------- #>  #> Benchmarking indicator series [van_sales] with benchmarks [van_sales] #> --------------------------------------------------------------------- #>  #> Benchmarking by-group 2 (group=B) #> ================================= #>  #> Benchmarking indicator series [car_sales] with benchmarks [car_sales] #> --------------------------------------------------------------------- #>  #> Benchmarking indicator series [van_sales] with benchmarks [van_sales] #> ---------------------------------------------------------------------  # Generate the benchmarking graphs plot_graphTable(out_bench2$graphTable, \"Ex2_graphs.pdf\") #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 4 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\Ex2_graphs.pdf  # Check the value of van sales for 2012 Q1 and Q2 in group A (fixed values) all.equal(my_series2$van_sales[c(5,6)], out_bench2$series$van_sales[c(5,6)]) #> [1] TRUE   ########### # Example 3: same as example 2, but benchmarking all 4 series as BY-groups #            (4 BY-groups of 1 series instead of 2 BY-groups of 2 series)  qtr_sales2 <- ts.union(A = qtr_sales, B = qtr_sales) my_series3 <- stack_tsDF(ts_to_tsDF(qtr_sales2)) my_series3$alter <- 1 my_series3$alter[my_series3$series == \"A.van_sales\"                 & my_series3$year == 2012 & my_series3$period <= 2] <- 0 head(my_series3) #>        series year period value alter #> 1 A.car_sales 2011      1  1851     1 #> 2 A.car_sales 2011      2  2436     1 #> 3 A.car_sales 2011      3  3115     1 #> 4 A.car_sales 2011      4  2205     1 #> 5 A.car_sales 2012      1  1987     1 #> 6 A.car_sales 2012      2  2635     1 tail(my_series3) #>          series year period value alter #> 115 B.van_sales 2017      1  2770     1 #> 116 B.van_sales 2017      2  3080     1 #> 117 B.van_sales 2017      3  3100     1 #> 118 B.van_sales 2017      4  2800     1 #> 119 B.van_sales 2018      1  3100     1 #> 120 B.van_sales 2018      2  2860     1   ann_sales2 <- ts.union(A = ann_sales, B = ann_sales) my_benchmarks3 <- stack_bmkDF(ts_to_bmkDF(ann_sales2, ind_frequency = 4)) head(my_benchmarks3) #>        series startYear startPeriod endYear endPeriod value #> 1 A.car_sales      2011           1    2011         4 10324 #> 2 A.car_sales      2012           1    2012         4 10200 #> 3 A.car_sales      2013           1    2013         4 10582 #> 4 A.car_sales      2014           1    2014         4 11097 #> 5 A.car_sales      2015           1    2015         4 11582 #> 6 A.car_sales      2016           1    2016         4 11092 tail(my_benchmarks3) #>         series startYear startPeriod endYear endPeriod value #> 19 B.van_sales      2011           1    2011         4 12000 #> 20 B.van_sales      2012           1    2012         4 10400 #> 21 B.van_sales      2013           1    2013         4 11550 #> 22 B.van_sales      2014           1    2014         4 11400 #> 23 B.van_sales      2015           1    2015         4 14500 #> 24 B.van_sales      2016           1    2016         4 16000  out_bench3 <- benchmarking(my_series3,                            my_benchmarks3,                            rho = 0.729,                            lambda = 1,                            biasOption = 1,                            var = \"value / alter\",                            with = \"value\",                            by = \"series\",                            quiet = TRUE) #>  #> Benchmarking by-group 1 (series=A.car_sales) #> ============================================ #>  #> Benchmarking by-group 2 (series=A.van_sales) #> ============================================ #>  #> Benchmarking by-group 3 (series=B.car_sales) #> ============================================ #>  #> Benchmarking by-group 4 (series=B.van_sales) #> ============================================  # Generate the benchmarking graphs plot_graphTable(out_bench3$graphTable, \"Ex3_graphs.pdf\") #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 4 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\Ex3_graphs.pdf  # Convert data frame `out_bench3$series` to a \"mts\" object qtr_sales2_bmked <- tsDF_to_ts(unstack_tsDF(out_bench3$series), frequency = 4)  # Print the first 10 observations ts(qtr_sales2_bmked[1:10, ], start = start(qtr_sales2), deltat = deltat(qtr_sales2)) #>         A.car_sales A.van_sales B.car_sales B.van_sales #> 2011 Q1    1987.762    2470.301    1987.762    2497.155 #> 2011 Q2    2641.222    2956.559    2641.222    2980.984 #> 2011 Q3    3366.003    4031.113    3366.003    4029.901 #> 2011 Q4    2329.013    2542.026    2329.013    2491.960 #> 2012 Q1    2021.161    1900.000    2021.161    2077.268 #> 2012 Q2    2602.064    2500.000    2602.064    2466.739 #> 2012 Q3    3320.486    3636.551    3320.486    3522.652 #> 2012 Q4    2256.289    2363.449    2256.289    2333.342 #> 2013 Q1    2072.168    2071.868    2072.168    2060.533 #> 2013 Q2    2663.309    3112.774    2663.309    3110.631  # Check the value of van sales for 2012 Q1 and Q2 in group A (fixed values) all.equal(window(qtr_sales2[, \"A.van_sales\"], start = c(2012, 1), end = c(2012, 2)),           window(qtr_sales2_bmked[, \"A.van_sales\"], start = c(2012, 1), end = c(2012, 2))) #> [1] TRUE   # Reset the working directory to its initial location setwd(iniwd)"},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a benchmarking graphic — bench_graphs","title":"Generate a benchmarking graphic — bench_graphs","text":"Functions used internally plot_graphTable() generate benchmarking graphics PDF file: ori_plot(): Original Scale Plot (plot_graphTable() argument ori_plot_flag = TRUE) adj_plot(): Adjustment Scale Plot (plot_graphTable() argument adj_plot_flag = TRUE) GR_plot(): Growth Rates Plot (plot_graphTable() argument GR_plot_flag = TRUE) GR_table(): Growth Rates Table (plot_graphTable() argument GR_table_flag = TRUE) functions called directly, graphTable data frame (argument graphTable) contain single series graphic generated current (active) graphics device.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a benchmarking graphic — bench_graphs","text":"","code":"ori_plot(   graphTable,   title_str = \"Original Scale\",   subtitle_str = NULL,   mth_gap = NULL,   points_set = NULL,   pt_sz = 2,   display_ggplot = TRUE,   .setup = TRUE )  adj_plot(   graphTable,   title_str = \"Adjustment Scale\",   subtitle_str = NULL,   mth_gap = NULL,   full_set = NULL,   pt_sz = 2,   display_ggplot = TRUE,   .setup = TRUE )  GR_plot(   graphTable,   title_str = \"Growth Rates\",   subtitle_str = NULL,   factor = NULL,   type_chars = NULL,   periodicity = NULL,   display_ggplot = TRUE,   .setup = TRUE )  GR_table(   graphTable,   title_str = \"Growth Rates Table\",   subtitle_str = NULL,   factor = NULL,   type_chars = NULL,   display_ggplot = TRUE,   .setup = TRUE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a benchmarking graphic — bench_graphs","text":"graphTable (mandatory) Data frame, object coerced one, corresponding benchmarking function output graphTable data frame. title_str, subtitle_str (optional) Graphic title subtitle strings (character constants). subtitle_str automatically built graphTable data frame contents NULL contains graphTable data frame name 2nd line benchmarking parameters 3rd line. Specifying empty strings (\"\") remove titles. Simple Markdown HTML syntax allowed (e.g., bold, italic colored fonts) thanks internal use ggtext package (see help(package = \"ggtext\")). Default values subtitle_str = NULL function specific string title_str (see Usage). mth_gap (optional) Number months consecutive periods (e.g. 1 monthly data, 3 quarterly data, etc.). Based graphTable data frame contents  NULL (calculated 12 / graphTable$periodicity[1]). Default value mth_gap = NULL. points_set, full_set (optional) Character vector elements (variables graphTable data frame) include plot. Automatically built NULL. See plot_graphTable() (default) list variables used type graphic. Default values points_set = NULL full_set = NULL. pt_sz (optional) Size data points shape (symbol) ggplot2. Default value pt_sz = 2. display_ggplot (optional) Logical arguments indicating whether ggplot object(s) displayed current (active) graphics device. Default value display_ggplot = TRUE. .setup (optional) Logical argument indicating whether setup steps must executed . Must TRUE function called directly (.e., outside plot_graphTable() context). Default value .setup = TRUE. factor, type_chars (optional) Growth rates factor (1 100) value label suffix (\"\" \"(%)\") according adjustment model parameter \\(\\lambda\\). Based graphTable data frame contents NULL (based graphTable$lambda[1]). Default values factor = NULL type_chars = NULL. periodicity (optional) Number periods year. Based graphTable data frame contents NULL (defined graphTable$periodicity[1]). Default value periodicity = NULL.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a benchmarking graphic — bench_graphs","text":"addition displaying corresponding graphic(s) current (active) graphics device (except display_ggplot = FALSE), function also invisibly returns list containing generated ggplot object(s). ori_plot() adj_plot() generate single ggplot object (single graphic) GR_plot() GR_table() often generated several ggplot objects (several graphics). returned ggplot object(s) can displayed manually print(), case following ggplot2 theme updates (used internally display_ggplot = TRUE) suggested:","code":"ggplot2::theme_update(   plot.title = ggtext::element_markdown(hjust = 0.5),   plot.subtitle = ggtext::element_markdown(hjust = 0.5),   legend.position = \"bottom\",   plot.margin = ggplot2::margin(t = 1.5, r = 1.5, b = 1.5, l = 1.5, unit = \"cm\"))"},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a benchmarking graphic — bench_graphs","text":"See plot_graphTable() detailed description four benchmarking graphics associated individual functions. graphics optimized US Letter paper size format landscape view, .e., 11in wide (27.9cm, 1056px 96 DPI) 8.5in tall (21.6cm, 816px 96 DPI). Keep mind viewing saving graphics generated calls individual functions (.e., outside plot_graphTable() context). Also note GR_plot() GR_table() often generate one graphic (one page), unless number periods included input graphTable data frame reduced (e.g., subsetting data frame ranges calendar years).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/bench_graphs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a benchmarking graphic — bench_graphs","text":"","code":"# Deactivate the graphics device creation for the pkgdown website HTML reference page # (irrelevant in that context) new_grDev <- !(identical(Sys.getenv(\"IN_PKGDOWN\"), \"true\"))   # Initial quarterly time series (indicator series to be benchmarked) qtr_ts <- ts(c(1.9, 2.4, 3.1, 2.2, 2.0, 2.6, 3.4, 2.4, 2.3),              start = c(2015, 1), frequency = 4)  # Annual time series (benchmarks) ann_ts <- ts(c(10.3, 10.2), start = 2015, frequency = 1)  # Proportional benchmarking out_bench <- benchmarking(ts_to_tsDF(qtr_ts),                           ts_to_bmkDF(ann_ts, ind_frequency = 4),                           rho = 0.729, lambda = 1, biasOption = 3,                           quiet = TRUE)   # Open a new graphics device that is 11in wide and 8.5in tall  # (US Letter paper size format in landscape view) if (new_grDev) {   dev.new(width = 11, height = 8.5, unit = \"in\", noRStudioGD = TRUE) }  # Generate the benchmarking graphics ori_plot(out_bench$graphTable)  adj_plot(out_bench$graphTable)  GR_plot(out_bench$graphTable)  GR_table(out_bench$graphTable)    # Simulate multiple series benchmarking (3 series)  qtr_mts <- ts.union(ser1 = qtr_ts, ser2 = qtr_ts * 100, ser3 = qtr_ts * 10) ann_mts <- ts.union(ser1 = ann_ts, ser2 = ann_ts * 100, ser3 = ann_ts * 10)  # Using argument `allCols = TRUE` (identify series with column `varSeries`) out_bench2 <- benchmarking(ts_to_tsDF(qtr_mts),                            ts_to_bmkDF(ann_mts, ind_frequency = 4),                            rho = 0.729, lambda = 1, biasOption = 3,                            allCols = TRUE,                            quiet = TRUE) #>  #> Benchmarking indicator series [ser1] with benchmarks [ser1] #> ----------------------------------------------------------- #>  #> Benchmarking indicator series [ser2] with benchmarks [ser2] #> ----------------------------------------------------------- #>  #> Benchmarking indicator series [ser3] with benchmarks [ser3] #> -----------------------------------------------------------  # Original and adjustment scale plots for the 2nd series (ser2) ser2_res <- out_bench2$graphTable[out_bench2$graphTable$varSeries == \"ser2\", ] ori_plot(ser2_res)  adj_plot(ser2_res)   # Using argument `by = \"series\"` (identify series with column `series`) out_bench3 <- benchmarking(stack_tsDF(ts_to_tsDF(qtr_mts)),                            stack_bmkDF(ts_to_bmkDF(ann_mts, ind_frequency = 4)),                            rho = 0.729, lambda = 1, biasOption = 3,                            by = \"series\",                            quiet = TRUE) #>  #> Benchmarking by-group 1 (series=ser1) #> ===================================== #>  #> Benchmarking by-group 2 (series=ser2) #> ===================================== #>  #> Benchmarking by-group 3 (series=ser3) #> =====================================                 # Growth rates plot for the 3rd series (ser3) ser3_res <- out_bench3$graphTable[out_bench3$graphTable$series == \"ser3\", ] GR_plot(ser3_res)    # Close the graphics device  if (new_grDev) {   dev.off() }"},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"function used internally tsbalancing() build core elements balancing problems. can also useful derive indirect series associated equality balancing constraints manually (outside tsbalancing() context).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"","code":"build_balancing_problem(   in_ts,   problem_specs_df,   in_ts_name = deparse1(substitute(in_ts)),   ts_freq = stats::frequency(in_ts),   periods = gs.time2str(in_ts),   n_per = nrow(as.matrix(in_ts)),   specs_df_name = deparse1(substitute(problem_specs_df)),   temporal_grp_periodicity = 1,   alter_pos = 1,   alter_neg = 1,   alter_mix = 1,   lower_bound = -Inf,   upper_bound = Inf,   validation_only = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"in_ts (mandatory) Time series (\"ts\" \"mts\"), object coerced one, contains time series data reconciled. balancing problems' input data (initial solutions). problem_specs_df (mandatory) Balancing problem specifications data frame. Using sparse format inspired SAS/\\(^\\circledR\\) LP procedure’s sparse data input format (SAS Institute 2015), contains relevant information nonzero coefficients balancing constraints well non-default alterability coefficients lower/upper bounds (.e., values take precedence defined arguments alter_pos, alter_neg, alter_mix, alter_temporal, lower_bound upper_bound). information provided using four mandatory variables (type, col, row coef) one optional variable (timeVal). observation (row) problem specs data frame either defines label one seven types balancing problem elements columns type row (see Label definition records ) specifies coefficients (numerical values) balancing problem elements variables col, row, coef timeVal (see Information specification records ). Label definition records (type missing (NA)) type (chr): reserved keyword identifying type problem element defined: EQ: equality (\\(=\\)) balancing constraint LE: lower equal (\\(\\le\\)) balancing constraint GE: greater equal (\\(\\ge\\)) balancing constraint lowerBd: period value lower bound upperBd: period value upper bound alter: period values alterability coefficient alterTmp: temporal total alterability coefficient row (chr): label associated problem element (type keyword) variables irrelevant contain missing data (NA values) Information specification records (type missing (NA)) type (chr): applicable (NA) col (chr): series name reserved word _rhs_ specify balancing constraint right-hand side (RHS) value. row (chr): problem element label. coef (num): problem element value: balancing constraint series coefficient RHS value series period value lower upper bound series period value temporal total alterability coefficient timeVal (num): optional time value restrict application series bounds alterability coefficients specific time period (temporal group). corresponds time value, returned stats::time(), given input time series (argument in_ts) period (observation) conceptually equivalent \\(year + (period - 1) /   frequency\\). Note empty strings (\"\" '') character variables interpreted missing (NA) function. Variable row identifies elements balancing problem key variable makes link types records. label (row) associated one type problem element (type) multiple labels (row) defined given type problem element (type), except balancing constraints (values \"EQ\", \"LE\" \"GE\" column type). User-friendly features problem specs data frame include: order observations (rows) important. Character values (variables type, row col) case sensitive (e.g., strings \"Constraint 1\" \"CONSTRAINT 1\" row considered problem element label), except col used specify series name (column input time series object) case sensitivity enforced. variable names problem specs data frame also case sensitive (e.g., type, Type TYPE valid) time_val accepted variable name (instead timeVal). Finally, following table lists valid aliases type keywords (type problem element): Reviewing Examples help conceptualize balancing problem specifications data frame. in_ts_name (optional) String containing value argument in_ts. Default value in_ts_name = deparse1(substitute(in_ts)). ts_freq (optional) Frequency time series object (argument in_ts). Default value ts_freq = stats::frequency(in_ts). periods (optional) Character vector describing time series object (argument in_ts) periods. Default value periods = gs.time2str(in_ts). n_per (optional) Number periods time series object (argument in_ts). Default value n_per = nrow(.matrix(in_ts)). specs_df_name (optional) String containing value argument problem_specs_df. Default value specs_df_name = deparse1(substitute(problem_specs_df)). temporal_grp_periodicity (optional) Positive integer defining number periods temporal groups totals preserved. E.g., specify temporal_grp_periodicity = 3 monthly time series quarterly total preservation temporal_grp_periodicity = 12 (temporal_grp_periodicity = frequency(in_ts)) annual total preservation. Specifying temporal_grp_periodicity = 1 (default) corresponds period--period processing without temporal total preservation. Default value temporal_grp_periodicity = 1 (period--period processing without temporal total preservation). alter_pos (optional) Nonnegative real number specifying default alterability coefficient associated values time series positive coefficients balancing constraints involved (e.g., component series aggregation table raking problems). Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_pos = 1.0 (nonbinding values). alter_neg (optional) Nonnegative real number specifying default alterability coefficient associated values time series negative coefficients balancing constraints involved (e.g., marginal totals aggregation table raking problems). Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_neg = 1.0 (nonbinding values). alter_mix (optional) Nonnegative real number specifying default alterability coefficient associated values time series mix positive negative coefficients balancing constraints involved. Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_mix = 1.0 (nonbinding values). lower_bound (optional) Real number specifying default lower bound time series values. Lower bounds provided problem specification data frame (argument problem_specs_df) override value. Default value lower_bound = -Inf (unbounded). upper_bound (optional) Real number specifying default upper bound time series values. Upper bounds provided problem specification data frame (argument problem_specs_df) override value. Default value upper_bound = Inf (unbounded). validation_only (optional) Logical argument specifying whether function perform input data validation . validation_only = TRUE, specified balancing constraints period value (lower upper) bounds constraints validated input time series data, allowing discrepancies value specified argument validation_tol. Otherwise, validation_only = FALSE (default), input data first reconciled resulting (output) data validated. Default value validation_only = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"list elements balancing problems (excluding temporal totals info): labels_df: cleaned-version label definition records problem_specs_df (type missing (NA)); extra columns: type.lc : tolower(type) row.lc  : tolower(row) con.flag: type.lc %% c(\"eq\", \"le\", \"ge\") coefs_df : cleaned-version information specification records problem_specs_df (type missing (NA); extra columns: row.lc  : tolower(row) con.flag: labels_df$con.flag allocated row.lc values_ts: reduced version 'in_ts' relevant series (see vector ser_names) lb       : lower bound info (type.lc  = \"lowerbd\") relevant series; list object following elements: coefs_ts       : lower bound values series period nondated_coefs : vector nondated lower bounds problem_specs_df (timeVal NA) nondated_id_vec: vector ser_names id's associated vector nondated_coefs dated_id_vec   : vector ser_names id's associated dated lower bounds problem_specs_df (timeVal NA) ub       : lb equivalent upper bounds (type.lc = \"upperbd\") alter    : lb equivalent period value alterability coefficients (type.lc = \"alter\") altertmp : lb equivalent temporal total alterability coefficients (type.lc = \"altertmp\") ser_names: vector relevant series names (set series involved balancing constraints) pos_ser  : vector series names positive nonzero coefficients across balancing constraints neg_ser  : vector series names negative nonzero coefficients across balancing constraints mix_ser  : vector series names positive negative nonzero coefficients across balancing constraints A1,op1,b1: balancing constraint elements problems involving single period (e.g., period incomplete temporal group) A2,op2,b2: balancing constraint elements problems involving temporal_grp_periodicity periods (e.g., set periods complete temporal group)","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"See tsbalancing() detailed description time series balancing problems. missing (NA) value found input time series object (argument in_ts) replaced 0 values_ts trigger warning message. returned elements balancing problems include implicit temporal totals (.e., elements A2, op2 b2 contain balancing constraints). Multi-period balancing problem elements A2, op2 b2 (temporal_grp_periodicity > 1) constructed column column (\"column-major order\"), corresponding default behaviour R converting objects class \"matrix\" vectors. .e., balancing constraints conceptually correspond : A1 %*% values_ts[t, ] op1 b1 problems involving single period (t) A2 %*% .vector(values_ts[t1:t2, ]) op2 b2 problems involving temporal_grp_periodicity periods (t1:t2). Note argument alter_temporal applied yet point altertmp$coefs_ts contains coefficients specified problem specs data frame (argument problem_specs_df). .e., altertmp$coefs_ts contains missing (NA) values except temporal total alterability coefficients included (specified ) problem_specs_df. done order simplify identification first non missing (non NA) temporal total alterability coefficient complete temporal group (occur later, applicable, inside tsbalancing()).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/build_balancing_problem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the core elements (building blocks) for the balancing problems. — build_balancing_problem","text":"","code":"###################################################################################### #        Indirect series derivation framework with `tsbalancing()` metadata ###################################################################################### # # Is is assumed (agreed) that... # # a) All balancing constraints are equality constraints (`type = EQ`). # b) All constraints have only one nonbinding (free) series: the series to be derived #    (i.e., all series have an alter. coef of 0 except the series to be derived). # c) Each constraint derives a different (new) series. # d) Constraints are the same for all periods (i.e., no \"dated\" alter. coefs  #    specified with column `timeVal`). ######################################################################################   # Derive the 5 marginal totals of a 2 x 3 two-dimensional data cube using `tsbalancing()`  # metadata (data cube aggregation constraints respect the above assumptions).   # Build the balancing problem specs through the (simpler) raking metadata. my_specs <- rkMeta_to_blSpecs(   data.frame(series = c(\"A1\", \"A2\", \"A3\",                         \"B1\", \"B2\", \"B3\"),              total1 = c(rep(\"totA\", 3),                         rep(\"totB\", 3)),              total2 = rep(c(\"tot1\", \"tot2\", \"tot3\"), 2)),   alterSeries = 0,  # binding (fixed) component series   alterTotal1 = 1,  # nonbinding (free) marginal totals (to be derived)   alterTotal2 = 1)  # nonbinding (free) marginal totals (to be derived) my_specs #>     type  col                       row coef timeVal #> 1     EQ <NA>   Marginal Total 1 (totA)   NA      NA #> 2   <NA>   A1   Marginal Total 1 (totA)    1      NA #> 3   <NA>   A2   Marginal Total 1 (totA)    1      NA #> 4   <NA>   A3   Marginal Total 1 (totA)    1      NA #> 5   <NA> totA   Marginal Total 1 (totA)   -1      NA #> 6     EQ <NA>   Marginal Total 2 (totB)   NA      NA #> 7   <NA>   B1   Marginal Total 2 (totB)    1      NA #> 8   <NA>   B2   Marginal Total 2 (totB)    1      NA #> 9   <NA>   B3   Marginal Total 2 (totB)    1      NA #> 10  <NA> totB   Marginal Total 2 (totB)   -1      NA #> 11    EQ <NA>   Marginal Total 3 (tot1)   NA      NA #> 12  <NA>   A1   Marginal Total 3 (tot1)    1      NA #> 13  <NA>   B1   Marginal Total 3 (tot1)    1      NA #> 14  <NA> tot1   Marginal Total 3 (tot1)   -1      NA #> 15    EQ <NA>   Marginal Total 4 (tot2)   NA      NA #> 16  <NA>   A2   Marginal Total 4 (tot2)    1      NA #> 17  <NA>   B2   Marginal Total 4 (tot2)    1      NA #> 18  <NA> tot2   Marginal Total 4 (tot2)   -1      NA #> 19    EQ <NA>   Marginal Total 5 (tot3)   NA      NA #> 20  <NA>   A3   Marginal Total 5 (tot3)    1      NA #> 21  <NA>   B3   Marginal Total 5 (tot3)    1      NA #> 22  <NA> tot3   Marginal Total 5 (tot3)   -1      NA #> 23 alter <NA> Period Value Alterability   NA      NA #> 24  <NA>   A1 Period Value Alterability    0      NA #> 25  <NA>   A2 Period Value Alterability    0      NA #> 26  <NA>   A3 Period Value Alterability    0      NA #> 27  <NA>   B1 Period Value Alterability    0      NA #> 28  <NA>   B2 Period Value Alterability    0      NA #> 29  <NA>   B3 Period Value Alterability    0      NA #> 30  <NA> totA Period Value Alterability    1      NA #> 31  <NA> totB Period Value Alterability    1      NA #> 32  <NA> tot1 Period Value Alterability    1      NA #> 33  <NA> tot2 Period Value Alterability    1      NA #> 34  <NA> tot3 Period Value Alterability    1      NA  # 6 periods (quarters) of data with marginal totals set to zero (0): they MUST exist # in the input data AND contain valid (non missing) data. my_ts <- ts(data.frame(A1 = c(12, 10, 12,  9, 15,  7),                        B1 = c(20, 21, 15, 17, 19, 18),                        A2 = c(14,  9,  8,  9, 11, 10),                        B2 = c(20, 29, 20, 24, 21, 17),                        A3 = c(13, 15, 17, 14, 16, 12),                        B3 = c(24, 20, 30, 23, 21, 19),                        tot1 = rep(0, 6),                        tot2 = rep(0, 6),                        tot3 = rep(0, 6),                        totA = rep(0, 6),                        totB = rep(0, 6)),             start = 2019, frequency = 4)  # Get the balancing problem elements. n_per <- nrow(my_ts) p <- build_balancing_problem(my_ts, my_specs,                               temporal_grp_periodicity = n_per)  # `A2`, `op2` and `b2` define 30 constraints (5 marginal totals X 6 periods)  # involving a total of 66 time series data points (11 series X 6 periods) of which  # 36 belong to the 6 component series and 30 belong to the 5 marginal totals. dim(p$A2) #> [1] 30 66  # Get the names of the marginal totals (series with a nonzero alter. coef), in the order  # in which the corresponding constraints appear in the specs (constraints specification  # order). tmp <- p$coefs_df$col[p$coefs_df$con.flag] tot_names <- tmp[tmp %in% p$ser_names[p$alter$nondated_id_vec[p$alter$nondated_coefs != 0]]]  # Define logical flags identifying the marginal total columns: # - `tot_col_logi1`: for single-period elements (of length 11 = number of series) # - `tot_col_logi2`: for multi-period elements (of length 66 = number of data points),  #                    in \"column-major order\" (the `A2` matrix element construction order) tot_col_logi1 <- p$ser_names %in% tot_names tot_col_logi2 <- rep(tot_col_logi1, each = n_per)  # Order of the marginal totals to be derived based on # ... the input data columns (\"mts\" object `my_ts`) p$ser_names[tot_col_logi1] #> [1] \"tot1\" \"tot2\" \"tot3\" \"totA\" \"totB\" # ... the constraints specification (data frame `my_specs`) tot_names #> [1] \"totA\" \"totB\" \"tot1\" \"tot2\" \"tot3\"   # Calculate the 5 marginal totals for all 6 periods # Note: the following calculation allows for general linear equality constraints, i.e., #       a) nonzero right-hand side (RHS) constraint values (`b2`) and  #       b) nonzero constraint coefs other than 1 for the component series and -1 for  #          the derived series. my_ts[, tot_names] <- {   (     # Constraints RHS.     p$b2 -       # Sums of the components (\"weighted\" by the constraint coefficients).     p$A2[, !tot_col_logi2, drop = FALSE] %*% as.vector(p$values_ts[, !tot_col_logi1])   ) /    # Derived series constraint coefficients: `t()` allows for a \"row-major order\" search    # in matrix `A2` (i.e., according to the constraints specification order).   # Note: `diag(p$A2[, tot_col_logi2])` would work if `p$ser_names[tot_col_logi1]` and    #       `tot_names` were identical (same totals order); however, the following search    #       in \"row-major order\" will always work (and is necessary in the current case).   t(p$A2[, tot_col_logi2])[t(p$A2[, tot_col_logi2]) != 0] } my_ts #>         A1 B1 A2 B2 A3 B3 tot1 tot2 tot3 totA totB #> 2019 Q1 12 20 14 20 13 24   32   34   37   39   64 #> 2019 Q2 10 21  9 29 15 20   31   38   35   34   70 #> 2019 Q3 12 15  8 20 17 30   27   28   47   37   65 #> 2019 Q4  9 17  9 24 14 23   26   33   37   32   64 #> 2020 Q1 15 19 11 21 16 21   34   32   37   42   61 #> 2020 Q2  7 18 10 17 12 19   25   27   31   29   54"},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the elements of the raking problem. — build_raking_problem","title":"Build the elements of the raking problem. — build_raking_problem","text":"function used internally tsraking() build elements raking problem. can also useful derive cross-sectional (marginal) totals raking problem manually (outside tsraking() context).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the elements of the raking problem. — build_raking_problem","text":"","code":"build_raking_problem(   data_df,   metadata_df,   data_df_name = deparse1(substitute(data_df)),   metadata_df_name = deparse1(substitute(metadata_df)),   alterability_df = NULL,   alterSeries = 1,   alterTotal1 = 0,   alterTotal2 = 0 )"},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the elements of the raking problem. — build_raking_problem","text":"data_df (mandatory) Data frame, object coerced one, contains time series data reconciled. must minimally contain variables corresponding component series cross-sectional control totals specified metadata data frame (argument metadata_df). one observation (period) provided, sum provided component series values also preserved part implicit temporal constraints. metadata_df (mandatory) Data frame, object coerced one, describes cross-sectional aggregation constraints (additivity rules) raking problem. Two character variables must included metadata data frame: series total1. Two variables optional: total2 (character) alterAnnual (numeric). values variable series represent variable names component series input time series data frame (argument data_df). Similarly, values variables total1 total2 represent variable names 1st 2nd dimension cross-sectional control totals input time series data frame. Variable alterAnnual contains alterability coefficient temporal constraint associated component series. specified, latter override default alterability coefficient specified argument alterAnnual. data_df_name (optional) String containing value argument data_df. Default value data_df_name = deparse1(substitute(data_df)). metadata_df_name (optional) String containing value argument metadata_df. Default value metadata_df_name = deparse1(substitute(metadata_df)). alterability_df (optional) Data frame, object coerced one, NULL, contains alterability coefficients variables. must correspond component series cross-sectional control total, , variable name must exist input time series data frame (argument data_df). values alterability coefficients override default alterability coefficients specified arguments alterSeries, alterTotal1 alterTotal2. input time series data frame contains several observations alterability coefficients data frame contains one, alterability coefficients used (repeated) observations input time series data frame. Alternatively, alterability coefficients data frame may contain many observations input time series data frame. Default value alterability_df = NULL (default alterability coefficients). alterSeries (optional) Nonnegative real number specifying default alterability coefficient component series values. apply component series alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterSeries = 1.0 (nonbinding component series values). alterTotal1 (optional) Nonnegative real number specifying default alterability coefficient 1st dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal1 = 0.0 (binding 1st dimension cross-sectional control totals) alterTotal2 (optional) Nonnegative real number specifying default alterability coefficient 2nd dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal2 = 0.0 (binding 2nd dimension cross-sectional control totals).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the elements of the raking problem. — build_raking_problem","text":"list elements raking problem (excluding implicit temporal totals): x        : vector component series initial values c_x      : vector component series alterability coefficients comp_cols: vector component series (column) names g        : vector cross-sectional total initial values c_g      : vector cross-sectional total alterability coefficients tot_cols : vector cross-sectional total (column) names G        : cross-sectional total aggregation matrix (g = G %*% x)","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build the elements of the raking problem. — build_raking_problem","text":"See tsraking() detailed description time series raking problems. returned raking problem elements include implicit component series temporal totals applicable (.e., elements g G contain cross-sectional totals info). input data contains multiple periods (temporal total preservation scenario), raking problem elements x, c_x, g, c_g G constructed column column (\"column-major order\"), corresponding default behaviour R converting objects class \"matrix\" vectors.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/build_raking_problem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the elements of the raking problem. — build_raking_problem","text":"","code":"# Derive the 5 marginal totals of a 2 x 3 two-dimensional data cube using `tsraking()`  # metadata.  my_metadata <- data.frame(series = c(\"A1\", \"A2\", \"A3\",                                      \"B1\", \"B2\", \"B3\"),                           total1 = c(rep(\"totA\", 3),                                      rep(\"totB\", 3)),                           total2 = rep(c(\"tot1\", \"tot2\", \"tot3\"), 2)) my_metadata #>   series total1 total2 #> 1     A1   totA   tot1 #> 2     A2   totA   tot2 #> 3     A3   totA   tot3 #> 4     B1   totB   tot1 #> 5     B2   totB   tot2 #> 6     B3   totB   tot3  # 6 periods of data with marginal totals set to `NA` (they MUST exist in the input data  # but can be `NA`). my_data <- data.frame(A1 = c(12, 10, 12,  9, 15,  7),                       B1 = c(20, 21, 15, 17, 19, 18),                       A2 = c(14,  9,  8,  9, 11, 10),                       B2 = c(20, 29, 20, 24, 21, 17),                       A3 = c(13, 15, 17, 14, 16, 12),                       B3 = c(24, 20, 30, 23, 21, 19),                       tot1 = rep(NA, 6),                       tot2 = rep(NA, 6),                       tot3 = rep(NA, 6),                       totA = rep(NA, 6),                       totB = rep(NA, 6))  # Get the raking problem elements. p <- build_raking_problem(my_data, my_metadata) str(p) #> List of 7 #>  $ x        : num [1:36] 12 10 12 9 15 7 14 9 8 9 ... #>  $ c_x      : num [1:36] 1 1 1 1 1 1 1 1 1 1 ... #>  $ comp_cols: chr [1:6] \"A1\" \"A2\" \"A3\" \"B1\" ... #>  $ g        : logi [1:30] NA NA NA NA NA NA ... #>  $ c_g      : num [1:30] 0 0 0 0 0 0 0 0 0 0 ... #>  $ tot_cols : chr [1:5] \"totA\" \"totB\" \"tot1\" \"tot2\" ... #>  $ G        : num [1:30, 1:36] 1 0 0 0 0 0 0 0 0 0 ...  # Calculate the 5 marginal totals for all 6 periods. my_data[p$tot_cols] <- p$G %*% p$x my_data #>   A1 B1 A2 B2 A3 B3 tot1 tot2 tot3 totA totB #> 1 12 20 14 20 13 24   32   34   37   39   64 #> 2 10 21  9 29 15 20   31   38   35   34   70 #> 3 12 15  8 20 17 30   27   28   47   37   65 #> 4  9 17  9 24 14 23   26   33   37   32   64 #> 5 15 19 11 21 16 21   34   32   37   42   61 #> 6  7 18 10 17 12 19   25   27   31   29   54"},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":null,"dir":"Reference","previous_headings":"","what":"Build reconciliation processing groups — gs.build_proc_grps","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"function builds processing groups data frame reconciliation problems. used internally tsraking_driver() tsbalancing().","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"","code":"gs.build_proc_grps(   ts_yr_vec,   ts_per_vec,   n_per,   ts_freq,   temporal_grp_periodicity,   temporal_grp_start )"},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"ts_yr_vec (mandatory) Vector time series year (time unit) values (see gs.time2year()). ts_per_vec (mandatory) Vector time series period (cycle) values (see gs.time2per()). n_per (mandatory) Time series length (number periods). ts_freq (mandatory) Time series frequency (see stats::frequency()). temporal_grp_periodicity (mandatory) Number periods temporal groups. temporal_grp_start (mandatory) First period temporal groups.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"data frame following variables (columns): grp         : integer vector identifying processing group (1 .. < total number groups >) beg_per     : integer vector identifying first period processing group (1 .. n_per) end_per     : integer vector identifying last period processing group (1 .. n_per) complete_grp: logical vector indicating processing group corresponds complete temporal group","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":"processing-groups","dir":"Reference","previous_headings":"","what":"Processing groups","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"set periods given reconciliation (raking balancing) problem called processing group either corresponds : single period period--period processing , preserving temporal totals, individual periods incomplete temporal group (e.g., incomplete year) set periods complete temporal group (e.g., complete year) preserving temporal totals. total number processing groups (total number reconciliation problems) depends set periods input time series object (argument in_ts) value arguments temporal_grp_periodicity temporal_grp_start. Common scenarios include temporal_grp_periodicity = 1 (default) period-period processing without temporal total preservation temporal_grp_periodicity = frequency(in_ts) preservation annual totals (calendar years default). Argument temporal_grp_start allows specification types (non-calendar) years. E.g., fiscal years starting April correspond temporal_grp_start = 4 monthly data temporal_grp_start = 2 quarterly data. Preserving quarterly totals monthly data correspond temporal_grp_periodicity = 3. default, temporal groups covering year (.e., corresponding temporal_grp_periodicity > frequency(in_ts) start year multiple  ceiling(temporal_grp_periodicity / frequency(in_ts)). E.g., biennial groups corresponding temporal_grp_periodicity = 2 * frequency(in_ts) start even year default. behaviour can changed argument temporal_grp_start. E.g., preservation biennial totals starting odd year instead even year (default) corresponds temporal_grp_start = frequency(in_ts) + 1 (along temporal_grp_periodicity = 2 * frequency(in_ts)). See gs.build_proc_grps() Examples common processing group scenarios.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.build_proc_grps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build reconciliation processing groups — gs.build_proc_grps","text":"","code":"####### # Preliminary setup  # Dummy monthly and quarterly time series (2.5 years long) mth_ts <- ts(rep(NA, 30), start = c(2019, 1), frequency = 12) mth_ts #>      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #> 2019  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA #> 2020  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA #> 2021  NA  NA  NA  NA  NA  NA                         qtr_ts <- ts(rep(NA, 10), start = c(2019, 1), frequency = 4) qtr_ts #>      Qtr1 Qtr2 Qtr3 Qtr4 #> 2019   NA   NA   NA   NA #> 2020   NA   NA   NA   NA #> 2021   NA   NA            # Summarized time series info ts_info <- function(ts, sep = \"-\") {   list(y = gs.time2year(ts),      # years        p = gs.time2per(ts),       # periods        n = length(ts),            # length        f = frequency(ts),         # frequency        l = gs.time2str(ts, sep))  # labels } mth_info <- ts_info(mth_ts) qtr_info <- ts_info(qtr_ts, sep = \"q\")  # Function to add a description label for the processing group add_desc <- function(grp_df, lab_vec, word) {   grp_df$description <- ifelse(grp_df$complete_grp,                                paste0(\"--- \", grp_df$end_per - grp_df$beg_per + 1, \" \", word, \"s: \",                                       lab_vec[grp_df$beg_per], \" to \",                                       lab_vec[grp_df$end_per], \" --- \"),                                paste0(\"--- 1 \", word, \": \", lab_vec[grp_df$beg_per], \" ---\"))   grp_df }     ####### # Common processing group scenarios for monthly data   # 0- Month-by-month processing (every single month is a processing group) mth_grps0 <- gs.build_proc_grps(mth_info$y, mth_info$p, mth_info$n, mth_info$f,                                 temporal_grp_periodicity = 1,                                 temporal_grp_start = 1) tmp <- add_desc(mth_grps0, mth_info$l, word = \"month\") head(tmp) #>   grp beg_per end_per complete_grp             description #> 1   1       1       1        FALSE --- 1 month: 2019-1 --- #> 2   2       2       2        FALSE --- 1 month: 2019-2 --- #> 3   3       3       3        FALSE --- 1 month: 2019-3 --- #> 4   4       4       4        FALSE --- 1 month: 2019-4 --- #> 5   5       5       5        FALSE --- 1 month: 2019-5 --- #> 6   6       6       6        FALSE --- 1 month: 2019-6 --- tail(tmp) #>    grp beg_per end_per complete_grp             description #> 25  25      25      25        FALSE --- 1 month: 2021-1 --- #> 26  26      26      26        FALSE --- 1 month: 2021-2 --- #> 27  27      27      27        FALSE --- 1 month: 2021-3 --- #> 28  28      28      28        FALSE --- 1 month: 2021-4 --- #> 29  29      29      29        FALSE --- 1 month: 2021-5 --- #> 30  30      30      30        FALSE --- 1 month: 2021-6 ---   # Temporal groups corresponding to ...  # 1- calendar years mth_grps1 <- gs.build_proc_grps(mth_info$y, mth_info$p, mth_info$n, mth_info$f,                                 temporal_grp_periodicity = 12,                                 temporal_grp_start = 1) add_desc(mth_grps1, mth_info$l, word = \"month\") #>   grp beg_per end_per complete_grp                           description #> 1   1       1      12         TRUE --- 12 months: 2019-1 to 2019-12 ---  #> 2   2      13      24         TRUE --- 12 months: 2020-1 to 2020-12 ---  #> 3   3      25      25        FALSE               --- 1 month: 2021-1 --- #> 4   4      26      26        FALSE               --- 1 month: 2021-2 --- #> 5   5      27      27        FALSE               --- 1 month: 2021-3 --- #> 6   6      28      28        FALSE               --- 1 month: 2021-4 --- #> 7   7      29      29        FALSE               --- 1 month: 2021-5 --- #> 8   8      30      30        FALSE               --- 1 month: 2021-6 ---  # 2- fiscal years starting on April mth_grps2 <- gs.build_proc_grps(mth_info$y, mth_info$p, mth_info$n, mth_info$f,                                 temporal_grp_periodicity = 12,                                 temporal_grp_start = 4) add_desc(mth_grps2, mth_info$l, word = \"month\") #>   grp beg_per end_per complete_grp                          description #> 1   1       1       1        FALSE              --- 1 month: 2019-1 --- #> 2   2       2       2        FALSE              --- 1 month: 2019-2 --- #> 3   3       3       3        FALSE              --- 1 month: 2019-3 --- #> 4   4       4      15         TRUE --- 12 months: 2019-4 to 2020-3 ---  #> 5   5      16      27         TRUE --- 12 months: 2020-4 to 2021-3 ---  #> 6   6      28      28        FALSE              --- 1 month: 2021-4 --- #> 7   7      29      29        FALSE              --- 1 month: 2021-5 --- #> 8   8      30      30        FALSE              --- 1 month: 2021-6 ---  # 3- regular quarters (starting on Jan, Apr, Jul and Oct) mth_grps3 <- gs.build_proc_grps(mth_info$y, mth_info$p, mth_info$n, mth_info$f,                                 temporal_grp_periodicity = 3,                                 temporal_grp_start = 1) add_desc(mth_grps3, mth_info$l, word = \"month\") #>    grp beg_per end_per complete_grp                           description #> 1    1       1       3         TRUE   --- 3 months: 2019-1 to 2019-3 ---  #> 2    2       4       6         TRUE   --- 3 months: 2019-4 to 2019-6 ---  #> 3    3       7       9         TRUE   --- 3 months: 2019-7 to 2019-9 ---  #> 4    4      10      12         TRUE --- 3 months: 2019-10 to 2019-12 ---  #> 5    5      13      15         TRUE   --- 3 months: 2020-1 to 2020-3 ---  #> 6    6      16      18         TRUE   --- 3 months: 2020-4 to 2020-6 ---  #> 7    7      19      21         TRUE   --- 3 months: 2020-7 to 2020-9 ---  #> 8    8      22      24         TRUE --- 3 months: 2020-10 to 2020-12 ---  #> 9    9      25      27         TRUE   --- 3 months: 2021-1 to 2021-3 ---  #> 10  10      28      30         TRUE   --- 3 months: 2021-4 to 2021-6 ---   # 4- quarters shifted by one month (starting on Feb, May, Aug and Nov) mth_grps4 <- gs.build_proc_grps(mth_info$y, mth_info$p, mth_info$n, mth_info$f,                                 temporal_grp_periodicity = 3,                                 temporal_grp_start = 2) add_desc(mth_grps4, mth_info$l, word = \"month\") #>    grp beg_per end_per complete_grp                          description #> 1    1       1       1        FALSE              --- 1 month: 2019-1 --- #> 2    2       2       4         TRUE  --- 3 months: 2019-2 to 2019-4 ---  #> 3    3       5       7         TRUE  --- 3 months: 2019-5 to 2019-7 ---  #> 4    4       8      10         TRUE --- 3 months: 2019-8 to 2019-10 ---  #> 5    5      11      13         TRUE --- 3 months: 2019-11 to 2020-1 ---  #> 6    6      14      16         TRUE  --- 3 months: 2020-2 to 2020-4 ---  #> 7    7      17      19         TRUE  --- 3 months: 2020-5 to 2020-7 ---  #> 8    8      20      22         TRUE --- 3 months: 2020-8 to 2020-10 ---  #> 9    9      23      25         TRUE --- 3 months: 2020-11 to 2021-1 ---  #> 10  10      26      28         TRUE  --- 3 months: 2021-2 to 2021-4 ---  #> 11  11      29      29        FALSE              --- 1 month: 2021-5 --- #> 12  12      30      30        FALSE              --- 1 month: 2021-6 ---     ####### # Common processing group scenarios for quarterly data   # 0- Quarter-by-quarter processing (every single quarter is a processing group) qtr_grps0 <- gs.build_proc_grps(qtr_info$y, qtr_info$p, qtr_info$n, qtr_info$f,                                 temporal_grp_periodicity = 1,                                 temporal_grp_start = 1) add_desc(qtr_grps0, qtr_info$l, word = \"quarter\") #>    grp beg_per end_per complete_grp               description #> 1    1       1       1        FALSE --- 1 quarter: 2019q1 --- #> 2    2       2       2        FALSE --- 1 quarter: 2019q2 --- #> 3    3       3       3        FALSE --- 1 quarter: 2019q3 --- #> 4    4       4       4        FALSE --- 1 quarter: 2019q4 --- #> 5    5       5       5        FALSE --- 1 quarter: 2020q1 --- #> 6    6       6       6        FALSE --- 1 quarter: 2020q2 --- #> 7    7       7       7        FALSE --- 1 quarter: 2020q3 --- #> 8    8       8       8        FALSE --- 1 quarter: 2020q4 --- #> 9    9       9       9        FALSE --- 1 quarter: 2021q1 --- #> 10  10      10      10        FALSE --- 1 quarter: 2021q2 ---   # Temporal groups corresponding to ...  # 1- calendar years qtr_grps1 <- gs.build_proc_grps(qtr_info$y, qtr_info$p, qtr_info$n, qtr_info$f,                                 temporal_grp_periodicity = 4,                                 temporal_grp_start = 1) add_desc(qtr_grps1, qtr_info$l, word = \"quarter\") #>   grp beg_per end_per complete_grp                           description #> 1   1       1       4         TRUE --- 4 quarters: 2019q1 to 2019q4 ---  #> 2   2       5       8         TRUE --- 4 quarters: 2020q1 to 2020q4 ---  #> 3   3       9       9        FALSE             --- 1 quarter: 2021q1 --- #> 4   4      10      10        FALSE             --- 1 quarter: 2021q2 ---  # 2- fiscal years starting on April (2nd quarter) qtr_grps2 <- gs.build_proc_grps(qtr_info$y, qtr_info$p, qtr_info$n, qtr_info$f,                                 temporal_grp_periodicity = 4,                                 temporal_grp_start = 2) add_desc(qtr_grps2, qtr_info$l, word = \"quarter\") #>   grp beg_per end_per complete_grp                           description #> 1   1       1       1        FALSE             --- 1 quarter: 2019q1 --- #> 2   2       2       5         TRUE --- 4 quarters: 2019q2 to 2020q1 ---  #> 3   3       6       9         TRUE --- 4 quarters: 2020q2 to 2021q1 ---  #> 4   4      10      10        FALSE             --- 1 quarter: 2021q2 ---"},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":null,"dir":"Reference","previous_headings":"","what":"Moore-Penrose inverse — gs.gInv_MP","title":"Moore-Penrose inverse — gs.gInv_MP","text":"function calculates Moore-Penrose (pseudo) inverse square rectangular matrix using Singular Value Decomposition (SVD). used internally tsraking() benchmarking().","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moore-Penrose inverse — gs.gInv_MP","text":"","code":"gs.gInv_MP(X, tol = NA)"},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moore-Penrose inverse — gs.gInv_MP","text":"X (mandatory) Matrix invert. tol (optional) Real number specifies tolerance identifying zero singular values. tol = NA (default), tolerance calculated product size (dimension) matrix, norm matrix (largest singular value) machine epsilon (.Machine$double.eps). Default value tol = NA.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moore-Penrose inverse — gs.gInv_MP","text":"Moore-Penrose (pseudo) inverse matrix X.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Moore-Penrose inverse — gs.gInv_MP","text":"default tolerance (argument tol = NA) coherent tolerance used MATLAB GNU Octave software general inverse functions. testing, default tolerance also produced solutions (results) comparable G-Series 2.0 SAS\\(^\\circledR\\).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/gs.gInv_MP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moore-Penrose inverse — gs.gInv_MP","text":"","code":"# Invertible matrix X1 <- matrix(c(3, 2, 8,                 6, 3, 2,                5, 2, 4), nrow = 3, byrow = TRUE) Y1 <- gs.gInv_MP(X1) all.equal(Y1, solve(X1)) #> [1] TRUE X1 %*% Y1 #>               [,1]          [,2]         [,3] #> [1,]  1.000000e+00 -1.110223e-15 3.885781e-15 #> [2,] -2.220446e-16  1.000000e+00 1.748601e-15 #> [3,] -8.881784e-16 -8.881784e-16 1.000000e+00  # Rectangular matrix X2 <- X1[-1, ] try(solve(X2)) #> Error in solve.default(X2) : 'a' (2 x 3) must be square X2 %*% gs.gInv_MP(X2) #>               [,1]         [,2] #> [1,]  1.000000e+00 1.110223e-16 #> [2,] -4.440892e-16 1.000000e+00  # Non-invertible square matrix X3 <- matrix(c(3, 0, 0,                 0, 0, 0,                 0, 0, 4), nrow = 3, byrow = TRUE) try(solve(X3)) #> Error in solve.default(X3) :  #>   Lapack routine dgesv: system is exactly singular: U[2,2] = 0 X3 %*% gs.gInv_MP(X3) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    0    0 #> [3,]    0    0    1"},{"path":"https://ferlmic.github.io/gstest/en/reference/gstest-package.html","id":null,"dir":"Reference","previous_headings":"","what":"gstest: (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' — gstest-package","title":"gstest: (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' — gstest-package","text":"(EN) Statistics Canada's generalized system devoted time series benchmarking reconciliation. methods used 'G-Series' essentially come Dagum Cholette (2006) doi:10.1007/0-387-35439-5 . | (FR) Système généralisé de Statistique Canada consacré à l'étalonnage et à la réconciliation de séries chronologiques. Les méthodes utilisées dans 'G-Séries' proviennent essentiellement de Dagum et Cholette (2006) doi:10.1007/0-387-35439-5 .","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/gstest-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gstest: (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' — gstest-package","text":"Maintainer: Michel Ferland michel.ferland@statcan.gc.ca contributors: Statistics Canada [copyright holder, funder]","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/osqp_settings_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"OSQP settings sequence data frame — osqp_settings_sequence","title":"OSQP settings sequence data frame — osqp_settings_sequence","text":"Data frame containing sequence OSQP settings tsbalancing() specified argument osqp_settings_df. package includes two predefined OSQP settings sequence data frames: default_osqp_sequence: fast effective (default osqp_settings_df argument value); alternate_osqp_sequence: geared towards precision expense execution time. See vignette(\"osqp-settings-sequence-dataframe\") actual contents data frames.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/osqp_settings_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OSQP settings sequence data frame — osqp_settings_sequence","text":"","code":"# Default sequence: # tsbalancing(..., osqp_settings_df = default_osqp_sequence)  # Alternative (slower) sequence: # tsbalancing(..., osqp_settings_df = alternate_osqp_sequence)  # Custom-made sequence: # tsbalancing(..., osqp_settings_df = <my-osqp-sequence-data-frame>)  # Single sequence consisting of the default OSQP settings (not recommended!): # tsbalancing(..., osqp_settings_df = NULL)"},{"path":"https://ferlmic.github.io/gstest/en/reference/osqp_settings_sequence.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"OSQP settings sequence data frame — osqp_settings_sequence","text":"data frame least one row least one column, common columns : max_iter Maximum number iterations (integer) sigma Alternating direction method multipliers (ADMM) sigma step (double) eps_abs Absolute tolerance (double) eps_rel Relative tolerance (double) eps_prim_inf Primal infeasibility tolerance (double) eps_dual_inf Dual infeasibility tolerance (double) polish Perform solution polishing (logical) scaling Number scaling iterations (integer) prior_scaling Scale problem data prior solving OSQP (logical) require_polished Require polished solution stop sequence (logical) [--OSQP-setting] Value corresponding OSQP setting","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/osqp_settings_sequence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"OSQP settings sequence data frame — osqp_settings_sequence","text":"exception prior_scaling require_polished, columns data frame must correspond OSQP setting. Default OSQP values used setting specified data frame. Visit https://osqp.org/docs/interfaces/solver_settings.html available OSQP settings. Note OSQP verbose setting actually controlled tsbalancing() arguments quiet display_level (.e., column verbose OSQP settings sequence data frame ignored). row OSQP settings sequence data frame represents one attempt solving balancing problem corresponding OSQP settings. solving sequence stops soon valid solution obtained (solution constraint discrepancies smaller equal tolerance specified tsbalancing() argument validation_tol) unless column require_polished = TRUE, case polished solution OSQP (status_polish = 1) also required stop sequence. Constraint discrepancies correspond \\(\\mathrm{max}(0, l - Ax, Ax - u)\\) constraints defined \\(l \\le Ax \\le u\\). event satisfactory solution obtained gone entire sequence, tsbalancing() returns solution generated smallest total constraint discrepancies among valid solutions, , among solutions, otherwise. Note running entire solving sequence can enforced specifying tsbalancing() argument full_sequence = TRUE. Rows column prior_scaling = TRUE problem data scaled prior solving OSQP, using average free (nonbinding) problem values scaling factor. addition specifying custom-made OSQP settings sequence data frame argument osqp_settings_df, one can also specify osqp_settings_df = NULL result single solving attempt default OSQP values settings along prior_scaling = FALSE require_polished = FALSE. Note recommended, however, first try data frames default_osqp_sequence alternate_osqp_sequence, along full_sequence = TRUE necessary, considering alternatives. Vignette OSQP Settings Sequence Data Frame (vignette(\"osqp-settings-sequence-dataframe\")) contains additional information.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot benchmarking adjustments — plot_benchAdj","title":"Plot benchmarking adjustments — plot_benchAdj","text":"Plot benchmarking adjustments single series current (active) graphics device. three types adjustments can overlayed plot: Adjustments generated function benchmarking() Adjustments generated function stock_benchmarking() Cubic spline associated adjustments generated function stock_benchmarking() plots can useful assess quality benchmarking results compare adjustments generated benchmarking functions (benchmarking() stock_benchmarking()) stock series.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot benchmarking adjustments — plot_benchAdj","text":"","code":"plot_benchAdj(   PB_graphTable = NULL,   SB_graphTable = NULL,   SB_splineKnots = NULL,   legendPos = \"bottomright\" )"},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot benchmarking adjustments — plot_benchAdj","text":"PB_graphTable (optional) Data frame, object coerced one, corresponding benchmarking() (PB \"Proc Benchmarking\" approach) function output graphTable data frame. Specify NULL include benchmarking() adjustments plot. Default value PB_graphTable = NULL. SB_graphTable (optional) Data frame, object coerced one, corresponding stock_benchmarking() (SB) function output graphTable data frame. Specify NULL include stock_benchmarking() adjustments plot. Default value SB_graphTable = NULL. SB_splineKnots (optional) Data frame, object coerced one, corresponding stock_benchmarking() (SB) function output splineKnots data frame. Specify NULL include stock_benchmarking() cubic spline plot. Default value SB_splineKnots = NULL. legendPos (optional) String (keyword) specifying location legend plot. See description argument x documentation graphics::legend() list valid keywords. Specify NULL include legend plot. Default value legendPos = \"bottomright\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot benchmarking adjustments — plot_benchAdj","text":"function returns nothing (invisible(NULL)).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot benchmarking adjustments — plot_benchAdj","text":"graphTable data frame (arguments PB_graphTable SB_graphTable) variables used plot: t x-axis values (t) benchmarkedSubAnnualRatio Stock Bench. (SB) Proc Bench. (PB) lines bias Bias line (\\(\\rho < 1\\)) splineKnots data frame (argument SB_splineKnots) variables used plot: x x-axis values (t) y Cubic spline line Extra knot Original knot points extraKnot type knot (Extra knot vs. Original knot) See section Value benchmarking() stock_benchmarking() details data frames.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_benchAdj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot benchmarking adjustments — plot_benchAdj","text":"","code":"####### # Preliminary setup  # Quarterly stocks (same annual pattern repeated for 7 years) qtr_ts <- ts(rep(c(85, 95, 125, 95), 7), start = c(2013, 1), frequency = 4)  # End-of-year stocks ann_ts <- ts(c(135, 125, 155, 145, 165), start = 2013, frequency = 1)  # Proportional benchmarking # ... with `benchmarking()` (\"Proc Benchmarking\" approach) out_PB <- benchmarking(   ts_to_tsDF(qtr_ts),    ts_to_bmkDF(ann_ts, discrete_flag = TRUE, alignment = \"e\", ind_frequency = 4),   rho = 0.729, lambda = 1, biasOption = 3,   quiet = TRUE) # ... with `stock_benchmarking()` out_SB <- stock_benchmarking(   ts_to_tsDF(qtr_ts),    ts_to_bmkDF(ann_ts, discrete_flag = TRUE, alignment = \"e\", ind_frequency = 4),   rho = 0.729, lambda = 1, biasOption = 3,   quiet = TRUE)   ####### # Plot the benchmarking adjustments  # `benchmarking()` adjustments (`out_PB`), without a legend plot_benchAdj(PB_graphTable = out_PB$graphTable,               legendPos = NULL)   # Add the `stock_benchmarking()` (`out_SB`) adjustments, with a legend this time plot_benchAdj(PB_graphTable = out_PB$graphTable,               SB_graphTable = out_SB$graphTable)   # Add the `stock_benchmarking()` cubic spline actually used to generate the adjustments # (incl. the extra knots at both ends), with the legend located in the top-left corner plot_benchAdj(PB_graphTable = out_PB$graphTable,               SB_graphTable = out_SB$graphTable,               SB_splineKnots = out_SB$splineKnots,               legendPos = \"topleft\")    ####### # Simulate multiple series benchmarking (3 stock series)  qtr_mts <- ts.union(ser1 = qtr_ts, ser2 = qtr_ts * 100, ser3 = qtr_ts * 10) ann_mts <- ts.union(ser1 = ann_ts, ser2 = ann_ts * 100, ser3 = ann_ts * 10)  # Using argument `allCols = TRUE` (identify stocks with column `varSeries`) out_SB2 <- stock_benchmarking(   ts_to_tsDF(qtr_mts),   ts_to_bmkDF(ann_mts, discrete_flag = TRUE, alignment = \"e\", ind_frequency = 4),   rho = 0.729, lambda = 1, biasOption = 3,   allCols = TRUE,   quiet = TRUE) #>  #> Benchmarking indicator series [ser1] with benchmarks [ser1] #> ----------------------------------------------------------- #>  #> Benchmarking indicator series [ser2] with benchmarks [ser2] #> ----------------------------------------------------------- #>  #> Benchmarking indicator series [ser3] with benchmarks [ser3] #> -----------------------------------------------------------  # Adjustments for 2nd stock (ser2) plot_benchAdj(   SB_graphTable = out_SB2$graphTable[out_SB2$graphTable$varSeries == \"ser2\", ])   # Using argument `by = \"series\"` (identify stocks with column `series`) out_SB3 <- stock_benchmarking(   stack_tsDF(ts_to_tsDF(qtr_mts)),   stack_bmkDF(ts_to_bmkDF(     ann_mts, discrete_flag = TRUE, alignment = \"e\", ind_frequency = 4)),   rho = 0.729, lambda = 1, biasOption = 3,   by = \"series\",   quiet = TRUE) #>  #> Benchmarking by-group 1 (series=ser1) #> ===================================== #>  #> Benchmarking by-group 2 (series=ser2) #> ===================================== #>  #> Benchmarking by-group 3 (series=ser3) #> =====================================  # Cubic spline for 3nd stock (ser3) plot_benchAdj(   SB_splineKnots = out_SB3$splineKnots[out_SB3$splineKnots$series == \"ser3\", ])"},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate benchmarking graphics in a PDF file — plot_graphTable","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"Create PDF file (US Letter paper size format landscape view) containing benchmarking graphics set series contained specified benchmarking function (benchmarking() stock_benchmarking()) output graphTable data frame (argument graphTable). Four types benchmarking graphics can generated series: Original Scale Plot (argument ori_plot_flag) - overlay graph : Indicator series Average indicator series Bias corrected indicator series (\\(\\rho < 1\\)) Benchmarked series Average benchmark Adjustment Scale Plot (argument adj_plot_flag) - overlay graph : Benchmarking adjustments Average benchmarking adjustments Bias line (\\(\\rho < 1\\)) Growth Rates Plot (argument GR_plot_flag) - bar chart indicator benchmarked series growth rates. Growth Rates Table (argument GR_table_flag) - table indicator benchmarked series growth rates. graphics can useful assess quality benchmarking results. four types benchmarking graphics can enabled disabled corresponding flag. first three types graphics (plots) generated default fourth (growth rates table) .","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"","code":"plot_graphTable(   graphTable,   pdf_file,   ori_plot_flag = TRUE,   adj_plot_flag = TRUE,   GR_plot_flag = TRUE,   GR_table_flag = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"graphTable (mandatory) Data frame, object coerced one, corresponding benchmarking function output graphTable data frame. pdf_file (mandatory) Name (path) PDF file contain benchmarking graphics. name include \".pdf\" file extension. PDF file created R session working directory (returned getwd()) path specified. Specifying NULL cancel creation PDF file. ori_plot_flag, adj_plot_flag, GR_plot_flag, GR_table_flag (optional) Logical arguments indicating whether corresponding type benchmarking graphic generated. three plots generated default growth rates tables. Default values ori_plot_flag = TRUE, adj_plot_flag = TRUE, GR_plot_flag = TRUE GR_table_flag = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"addition creating PDF file containing benchmarking graphics (except pdf_file = NULL), function also invisibly returns list following elements: pdf_name: Character string (character vector length one) contains complete name path PDF file successfully created invisible(NA_character_) otherwise pdf_file = NULL specified. graph_list: List generated benchmarking graphics (one per series) following elements: name: Character string describing series (matches bookmark name PDF file). page: Integer representing sequence number first graphic series entire sequence graphics series (matches page number PDF file). ggplot_list: List ggplot objects (one per graphic page PDF file) corresponding generated benchmarking graphics series. See section Value bench_graphs details. Note returned ggplot objects can displayed manually print(), case updates ggplot2 theme defaults recommended order produce graphics similar look feel generated PDF file (see section Value bench_graphs details). Also keep mind graphics optimized US Letter paper size format landscape view (displayed PDF file), .e., 11in wide (27.9cm, 1056px 96 DPI) 8.5in tall (21.6cm, 816px 96 DPI).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"List graphTable data frame (argument graphTable) variables corresponding element four types benchmarking graphics: Original Scale Plot (argument ori_plot_flag) subAnnual Indicator Series line avgSubAnnual Avg. Indicator Series segments subAnnualCorrected Bias Corr. Indicator Series line (\\(\\rho < 1\\)) benchmarked Benchmarked Series line avgBenchmark Average Benchmark segments Adjustment Scale Plot (argument adj_plot_flag) benchmarkedSubAnnualRatio BI Ratios (Benchmarked Series / Indicator Series) line \\(^{(*)}\\) avgBenchmarkSubAnnualRatio Average BI Ratios segments \\(^{(*)}\\) bias Bias line (\\(\\rho < 1\\)) Growth Rates Plot (argument GR_plot_flag) growthRateSubAnnual Growth R. Indicator Series bars \\(^{(*)}\\) growthRateBenchmarked Growth R. Benchmarked Series bars \\(^{(*)}\\) Growth Rates Table (argument GR_table_flag) year Year column period Period column subAnnual Indicator Series column benchmarked Benchmarked Series column growthRateSubAnnual Growth Rate Indicator Series column \\(^{(*)}\\) growthRateBenchmarked Growth Rate Benchmarked Series column \\(^{(*)}\\) \\(^{(*)}\\) BI ratios growth rates actually correspond differences \\(\\lambda = 0\\) (additive benchmarking). function uses extra columns graphTable data frame (columns listed Value section benchmarking() stock_benchmarking()), , build -groups. See section Benchmarking Multiple Series benchmarking() details.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"performance","dir":"Reference","previous_headings":"","what":"Performance","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"two types growth rates graphics, .e., bar chart (GR_plot_flag) table (GR_table_flag), often requires generation several pages PDF file, especially long monthly series several years data. creation extra pages slows execution plot_graphTable(). bar chart generated default (GR_plot_flag = TRUE GR_table_flag = FALSE). Deactivating types growth rates graphics (GR_plot_flag = FALSE GR_table_flag = FALSE) reducing size input graphTable data frame long series (e.g., keeping recent years) therefore improve execution time. Also note impact benchmarking growth rates can deduced adjustment scale plot (adj_plot_flag) examining extent vertical movement (downward upward) benchmarking adjustments adjacent periods: greater vertical movement, greater impact corresponding growth rate. Execution time plot_graphTable() therefore reduced, needed, generating first two types graphics focusing adjustment scale plot assess period--period movement preservation, .e., impact benchmarking initial growth rates.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"ggplot-themes","dir":"Reference","previous_headings":"","what":"ggplot2 themes","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"plots generated ggplot2 package comes convenient set complete themes general look feel plots (theme_grey() default theme). Use function theme_set() change theme applied plots generated plot_graphTable() (see Examples).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"bookmarks","dir":"Reference","previous_headings":"","what":"Bookmarks","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"Bookmarks added PDF file xmpdf::set_bookmarks(), requires command-line tool Ghostscript  PDFtk. See section Installation vignette(\"xmpdf\", package = \"xmpdf\") details. Important: bookmarks successfully added PDF file xmpdf::supports_set_bookmarks() returns TRUE. Ghostscript installed machine xmpdf::supports_set_bookmarks() still returns FALSE, try specifying path Ghostscript executable environment variable R_GSCMD (e.g., Sys.setenv(R_GSCMD =  \"C:/Program Files/.../bin/gswin64c.exe\") Windows).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/plot_graphTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate benchmarking graphics in a PDF file — plot_graphTable","text":"","code":"# Set the working directory (for the PDF files) iniwd <- getwd()  setwd(tempdir())  # Quarterly car and van sales (indicator series) qtr_ind <- ts_to_tsDF(   ts(matrix(c(# Car sales               1851, 2436, 3115, 2205, 1987, 2635, 3435, 2361, 2183, 2822,               3664, 2550, 2342, 3001, 3779, 2538, 2363, 3090, 3807, 2631,               2601, 3063, 3961, 2774, 2476, 3083, 3864, 2773, 2489, 3082,               # Van sales               1900, 2200, 3000, 2000, 1900, 2500, 3800, 2500, 2100, 3100,               3650, 2950, 3300, 4000, 3290, 2600, 2010, 3600, 3500, 2100,               2050, 3500, 4290, 2800, 2770, 3080, 3100, 2800, 3100, 2860),             ncol = 2),      start = c(2011, 1),      frequency = 4,      names = c(\"car_sales\", \"van_sales\")))  # Annual car and van sales (benchmarks) ann_bmk <- ts_to_bmkDF(   ts(matrix(c(# Car sales               10324, 10200, 10582, 11097, 11582, 11092,               # Van sales               12000, 10400, 11550, 11400, 14500, 16000),             ncol = 2),      start = 2011,      frequency = 1,      names = c(\"car_sales\", \"van_sales\")),    ind_frequency = 4)  # Proportional benchmarking without bias correction out_bench <- benchmarking(qtr_ind, ann_bmk,                            rho = 0.729, lambda = 1, biasOption = 1,                           allCols = TRUE,                           quiet = TRUE) #>  #> Benchmarking indicator series [car_sales] with benchmarks [car_sales] #> --------------------------------------------------------------------- #>  #> Benchmarking indicator series [van_sales] with benchmarks [van_sales] #> ---------------------------------------------------------------------   # Default set of graphics (the 3 types of plots) plot_graphTable(out_bench$graphTable, \"bench_graphs.pdf\") #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 2 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\bench_graphs.pdf  # Temporarily use ggplot2 `theme_bw()` for the plots library(ggplot2) #> Warning: package 'ggplot2' was built under R version 4.4.3 ini_theme <- theme_get() theme_set(theme_bw()) plot_graphTable(out_bench$graphTable, \"bench_graphs_bw.pdf\") #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 2 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\bench_graphs_bw.pdf theme_set(ini_theme)  # Generate all 4 types of graphics (including the growth rates table) plot_graphTable(out_bench$graphTable, \"bench_graphs_with_GRTable.pdf\",                 GR_table_flag = TRUE) #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 2 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\bench_graphs_with_GRTable.pdf  # Reduce execution time by disabling both types of growth rates graphics plot_graphTable(out_bench$graphTable, \"bench_graphs_no_GR.pdf\",                 GR_plot_flag = FALSE) #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 2 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\bench_graphs_no_GR.pdf   # Reset the working directory to its initial location setwd(iniwd)"},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert reconciliation metadata — rkMeta_to_blSpecs","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"Convert tsraking() metadata data frame tsbalancing() problem specs data frame.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"","code":"rkMeta_to_blSpecs(   metadata_df,   alterability_df = NULL,   alterSeries = 1,    alterTotal1 = 0,   alterTotal2 = 0,   alterability_df_only = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"metadata_df (mandatory) Data frame, object coerced one, describes cross-sectional aggregation constraints (additivity rules) raking problem. Two character variables must included metadata data frame: series total1. Two variables optional: total2 (character) alterAnnual (numeric). values variable series represent variable names component series input time series data frame (argument data_df). Similarly, values variables total1 total2 represent variable names 1st 2nd dimension cross-sectional control totals input time series data frame. Variable alterAnnual contains alterability coefficient temporal constraint associated component series. specified, latter override default alterability coefficient specified argument alterAnnual. alterability_df (optional) Data frame, object coerced one, NULL, contains alterability coefficients variables. must correspond component series cross-sectional control total, , variable name must exist input time series data frame (argument data_df). values alterability coefficients override default alterability coefficients specified arguments alterSeries, alterTotal1 alterTotal2. input time series data frame contains several observations alterability coefficients data frame contains one, alterability coefficients used (repeated) observations input time series data frame. Alternatively, alterability coefficients data frame may contain many observations input time series data frame. Default value alterability_df = NULL (default alterability coefficients). alterSeries (optional) Nonnegative real number specifying default alterability coefficient component series values. apply component series alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterSeries = 1.0 (nonbinding component series values). alterTotal1 (optional) Nonnegative real number specifying default alterability coefficient 1st dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal1 = 0.0 (binding 1st dimension cross-sectional control totals) alterTotal2 (optional) Nonnegative real number specifying default alterability coefficient 2nd dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal2 = 0.0 (binding 2nd dimension cross-sectional control totals). alterability_df_only (optional) Logical argument specifying whether set alterability ceofficients found alterability file (argument alterability_df) included returned tsbalancing() problem specs data frame. alterability_df_only = FALSE (default), alterability coefficients specified arguments alterSeries, alterTotal1 alterTotal2 combined found alterability_df (latter coefficients overwriting former) returned data frame therefore contains alterability coefficients component cross-sectional control total series. argument affect set temporal total alterability coefficients (associated tsraking() argument alterAnnual) included returned tsbalancing() problem specs data frame. latter always strictly contains specified metadata_df non-missing (non-NA) value column alterAnnual. Default value alterability_df_only = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"tsbalancing() problem specs data frame (argument problem_specs_df).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"preceding description argument alterability_df comes tsraking(). function (rkMeta_to_blSpecs()) slightly changes specification alterability coefficients argument alterability_df allowing either single observation, specifying set alterability coefficients use periods, one several observations additional column named timeVal allowing specification period-specific alterability coefficients (timeVal NA) generic coefficients use periods (timeVal NA). Values column timeVal correspond time values \"ts\" object returned stats::time(), conceptually corresponding \\(year + (period - 1) / frequency\\). Another difference tsraking() missing (NA) values allowed alterability coefficients data frame (argument alterability_df) result using generic coefficients (observations timeVal NA) default coefficients (arguments alterSeries, alterTotal1 alterTotal2). Note apart discarding alterability coefficients series listed tsraking() metadata data frame (argument metadata_df), function validate values specified alterability coefficients data frame (argument alterability_df) ones specified column alterAnnual tsraking() metadata data frame (argument metadata_df). function transfers returned tsbalancing() problem specs data frame.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/rkMeta_to_blSpecs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert reconciliation metadata — rkMeta_to_blSpecs","text":"","code":"# `tsraking()` metadata for a 2-dimensional raking problem (2 x 2 table) my_metadata <- data.frame(series = c(\"A1\", \"A2\", \"B1\", \"B2\"),                           total1 = c(\"totA\", \"totA\", \"totB\", \"totB\"),                           total2 = c(\"tot1\", \"tot2\", \"tot1\", \"tot2\")) my_metadata #>   series total1 total2 #> 1     A1   totA   tot1 #> 2     A2   totA   tot2 #> 3     B1   totB   tot1 #> 4     B2   totB   tot2   # Convert to `tsbalancing()` specifications  # Include the default `tsraking()` alterability coefficients rkMeta_to_blSpecs(my_metadata) #>     type  col                       row coef timeVal #> 1     EQ <NA>   Marginal Total 1 (totA)   NA      NA #> 2   <NA>   A1   Marginal Total 1 (totA)    1      NA #> 3   <NA>   A2   Marginal Total 1 (totA)    1      NA #> 4   <NA> totA   Marginal Total 1 (totA)   -1      NA #> 5     EQ <NA>   Marginal Total 2 (totB)   NA      NA #> 6   <NA>   B1   Marginal Total 2 (totB)    1      NA #> 7   <NA>   B2   Marginal Total 2 (totB)    1      NA #> 8   <NA> totB   Marginal Total 2 (totB)   -1      NA #> 9     EQ <NA>   Marginal Total 3 (tot1)   NA      NA #> 10  <NA>   A1   Marginal Total 3 (tot1)    1      NA #> 11  <NA>   B1   Marginal Total 3 (tot1)    1      NA #> 12  <NA> tot1   Marginal Total 3 (tot1)   -1      NA #> 13    EQ <NA>   Marginal Total 4 (tot2)   NA      NA #> 14  <NA>   A2   Marginal Total 4 (tot2)    1      NA #> 15  <NA>   B2   Marginal Total 4 (tot2)    1      NA #> 16  <NA> tot2   Marginal Total 4 (tot2)   -1      NA #> 17 alter <NA> Period Value Alterability   NA      NA #> 18  <NA>   A1 Period Value Alterability    1      NA #> 19  <NA>   A2 Period Value Alterability    1      NA #> 20  <NA>   B1 Period Value Alterability    1      NA #> 21  <NA>   B2 Period Value Alterability    1      NA #> 22  <NA> totA Period Value Alterability    0      NA #> 23  <NA> totB Period Value Alterability    0      NA #> 24  <NA> tot1 Period Value Alterability    0      NA #> 25  <NA> tot2 Period Value Alterability    0      NA  # Almost binding 1st marginal totals (small alter. coef for columns `totA` and `totB`) tail(rkMeta_to_blSpecs(my_metadata, alterTotal1 = 1e-6)) #>    type  col                       row  coef timeVal #> 20 <NA>   B1 Period Value Alterability 1e+00      NA #> 21 <NA>   B2 Period Value Alterability 1e+00      NA #> 22 <NA> totA Period Value Alterability 1e-06      NA #> 23 <NA> totB Period Value Alterability 1e-06      NA #> 24 <NA> tot1 Period Value Alterability 0e+00      NA #> 25 <NA> tot2 Period Value Alterability 0e+00      NA  # Do not include alterability coefficients (aggregation constraints only) rkMeta_to_blSpecs(my_metadata, alterability_df_only = TRUE) #>    type  col                     row coef timeVal #> 1    EQ <NA> Marginal Total 1 (totA)   NA      NA #> 2  <NA>   A1 Marginal Total 1 (totA)    1      NA #> 3  <NA>   A2 Marginal Total 1 (totA)    1      NA #> 4  <NA> totA Marginal Total 1 (totA)   -1      NA #> 5    EQ <NA> Marginal Total 2 (totB)   NA      NA #> 6  <NA>   B1 Marginal Total 2 (totB)    1      NA #> 7  <NA>   B2 Marginal Total 2 (totB)    1      NA #> 8  <NA> totB Marginal Total 2 (totB)   -1      NA #> 9    EQ <NA> Marginal Total 3 (tot1)   NA      NA #> 10 <NA>   A1 Marginal Total 3 (tot1)    1      NA #> 11 <NA>   B1 Marginal Total 3 (tot1)    1      NA #> 12 <NA> tot1 Marginal Total 3 (tot1)   -1      NA #> 13   EQ <NA> Marginal Total 4 (tot2)   NA      NA #> 14 <NA>   A2 Marginal Total 4 (tot2)    1      NA #> 15 <NA>   B2 Marginal Total 4 (tot2)    1      NA #> 16 <NA> tot2 Marginal Total 4 (tot2)   -1      NA  # With an alterability coefficients file (argument `alterability_df`) my_alter = data.frame(B2 = 0.5) tail(rkMeta_to_blSpecs(my_metadata, alterability_df = my_alter)) #>    type  col                       row coef timeVal #> 20 <NA>   B1 Period Value Alterability  1.0      NA #> 21 <NA>   B2 Period Value Alterability  0.5      NA #> 22 <NA> totA Period Value Alterability  0.0      NA #> 23 <NA> totB Period Value Alterability  0.0      NA #> 24 <NA> tot1 Period Value Alterability  0.0      NA #> 25 <NA> tot2 Period Value Alterability  0.0      NA  # Only include the alterability coefficients from `alterability_df`  # (i.e., for column `B2` only) tail(rkMeta_to_blSpecs(my_metadata, alterability_df = my_alter,                        alterability_df_only = TRUE)) #>     type  col                       row coef timeVal #> 13    EQ <NA>   Marginal Total 4 (tot2)   NA      NA #> 14  <NA>   A2   Marginal Total 4 (tot2)  1.0      NA #> 15  <NA>   B2   Marginal Total 4 (tot2)  1.0      NA #> 16  <NA> tot2   Marginal Total 4 (tot2) -1.0      NA #> 17 alter <NA> Period Value Alterability   NA      NA #> 18  <NA>   B2 Period Value Alterability  0.5      NA"},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_bmkDF.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack benchmarks data — stack_bmkDF","title":"Stack benchmarks data — stack_bmkDF","text":"Convert multivariate benchmarks data frame (see ts_to_bmkDF()) benchmarking functions (benchmarking() stock_benchmarking()) stacked (tall) data frame six variables (columns): one (1) benchmark name (e.g., series name) four (4) benchmark coverage one (1) benchmark value Missing (NA) benchmark values included output stacked data frame default. Specify argument keep_NA = TRUE order keep . function useful intending use argument (-group processing mode) benchmarking functions order benchmark multiple series single function call.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_bmkDF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack benchmarks data — stack_bmkDF","text":"","code":"stack_bmkDF(   bmk_df,   ser_cName = \"series\",   startYr_cName = \"startYear\",   startPer_cName = \"startPeriod\",   endYr_cName = \"endYear\",   endPer_cName = \"endPeriod\",   val_cName = \"value\",   keep_NA = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_bmkDF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack benchmarks data — stack_bmkDF","text":"bmk_df (mandatory) Data frame, object coerced one, contains multivariate benchmarks stacked. ser_cName (optional) String specifying name character variable (column) output stacked data frame contain benchmark names (name benchmark variables input multivariate benchmarks data frame). variable can used -group variable (argument ) benchmarking functions. Default value ser_cName = \"series\". startYr_cName, startPer_cName, endYr_cName, endPer_cName (optional) Strings specifying name numeric variables (columns) input multivariate benchmarks data frame define benchmark coverage, .e., starting ending year period (cycle) identifiers. variables transferred output stacked data frame variable names. Default values startYr_cName = \"startYear\", startPer_cName = \"startPeriod\" endYr_cName = \"endYear\" endPer_cName   = \"endPeriod\". val_cName (optional) String specifying name numeric variable (column) output stacked data frame contain benchmark values. Default value val_cName = \"value\". keep_NA (optional) Logical argument specifying whether missing (NA) benchmark values input multivariate benchmarks data frame kept output stacked data frame. Default value keep_NA = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_bmkDF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack benchmarks data — stack_bmkDF","text":"function returns data frame six variables: Benchmark (series) name, type character (see argument ser_cName) Benchmark coverage starting year, type numeric (see argument startYr_cName) Benchmark coverage starting period, type numeric (see argument startPer_cName) Benchmark coverage ending year, type numeric (see argument endtYr_cName) Benchmark coverage ending period, type numeric (see argument endPer_cName) Benchmark value, type numeric (see argument val_cName) Note: function returns \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_bmkDF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack benchmarks data — stack_bmkDF","text":"","code":"# Create an annual benchmarks data frame for 2 quarterly indicator series  # (with missing benchmark values for the last 2 years) my_benchmarks <- ts_to_bmkDF(ts(data.frame(ser1 = c(1:3 *  10, NA, NA),                                             ser2 = c(1:3 * 100, NA, NA)),                                  start = c(2019, 1), frequency = 1),                              ind_frequency = 4) my_benchmarks #>   startYear startPeriod endYear endPeriod ser1 ser2 #> 1      2019           1    2019         4   10  100 #> 2      2020           1    2020         4   20  200 #> 3      2021           1    2021         4   30  300 #> 4      2022           1    2022         4   NA   NA #> 5      2023           1    2023         4   NA   NA   # Stack the benchmarks ...  # discarding `NA` values in the output stacked data frame (default behavior) stack_bmkDF(my_benchmarks) #>   series startYear startPeriod endYear endPeriod value #> 1   ser1      2019           1    2019         4    10 #> 2   ser1      2020           1    2020         4    20 #> 3   ser1      2021           1    2021         4    30 #> 4   ser2      2019           1    2019         4   100 #> 5   ser2      2020           1    2020         4   200 #> 6   ser2      2021           1    2021         4   300  # keep `NA` values in the output stacked data frame stack_bmkDF(my_benchmarks, keep_NA = TRUE) #>    series startYear startPeriod endYear endPeriod value #> 1    ser1      2019           1    2019         4    10 #> 2    ser1      2020           1    2020         4    20 #> 3    ser1      2021           1    2021         4    30 #> 4    ser1      2022           1    2022         4    NA #> 5    ser1      2023           1    2023         4    NA #> 6    ser2      2019           1    2019         4   100 #> 7    ser2      2020           1    2020         4   200 #> 8    ser2      2021           1    2021         4   300 #> 9    ser2      2022           1    2022         4    NA #> 10   ser2      2023           1    2023         4    NA  # using custom variable (column) names stack_bmkDF(my_benchmarks, ser_cName = \"bmk_name\", val_cName = \"bmk_val\") #>   bmk_name startYear startPeriod endYear endPeriod bmk_val #> 1     ser1      2019           1    2019         4      10 #> 2     ser1      2020           1    2020         4      20 #> 3     ser1      2021           1    2021         4      30 #> 4     ser2      2019           1    2019         4     100 #> 5     ser2      2020           1    2020         4     200 #> 6     ser2      2021           1    2021         4     300"},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_tsDF.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack time series data — stack_tsDF","title":"Stack time series data — stack_tsDF","text":"Convert multivariate time series data frame (see ts_to_tsDF()) benchmarking functions (benchmarking() stock_benchmarking()) stacked (tall) data frame four variables (columns): one (1) series name two (2) data point identification (year period) one (1) data point value Missing (NA) series values included output stacked data frame default. Specify argument keep_NA = TRUE order keep . function useful intending use argument (-group processing mode) benchmarking functions order benchmark multiple series single function call.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_tsDF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack time series data — stack_tsDF","text":"","code":"stack_tsDF(   ts_df,   ser_cName = \"series\",   yr_cName = \"year\",   per_cName = \"period\",   val_cName = \"value\",   keep_NA = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_tsDF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack time series data — stack_tsDF","text":"ts_df (mandatory) Data frame, object coerced one, contains multivariate time series data stacked. ser_cName (optional) String specifying name character variable (column) output stacked data frame contain series names (name time series variables input multivariate time series data frame). variable can used -group variable (argument ) benchmarking functions. Default value ser_cName = \"series\". yr_cName, per_cName (optional) Strings specifying name numeric variables (columns) input multivariate time series data frame contain data point year period (cycle) identifiers. variables transferred output stacked data frame variable names. Default values yr_cName = \"year\" per_cName   = \"period\". val_cName (optional) String specifying name numeric variable (column) output stacked data frame contain data point values. Default value val_cName = \"value\". keep_NA (optional) Logical argument specifying whether NA time series values input multivariate time series data frame kept output stacked data frame. Default value keep_NA = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_tsDF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack time series data — stack_tsDF","text":"function returns data frame four variables: Series name, type character (see argument ser_cName) Data point year, type numeric (see argument yr_cName) Data point period, type numeric (see argument per_cName) Data point value, type numeric (see argument val_cName) Note: function returns \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/stack_tsDF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack time series data — stack_tsDF","text":"","code":"# Create a data frame with 2 quarterly indicators series # (with missing values for the last 2 quarters) my_indicators <- ts_to_tsDF(ts(data.frame(ser1 = c(1:5 *  10, NA, NA),                                           ser2 = c(1:5 * 100, NA, NA)),                                 start = c(2019, 1), frequency = 4)) my_indicators #>   year period ser1 ser2 #> 1 2019      1   10  100 #> 2 2019      2   20  200 #> 3 2019      3   30  300 #> 4 2019      4   40  400 #> 5 2020      1   50  500 #> 6 2020      2   NA   NA #> 7 2020      3   NA   NA   # Stack the indicator series ...  # discarding `NA` values in the output stacked data frame (default behavior) stack_tsDF(my_indicators) #>    series year period value #> 1    ser1 2019      1    10 #> 2    ser1 2019      2    20 #> 3    ser1 2019      3    30 #> 4    ser1 2019      4    40 #> 5    ser1 2020      1    50 #> 6    ser2 2019      1   100 #> 7    ser2 2019      2   200 #> 8    ser2 2019      3   300 #> 9    ser2 2019      4   400 #> 10   ser2 2020      1   500  # keeping `NA` values in the output stacked data frame stack_tsDF(my_indicators, keep_NA = TRUE) #>    series year period value #> 1    ser1 2019      1    10 #> 2    ser1 2019      2    20 #> 3    ser1 2019      3    30 #> 4    ser1 2019      4    40 #> 5    ser1 2020      1    50 #> 6    ser1 2020      2    NA #> 7    ser1 2020      3    NA #> 8    ser2 2019      1   100 #> 9    ser2 2019      2   200 #> 10   ser2 2019      3   300 #> 11   ser2 2019      4   400 #> 12   ser2 2020      1   500 #> 13   ser2 2020      2    NA #> 14   ser2 2020      3    NA  # using custom variable (column) names stack_tsDF(my_indicators, ser_cName = \"ser_name\", val_cName = \"ser_val\") #>    ser_name year period ser_val #> 1      ser1 2019      1      10 #> 2      ser1 2019      2      20 #> 3      ser1 2019      3      30 #> 4      ser1 2019      4      40 #> 5      ser1 2020      1      50 #> 6      ser2 2019      1     100 #> 7      ser2 2019      2     200 #> 8      ser2 2019      3     300 #> 9      ser2 2019      4     400 #> 10     ser2 2020      1     500"},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore temporal constraints for stock series — stock_benchmarking","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"Function specifically aimed benchmarking stock series benchmarks anchor points covering single period indicator series. Benchmarks covering one period indicator series used function. Function benchmarking() used instead benchmark non-stock series (flows). Several stock series can benchmarked single function call. Note functions stock_benchmarking() benchmarking() mainly share arguments return type object. Differences listed : Argument verbose defined stock_benchmarking(). Extra arguments defined stock_benchmarking(): low_freq_periodicity n_low_freq_proj proj_knots_rho_bd list returned stock_benchmarking() contains extra (fourth) data frame: splineKnots See section Details information similarities differences functions stock_benchmarking() benchmarking(). direct equivalent stock_benchmarking() exist SAS\\(^\\circledR\\) G-Series 2.0.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"","code":"stock_benchmarking(   series_df,   benchmarks_df,   rho,   lambda,   biasOption,   bias = NA,   low_freq_periodicity = NA,   n_low_freq_proj = 1,   proj_knots_rho_bd = 0.995,   tolV = 0.001,   tolP = NA,   warnNegResult = TRUE,   tolN = -0.001,   var = \"value\",   with = NULL,   by = NULL,   constant = 0,   negInput_option = 0,   allCols = FALSE,   quiet = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"series_df (mandatory) Data frame, object coerced one, contains indicator time series data benchmarked. addition series data variable(s), specified argument var, data frame must also contain two numeric variables, year period, identifying periods indicator time series. benchmarks_df (mandatory) Data frame, object coerced one, contains benchmarks. addition benchmarks data variable(s), specified argument , data frame must also contain four numeric variables, startYear, startPeriod, endYear endPeriod, identifying indicator time series periods covered benchmark. rho (mandatory) Real number \\([0,1]\\) interval specifies value autoregressive parameter \\(\\rho\\). See section Details information effect parameter \\(\\rho\\). lambda (mandatory) Real number, suggested values \\([-3,3]\\) interval, specifies value adjustment model parameter \\(\\lambda\\). Typical values lambda = 0.0 additive model lambda = 1.0 proportional model. biasOption (mandatory) Specification bias estimation option: 1: estimate bias. bias used correct indicator series value specified argument bias. 2: Estimate bias, display result, use . bias used correct indicator series value specified argument bias. 3: Estimate bias, display result use estimated bias correct indicator series. value specified argument bias ignored. Argument biasOption ignored rho = 1.0. See section Details information bias. bias (optional) Real number, NA, specifying value user-defined bias used correction indicator series prior benchmarking. bias added indicator series additive model (argument  lambda = 0.0) multiplied otherwise (argument lambda != 0.0). bias correction applied bias = NA, equivalent specifying bias = 0.0 lambda = 0.0 bias = 1.0 otherwise. Argument bias ignored biasOption = 3 rho = 1.0. See section Details information bias. Default value bias = NA (user-defined bias). low_freq_periodicity (optional) Positive integer representing number periods defining low (e.g., benchmarks) frequency adding extra spline knots (first benchmark last benchmark). example, low_freq_periodicity = 3 monthly indicators define quarterly knots. Annual knots added low_freq_periodicity = NA. Default value low_freq_periodicity = NA (annual knots). n_low_freq_proj (optional) Nonnegative integer representing number low frequency knots (defined argument low_freq_periodicity) add ends (first benchmark last benchmark) starting add high (indicator series) frequency knots. Default value n_low_freq_proj = 1. proj_knots_rho_bd (optional) Bound applies value specified argument rho determines type extra knots added ends (first benchmark last benchmark). rho > proj_knots_rho_bd, high (indicator series) frequency knots used right away. Otherwise, rho <= proj_knots_rho_bd, low frequency knots (see arguments low_freq_periodicity n_low_freq_proj) first projected either side. Note quarterly stocks, cube specified proj_knots_rho_bd value actually used. Therefore, value argument proj_knots_rho_bd correspond monthly stock indicators; internally adjusted quarterly stocks. argument aims reaching compromise set periods outside () provided benchmarks (anchor points), .e., Denton-type (straight line) adjustments rho approaches 1 (rho > proj_knots_rho_bd) natural looking (overly contorted) spline otherwise (rho <= proj_knots_rho_bd). Section Details contains information subject illustrative cases provided section Examples. Default value proj_knots_rho_bd = 0.995 (\\(0.995^3\\) quarterly stock indicators). tolV, tolP (optional) Nonnegative real number, NA, specifying tolerance, absolute value percentage, used validation output binding benchmarks (alterability coefficient \\(0.0\\)). validation compares input binding benchmark values equivalent values calculated benchmarked series (output) data. Arguments tolV tolP specified (one must specified must NA). Example: set tolerance 10 units, specify tolV = 10, tolP = NA; set tolerance 1%, specify tolV = NA, tolP = 0.01. Default values tolV = 0.001 tolP = NA. warnNegResult (optional) Logical argument specifying whether warning message generated negative value created function benchmarked (output) series smaller threshold specified argument tolN. Default value warnNegResult = TRUE. tolN (optional) Negative real number specifying threshold identification negative values. value considered negative smaller threshold. Default value tolN = -0.001. var (optional) String vector (minimum length 1) specifying variable name(s) indicator series data frame (argument series_df) containing values (optionally) user-defined alterability coefficients series benchmarked. variables must numeric. syntax var = c(\"series1 <\/ alt_ser1>\", \"series2 <\/ alt_ser2>\", ...). Default alterability coefficients \\(1.0\\) used user-defined alterability coefficients variable specified alongside indicator series variable. See section Details information alterability coefficients. Example: var = \"value / alter\" benchmark indicator series data frame variable value alterability coefficients contained variable alter var = c(\"value / alter\", \"value2\") additionally benchmark variable value2 default alterability coefficients \\(1.0\\). Default value var = \"value\" (benchmark variable value using default alterability coefficients \\(1.0\\)). (optional) String vector (length argument var), NULL, specifying variable name(s) benchmarks data frame (argument benchmarks_df) containing values (optionally) user-defined alterability coefficients benchmarks. variables must numeric. Specifying = NULL results using benchmark variable(s) names(s) specified argument var without user-defined benchmark alterability coefficients (.e., default alterability coefficients \\(0.0\\) corresponding binding benchmarks). syntax = NULL = c(\"bmk1 <\/ alt_bmk1>\", \"bmk2 <\/ alt_bmk2>\", ...). Default alterability coefficients \\(0.0\\) (binding benchmarks) used user-defined alterability coefficients variable specified alongside benchmark variable. See section Details information alterability coefficients. Example: = \"val_bmk\" use benchmarks data frame variable val_bmk default benchmark alterability coefficients \\(0.0\\) benchmark indicator series = c(\"val_bmk\", \"val_bmk2 / alt_bmk2\") additionally benchmark second indicator series using benchmark variable val_bmk2 benchmark alterability coefficients contained variable alt_bmk2. Default value = NULL (benchmark variable(s) argument var using default benchmark alterability coefficients \\(0.0\\)). (optional) String vector (minimum length 1), NULL, specifying variable name(s) input data frames (arguments series_df benchmarks_df) used form groups (-group processing) allow benchmarking multiple series single function call. -group variables can numeric character (factors ), must present input data frames appear three output data frames (see section Value). -group processing  implemented = NULL. See \"Benchmarking Multiple Series\" section Details information. Default value = NULL (-group processing). constant (optional) Real number specifies value temporarily added indicator series benchmarks solving proportional benchmarking problems (lambda != 0.0). temporary constant removed final output benchmarked series. E.g., specifying (small) constant allow proportional benchmarking rho = 1 (e.g., proportional Denton benchmarking) indicator series include values 0. Otherwise, proportional benchmarking values 0 indicator series possible rho < 1. Specifying constant additive benchmarking (lambda = 0.0) impact resulting benchmarked data. data variables graphTable output data frame include constant, corresponding benchmarking problem actually solved. Default value constant = 0 (temporary additive constant). negInput_option (optional) Handling negative values input data proportional benchmarking (lambda != 0.0): 0: allow negative values proportional benchmarking. error message displayed presence negative values input indicator series benchmarks missing (NA) values returned benchmarked series. corresponds G-Series 2.0 behaviour. 1: Allow negative values proportional benchmarking display warning message. 2: Allow negative values proportional benchmarking without displaying message. Default value negInput_option = 0 (allow negative values proportional benchmarking). allCols (optional) Logical argument specifying whether variables indicator series data frame (argument series_df), year period, determine set series benchmark. Values specified arguments var ignored allCols = TRUE, automatically implies default alterability coefficients, variables names indicator series must exist benchmarks data frame (argument benchmarks_df). Default value allCols = FALSE. quiet (optional) Logical argument specifying whether display essential information warning messages, error messages variable (series) -group information multiple series benchmarked single call function. advise wrapping benchmarking() call suppressMessages() suppress display variable (series) -group information processing multiple series make troubleshooting difficult case issues individual series. Note specifying quiet = TRUE also nullify argument verbose. Default value quiet = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"function returns list four data frames: series: data frame containing benchmarked data (primary function output). -group variables specified argument included data frame alterability coefficient variables specified argument var. benchmarks: copy input benchmarks data frame (excluding invalid benchmarks applicable). -group variables specified argument included data frame alterability coefficient variables specified argument . graphTable: data frame containing supplementary data useful produce analytical tables graphs (see function plot_graphTable()). contains following variables addition -group variables specified argument : varSeries: Name indicator series variable varBenchmarks: Name benchmark variable altSeries: Name user-defined indicator series alterability coefficients variable altSeriesValue: Indicator series alterability coefficients altbenchmarks: Name user-defined benchmark alterability coefficients variable altBenchmarksValue: Benchmark alterability coefficients t: Indicator series period identifier (1 \\(T\\)) m: Benchmark coverage periods identifier (1 \\(M\\)) year: Data point calendar year period: Data point period (cycle) value (1 periodicity) rho: Autoregressive parameter \\(\\rho\\) (argument rho) lambda: Adjustment model parameter \\(\\lambda\\) (argument lambda) bias: Bias adjustment (default, user-defined estimated bias according arguments biasOption bias) periodicity: maximum number periods year (e.g. 4 quarterly indicator series) date: Character string combining values variables year period subAnnual: Indicator series values benchmarked: Benchmarked series values avgBenchmark: Benchmark values divided number coverage periods avgSubAnnual: Indicator series values (variable subAnnual) averaged benchmark coverage period subAnnualCorrected: Bias corrected indicator series values benchmarkedSubAnnualRatio: Difference (\\(\\lambda = 0\\)) ratio (\\(\\lambda \\ne 0\\)) values variables benchmarked subAnnual avgBenchmarkSubAnnualRatio: Difference (\\(\\lambda = 0\\)) ratio (\\(\\lambda \\ne 0\\)) values variables avgBenchmark avgSubAnnual growthRateSubAnnual: Period period difference (\\(\\lambda = 0\\)) relative difference (\\(\\lambda \\ne 0\\)) indicator series values (variable subAnnual) growthRateBenchmarked: Period period difference (\\(\\lambda = 0\\)) relative difference (\\(\\lambda \\ne 0\\)) benchmarked series values (variable benchmarked) splineKnots: set x y coordinates (knots) used estimate natural cubic spline function stats::spline(). addition original set knots corresponding binding benchmarks (anchor points), extra knots also added beginning end order deal benchmarking timeliness issue approximate slope=0 spline ends (see section Details). contains following variables addition -group variables specified argument : varSeries: Name indicator series variable varBenchmarks: Name benchmark variable x: Cubic spline x coordinate y: Cubic spline y coordinate extraKnot: Logical value identifying extra knots added beginning end Rows extraKnot == FALSE correspond rows graphTable output data frame m missing (NA), x = t y = benchmarkedSubAnnualRatio. Notes: output benchmarks data frame always contains original benchmarks provided input benchmarks data frame. Modified nonbinding benchmarks, applicable, can recovered (calculated) output series data frame. function returns NULL object error occurs data processing start. Otherwise, execution gets far enough data processing start, incomplete object returned case errors (e.g., output series data frame NA values benchmarked data). function returns \"data.frame\" objects can explicitly coerced types objects appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"comparison-with-benchmarking-","dir":"Reference","previous_headings":"","what":"Comparison with benchmarking()","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"stock series, benchmarking() known produce breaks benchmarking adjustments periods corresponding benchmark stocks (anchor points). stock_benchmarking() addresses issue working directly benchmarking adjustments. Smooth adjustments stocks ensured estimating slope=0 cubic spline (spline flat end knots) going knots corresponding difference (argument lambda = 0.0) ratio (otherwise) benchmarks (anchor points) corresponding indicator series values. knots sometimes referred BI (Benchmark--Indicator) differences BI ratios. Interpolations estimated cubic spline provide adjustments periods benchmarks. Arguments rho, lambda, biasOptionand bias play similar role benchmarking(). However, note stock_benchmarking(), argument rho affects results periods outside , around , first last benchmarks lambda takes two values practice: lambda = 0.0 additive adjustments (spline interpolations knots BI differences) lambda = 1.0 multiplicative adjustments (spline interpolations knots BI ratios). nonzero value lambda return result lambda = 1.0. Alterability coefficients also play similar role benchmarking() default values, .e., \\(1.0\\) indicator series (nonbinding values) \\(0.0\\) benchmarks (binding benchmarks). However, similar argument lambda, alterability coefficients function take two values practice: \\(0.0\\) binding values \\(1.0\\) nonbinding values. nonzero alterability coefficient return result coefficient \\(1.0\\). Another difference benchmarking() user-defined alterability coefficients allowed even rho = 1 stock_benchmarking(). Finally, specifying nonbinding benchmark stock_benchmarking()  equivalent ignoring benchmark entirely, benchmark included input benchmarks file. Compared benchmarking(), generally translates nonbinding benchmarks larger impact resulting benchmarked stocks.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"solution-around-the-first-and-last-benchmarks-benchmarking-timeliness-issue-","dir":"Reference","previous_headings":"","what":"Solution around the first and last benchmarks (benchmarking timeliness issue)","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"slope=0 spline chosen conceptually corresponds (popular) Denton benchmarking approach (rho = 1). order provide solution first benchmark last benchmark similar benchmarking() rho < 1, .e., adjustments converging bias speed dictated argument rho, extra knots added ends estimating spline. default, one extra low frequency (defined argument low_freq_periodicity) knot added side (beginning end), .e. one extra knot added first benchmark last benchmark. , high (indicator series) frequency knots added cover indicator series span added extra year worth high frequency knots. value extra knots based arguments rho, biasOption bias. produces natural looking, smooth adjustments periods outside around first last benchmarks gradually converge bias, similarly benchmarking(). number extra low frequency knots added can modified argument n_low_freq_proj. Using high frequency knots right away (n_low_freq_proj = 0) produce projected adjustments benchmarking(). However, note tends produce unnatural looking (overly contorted) spline around first last benchmarks substantially revised next benchmark available. Using default n_low_freq_proj = 1 generally works better. However, rho close 1 (see argument proj_knots_rho_bd), high frequency knots immediately added side order ensure Denton-type (straight line) projected adjustments periods outside first last benchmarks. Finally, slope=0 cubic spline fitted (original extra) knots. Note practice, slope=0 spline actually approximated replicating value end knots 100 times within following period (frequency corresponding 100 times indicator series frequency). natural spline original end knots (first last benchmarks) can approximated specifying large value argument low_freq_periodicity. larger value low_freq_periodicity, cubic spline end knots behave like natural spline (2nd derivative equal 0 end knots, .e., spline keeps constant slope end knots opposed flat like slope=0 spline). summary, projected adjustments controlled arguments rho, bias (biasOption), n_low_freq_proj, proj_knots_rho_bd low_freq_periodicity: Default values arguments produce benchmarking() function-like projected adjustments (reasonably slow convergence bias). Smaller values rho generate faster convergence bias. Specifying user-defined bias argument bias rho < 1 another way influence shape projected adjustments. Specifying rho = 1 produce Denton-like projected adjustments (repeated first/last adjustments without convergence bias). Specifying large value low_freq_periodicity generates projected adjustments behave like natural spline, .e., adjustments continue direction first/last benchmark. larger value low_freq_periodicity, projected adjustments keep going direction turning around.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"note-on-revisions-to-the-benchmarking-adjustments","dir":"Reference","previous_headings":"","what":"Note on revisions to the benchmarking adjustments","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"benchmarking() adjustments revised future benchmarks fall exactly projected ones (based bias value rho) bias fixed. achieved stock_benchmarking() enough low (e.g., benchmarks) frequency knots projected. problem approach, however, projected adjustments may look natural spline may oscillate desired around projected knots. clearly noticeable rho approaches 1 spline oscillates around horizontally aligned projected knots instead aligned perfectly straight line. default implementation spline around first last benchmarks described previously aims reaching best compromise solution: natural looking spline around end knots avoiding oscillations excessive contortions; small revisions spline next benchmark close projected one rho far enough 1 (rho <= proj_knots_rho_bd); projected adjustments straight line (free oscillations) rho approaches 1 (rho > proj_knots_rho_bd). Subsections Benchmarking Multiple Series, Arguments constant negInput_option Treatment Missing (NA) Values end benchmarking() Details section also relevant stock_benchmarking(). Consult necessary. Finally, note cubic spline associated stock_benchmarking() adjustments can conveniently plotted plot_benchAdj(). latter used Examples illustrate topics discussed .","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"Statistics Canada (2012). \"Chapter 5: Benchmarking Stock\". Theory Application Benchmarking (Course code 0436). Statistics Canada, Ottawa, Canada.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/stock_benchmarking.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore temporal constraints for stock series — stock_benchmarking","text":"","code":"# Quarterly stock series (same pattern repeated every year) my_series <- ts_to_tsDF(ts(rep(c(85, 95, 125, 95), 7),                            start = c(2013, 1),                            frequency = 4)) head(my_series) #>   year period value #> 1 2013      1    85 #> 2 2013      2    95 #> 3 2013      3   125 #> 4 2013      4    95 #> 5 2014      1    85 #> 6 2014      2    95  # Annual benchmarks (end-of-year stocks) my_benchmarks <- ts_to_bmkDF(ts(c(135, 125, 155, 145, 165),                                 start = 2013,                                 frequency = 1),                              discrete_flag = TRUE,                              alignment = \"e\",                              ind_frequency = 4) my_benchmarks #>   startYear startPeriod endYear endPeriod value #> 1      2013           4    2013         4   135 #> 2      2014           4    2014         4   125 #> 3      2015           4    2015         4   155 #> 4      2016           4    2016         4   145 #> 5      2017           4    2017         4   165  # Benchmark using... #   - recommended `rho` value for quarterly series (`rho = 0.729`) #   - proportional model (`lambda = 1`) #   - bias-corrected indicator series with the estimated bias (`biasOption = 3`)  # ... with `benchmarking()` (\"Proc Benchmarking\" approach) out_PB <- benchmarking(my_series,                        my_benchmarks,                        rho = 0.729,                        lambda = 1,                        biasOption = 3) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> benchmarking() function: #>     series_df          = my_series #>     benchmarks_df      = my_benchmarks #>     rho                = 0.729 #>     lambda             = 1 #>     biasOption         = 3 (Calculate bias, use calculated bias) #>     bias               (ignored) #>     tolV               = 0.001 (default) #>     warnNegResult      = TRUE (default) #>     tolN               = -0.001 (default) #>     var                = value (default) #>     with               = NULL (default) #>     by                 = NULL (default) #>     verbose            = FALSE (default) #>     (*)constant        = 0 (default) #>     (*)negInput_option = 0 (default) #>     (*)allCols         = FALSE (default) #>     (*)quiet           = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #> Number of observations in the BENCHMARKS data frame .............:  5 #> Number of valid observations in the BENCHMARKS data frame .......:  5 #> Number of observations in the SERIES data frame .................: 28 #> Number of valid observations in the SERIES data frame ...........: 28 #> BIAS = 1.526316 (calculated)  # ... with `stock_benchmarking()` (\"Stock Benchmarking\" approach) out_SB <- stock_benchmarking(my_series,                              my_benchmarks,                              rho = 0.729,                              lambda = 1,                              biasOption = 3) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> stock_benchmarking() function: #>     series_df            = my_series #>     benchmarks_df        = my_benchmarks #>     rho                  = 0.729 #>     lambda               = 1 #>     biasOption           = 3 (Calculate bias, use calculated bias) #>     bias                 (ignored) #>     low_freq_periodicity = NA (default) #>     n_low_freq_proj      = 1 (default) #>     proj_knots_rho_bd    = 0.995 (default) #>     tolV                 = 0.001 (default) #>     warnNegResult        = TRUE (default) #>     tolN                 = -0.001 (default) #>     var                  = value (default) #>     with                 = NULL (default) #>     by                   = NULL (default) #>     constant             = 0 (default) #>     negInput_option      = 0 (default) #>     allCols              = FALSE (default) #>     quiet                = FALSE (default) #> Number of observations in the BENCHMARKS data frame .............:  5 #> Number of valid observations in the BENCHMARKS data frame .......:  5 #> Number of observations in the SERIES data frame .................: 28 #> Number of valid observations in the SERIES data frame ...........: 28 #> BIAS = 1.526316 (calculated)  # Compare the benchmarking adjustments of both approaches plot_benchAdj(PB_graphTable = out_PB$graphTable,               SB_graphTable = out_SB$graphTable)    # Have you noticed how smoother the `stock_benchmarking()` adjustments are compared  # to the `benchmarking()` ones?  # The gain in the quality of the resulting benchmarked stocks might not necessarily # be obvious in this example plot(out_SB$graphTable$t, out_SB$graphTable$benchmarked,      type = \"b\", col = \"red\", xlab = \"t\", ylab = \"Benchmarked Stock\") lines(out_PB$graphTable$t, out_PB$graphTable$benchmarked,       type = \"b\", col = \"blue\") legend(x = \"topleft\", bty = \"n\", inset = 0.05, lty = 1, pch = 1,        col = c(\"red\", \"blue\"), legend = c(\"out_SB\", \"out_PB\")) title(\"Benchmarked Stock\")    # What about cases where a flat indicator is used, which may happen in practice # in absence of a good indicator of the quarterly (sub-annual) movement? my_series2 <- my_series my_series2$value <- 1  # flat indicator head(my_series2) #>   year period value #> 1 2013      1     1 #> 2 2013      2     1 #> 3 2013      3     1 #> 4 2013      4     1 #> 5 2014      1     1 #> 6 2014      2     1 out_PB2 <- benchmarking(my_series2,                         my_benchmarks,                         rho = 0.729,                         lambda = 1,                         biasOption = 3,                         quiet = TRUE)  # don't show the function header  out_SB2 <- stock_benchmarking(my_series2,                               my_benchmarks,                               rho = 0.729,                               lambda = 1,                               biasOption = 3,                               quiet = TRUE)  # don't show the function header  plot(out_SB2$graphTable$t, out_SB2$graphTable$benchmarked,      type = \"b\", col = \"red\", xlab = \"t\", ylab = \"Benchmarked Stock\") lines(out_PB2$graphTable$t, out_PB2$graphTable$benchmarked,       type = \"b\", col = \"blue\") legend(x = \"bottomright\", bty = \"n\", inset = 0.05, lty = 1, pch = 1,        col = c(\"red\", \"blue\"), legend = c(\"out_SB2\", \"out_PB2\")) title(\"Benchmarked Stock - Flat Indicator\")    # The awkwardness of the benchmarked stocks produced by `benchmarking()` suddenly # becomes obvious. That's because the benchmarked series corresponds to the # benchmarking adjustments when using a flat indicator (e.g., a series on 1's # with proportional benchmarking): plot_benchAdj(PB_graphTable = out_PB2$graphTable,               SB_graphTable = out_SB2$graphTable)    # The shortcomings of the \"Proc Benchmarking\" approach (function `benchmarking()`) # with stocks is also quite noticeable in this case when looking at the resulting # quarterly growth rates, which are conveniently produced by `plot_graphTable()`. # Pay particular attention to the transition in the growth rates from Q4 to Q1 # every year in the generated PDF graphs. plot_graphTable(out_PB2$graphTable, file.path(tempdir(), \"PB_stock_flat_ind.pdf\")) #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 1 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\PB_stock_flat_ind.pdf plot_graphTable(out_SB2$graphTable, file.path(tempdir(), \"SB_stock_flat_ind.pdf\")) #>  #> Generating the benchmarking graphics. Please be patient... #> Benchmarking graphics generated for 1 series in the following PDF file: #>   C:\\Users\\ferlmic\\AppData\\Local\\Temp\\Rtmp0M5DK2\\SB_stock_flat_ind.pdf   # Illustrate approximating a natural cubic spline at the original end knots (first and  # last benchmarks) by specifying a large `low_freq_periodicity` value. out_SB3 <- stock_benchmarking(my_series,                               my_benchmarks,                               rho = 0.729,                               lambda = 1,                               biasOption = 3,                                                              # Large value to approximate a natural cubic spline                               low_freq_periodicity = 100,                                                              quiet = TRUE)  plot_benchAdj(SB_graphTable = out_SB3$graphTable,               SB_splineKnots = out_SB3$splineKnots,               legendPos = \"topleft\")    # Illustrate \"oscillations\" of the cubic spline beyond the original end knots with # Denton-type benchmarking (`rho ~ 1`) caused by using low frequency (annual) extra knots. out_SB4 <- stock_benchmarking(my_series,                               my_benchmarks,                               rho = 0.999,                               lambda = 1,                               biasOption = 3,                                                              # Use 3 annual extra knots first                               n_low_freq_proj = 3,                               proj_knots_rho_bd = 1,                                                              quiet = TRUE)  plot_benchAdj(SB_graphTable = out_SB4$graphTable,               SB_splineKnots = out_SB4$splineKnots)   # No \"oscillations\" with the default `proj_knots_rho_bd` value because high frequency  # (quarterly) extra knots are used right away (`n_low_freq_proj` is ignored) since  # `rho = 0.999` exceeds the default `proj_knots_rho_bd` value (0.995^3 for quarterly data).  # These projected adjustments are more in line with Denton-type adjustments (straight line). out_SB4b <- stock_benchmarking(my_series,                                my_benchmarks,                                rho = 0.999,                                lambda = 1,                                biasOption = 3,                                quiet = TRUE)  plot_benchAdj(SB_graphTable = out_SB4b$graphTable,               SB_splineKnots = out_SB4b$splineKnots)    # Illustrate \"contortions\" of the cubic spline around the original end knots caused # by using high frequency extra knots right away (`n_low_freq_proj = 0`), i.e., using  # the same projected adjustments as those that would be obtained with `benchmarking()`. # # To exacerbate the phenomenon, we'll use monthly data (11 periods between each annual  # benchmark compared to only 3 for quarterly data, i.e., a less constrained spline)  # and a rather small value for `rho` (0.5 < 0.9 = recommended value for monthly data)  # for a faster convergence to the bias of the projected adjustments.  yr_vec <- unique(my_series$year) my_series3 <- data.frame(year = rep(yr_vec, each = 12),                          period = rep(1:12, length(yr_vec)),                          value = rep(1, 12 * length(yr_vec)))  # flat indicator my_benchmarks2 <- my_benchmarks my_benchmarks2[c(\"startPeriod\", \"endPeriod\")] <- 12  out_SB5 <- stock_benchmarking(my_series3,                               my_benchmarks2,                               rho = 0.5,                               lambda = 1,                               biasOption = 3,                                                              # Use monthly extra knots right away                               n_low_freq_proj = 0,                                                              quiet = TRUE)  plot_benchAdj(SB_graphTable = out_SB5$graphTable,               SB_splineKnots = out_SB5$splineKnots)   # No excessive \"contortions\" around the original end knots with the default   # `n_low_freq_proj = 1`, i.e., use 1 low frequency (annual) extra knot first. out_SB5b <- stock_benchmarking(my_series3,                                my_benchmarks2,                                rho = 0.5,                                lambda = 1,                                biasOption = 3,                                quiet = TRUE)  plot_benchAdj(SB_graphTable = out_SB5b$graphTable,               SB_splineKnots = out_SB5b$splineKnots)   # To even better highlight the potential excessive \"contortions\" of the cubic spline  # when enforcing the `benchmarking()` projected adjustment (i.e., low frequency extra  # knots right away with `n_low_freq_proj = 0`), let's plot the previous two sets of  # adjustments on the same plot (the blue line corresponds to the `n_low_freq_proj = 0`  # case, i.e., the `benchmarking()` projected adjustments while the red line corresponds  # to the default `stock_benchmarking()` adjustments, i.e., `n_low_freq_proj = 1`). plot_benchAdj(PB_graphTable = out_SB5$graphTable,               SB_graphTable = out_SB5b$graphTable,               legend = NULL)"},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/time_values_conv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time values conversion functions — time_values_conv","text":"","code":"gs.time2year(ts)  gs.time2per(ts)  gs.time2str(ts, sep = \"-\")"},{"path":"https://ferlmic.github.io/gstest/en/reference/time_values_conv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time values conversion functions — time_values_conv","text":"ts (mandatory) Time series (\"ts\" \"mts\") object coerced one. sep (optional) String (character constant) specifying separator use year period values (defaults \"-\").","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/time_values_conv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time values conversion functions — time_values_conv","text":"gs.time2year() returns integer vector \"nearest\" year (time unit) values. function equivalent stats::cycle() time unit values. gs.time2per() returns integer vector period (cycle) values (see stats::cycle()). gs.time2str() returns character vector corresponding gs.time2year(ts) stats::frequency(ts) == 1 gs.time2year(ts) gs.time2per(ts) separated sep otherwise.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/time_values_conv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time values conversion functions — time_values_conv","text":"","code":"# Dummy monthly time series  mth_ts <- ts(rep(NA, 15), start = c(2019, 1), frequency = 12) mth_ts #>      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec #> 2019  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA #> 2020  NA  NA  NA                                     gs.time2year(mth_ts) #>  [1] 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2020 2020 2020 gs.time2per(mth_ts) #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12  1  2  3 gs.time2str(mth_ts) #>  [1] \"2019-1\"  \"2019-2\"  \"2019-3\"  \"2019-4\"  \"2019-5\"  \"2019-6\"  \"2019-7\"  #>  [8] \"2019-8\"  \"2019-9\"  \"2019-10\" \"2019-11\" \"2019-12\" \"2020-1\"  \"2020-2\"  #> [15] \"2020-3\"  gs.time2str(mth_ts, sep = \"m\") #>  [1] \"2019m1\"  \"2019m2\"  \"2019m3\"  \"2019m4\"  \"2019m5\"  \"2019m6\"  \"2019m7\"  #>  [8] \"2019m8\"  \"2019m9\"  \"2019m10\" \"2019m11\" \"2019m12\" \"2020m1\"  \"2020m2\"  #> [15] \"2020m3\"   # Dummy quarterly time series  qtr_ts <- ts(rep(NA, 5), start = c(2019, 1), frequency = 4) qtr_ts #>      Qtr1 Qtr2 Qtr3 Qtr4 #> 2019   NA   NA   NA   NA #> 2020   NA                gs.time2year(qtr_ts) #> [1] 2019 2019 2019 2019 2020 gs.time2per(qtr_ts) #> [1] 1 2 3 4 1 gs.time2str(qtr_ts) #> [1] \"2019-1\" \"2019-2\" \"2019-3\" \"2019-4\" \"2020-1\" gs.time2str(qtr_ts, sep = \"q\") #> [1] \"2019q1\" \"2019q2\" \"2019q3\" \"2019q4\" \"2020q1\""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"Replication G-Series 2.0 SAS\\(^\\circledR\\) GSeriesTSBalancing macro. See G-Series 2.0 documentation details (Statistics Canada 2016). function balances (reconciles) system time series according set linear constraints. balancing solution obtained solving one several quadratic minimization problems (see section Details) OSQP solver (Stellato et al. 2020). Given feasibility balancing problem(s), resulting time series data respect specified constraints every time period. Linear equality inequality constraints allowed. Optionally, preservation temporal totals may also specified.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"","code":"tsbalancing(   in_ts,   problem_specs_df,   temporal_grp_periodicity = 1,   temporal_grp_start = 1,   osqp_settings_df = default_osqp_sequence,   display_level = 1,   alter_pos = 1,   alter_neg = 1,   alter_mix = 1,   alter_temporal = 0,   lower_bound = -Inf,   upper_bound = Inf,   tolV = 0,   tolV_temporal = 0,   tolP_temporal = NA,    # New in G-Series 3.0   validation_tol = 0.001,   trunc_to_zero_tol = validation_tol,   full_sequence = FALSE,   validation_only = FALSE,   quiet = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"in_ts (mandatory) Time series (\"ts\" \"mts\"), object coerced one, contains time series data reconciled. balancing problems' input data (initial solutions). problem_specs_df (mandatory) Balancing problem specifications data frame. Using sparse format inspired SAS/\\(^\\circledR\\) LP procedure’s sparse data input format (SAS Institute 2015), contains relevant information nonzero coefficients balancing constraints well non-default alterability coefficients lower/upper bounds (.e., values take precedence defined arguments alter_pos, alter_neg, alter_mix, alter_temporal, lower_bound upper_bound). information provided using four mandatory variables (type, col, row coef) one optional variable (timeVal). observation (row) problem specs data frame either defines label one seven types balancing problem elements columns type row (see Label definition records ) specifies coefficients (numerical values) balancing problem elements variables col, row, coef timeVal (see Information specification records ). Label definition records (type missing (NA)) type (chr): reserved keyword identifying type problem element defined: EQ: equality (\\(=\\)) balancing constraint LE: lower equal (\\(\\le\\)) balancing constraint GE: greater equal (\\(\\ge\\)) balancing constraint lowerBd: period value lower bound upperBd: period value upper bound alter: period values alterability coefficient alterTmp: temporal total alterability coefficient row (chr): label associated problem element (type keyword) variables irrelevant contain missing data (NA values) Information specification records (type missing (NA)) type (chr): applicable (NA) col (chr): series name reserved word _rhs_ specify balancing constraint right-hand side (RHS) value. row (chr): problem element label. coef (num): problem element value: balancing constraint series coefficient RHS value series period value lower upper bound series period value temporal total alterability coefficient timeVal (num): optional time value restrict application series bounds alterability coefficients specific time period (temporal group). corresponds time value, returned stats::time(), given input time series (argument in_ts) period (observation) conceptually equivalent \\(year + (period - 1) /   frequency\\). Note empty strings (\"\" '') character variables interpreted missing (NA) function. Variable row identifies elements balancing problem key variable makes link types records. label (row) associated one type problem element (type) multiple labels (row) defined given type problem element (type), except balancing constraints (values \"EQ\", \"LE\" \"GE\" column type). User-friendly features problem specs data frame include: order observations (rows) important. Character values (variables type, row col) case sensitive (e.g., strings \"Constraint 1\" \"CONSTRAINT 1\" row considered problem element label), except col used specify series name (column input time series object) case sensitivity enforced. variable names problem specs data frame also case sensitive (e.g., type, Type TYPE valid) time_val accepted variable name (instead timeVal). Finally, following table lists valid aliases type keywords (type problem element): Reviewing Examples help conceptualize balancing problem specifications data frame. temporal_grp_periodicity (optional) Positive integer defining number periods temporal groups totals preserved. E.g., specify temporal_grp_periodicity = 3 monthly time series quarterly total preservation temporal_grp_periodicity = 12 (temporal_grp_periodicity = frequency(in_ts)) annual total preservation. Specifying temporal_grp_periodicity = 1 (default) corresponds period--period processing without temporal total preservation. Default value temporal_grp_periodicity = 1 (period--period processing without temporal total preservation). temporal_grp_start (optional) Integer [1 .. temporal_grp_periodicity] interval specifying starting period (cycle) temporal total preservation. E.g., annual totals corresponding fiscal years defined April March following year specified temporal_grp_start = 4 monthly time series (frequency(in_ts) = 12) temporal_grp_start = 2 quarterly time series (frequency(in_ts) = 4). argument effect period--period processing without temporal total preservation (temporal_grp_periodicity = 1). Default value temporal_grp_start = 1. osqp_settings_df (optional) Data frame containing sequence OSQP settings solving balancing problems. package includes two predefined OSQP settings sequence data frames: default_osqp_sequence: fast effective (default); alternate_osqp_sequence: geared towards precision expense execution time. See vignette(\"osqp-settings-sequence-dataframe\") details topic see actual contents two data frames. Note concept solving sequence different sets solver settings new G-Series 3.0 (single solving attempt made G-Series 2.0). Default value osqp_settings_df = default_osqp_sequence. display_level (optional) Integer [0 .. 3] interval specifying level information display console (stdout()). Note specifying argument quiet = TRUE nullify argument display_level (none following information displayed). Default value display_level = 1. alter_pos (optional) Nonnegative real number specifying default alterability coefficient associated values time series positive coefficients balancing constraints involved (e.g., component series aggregation table raking problems). Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_pos = 1.0 (nonbinding values). alter_neg (optional) Nonnegative real number specifying default alterability coefficient associated values time series negative coefficients balancing constraints involved (e.g., marginal totals aggregation table raking problems). Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_neg = 1.0 (nonbinding values). alter_mix (optional) Nonnegative real number specifying default alterability coefficient associated values time series mix positive negative coefficients balancing constraints involved. Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_mix = 1.0 (nonbinding values). alter_temporal (optional) Nonnegative real number specifying default alterability coefficient associated time series temporal totals. Alterability coefficients provided problem specification data frame (argument problem_specs_df) override value. Default value alter_temporal = 0.0 (binding values). lower_bound (optional) Real number specifying default lower bound time series values. Lower bounds provided problem specification data frame (argument problem_specs_df) override value. Default value lower_bound = -Inf (unbounded). upper_bound (optional) Real number specifying default upper bound time series values. Upper bounds provided problem specification data frame (argument problem_specs_df) override value. Default value upper_bound = Inf (unbounded). tolV (optional) Nonnegative real number specifying tolerance, absolute value, balancing constraints right-hand side (RHS) values: EQ constraints: \\(\\quad \\mathbf{x} = \\mathbf{b} \\quad\\) become \\(\\quad \\mathbf{b} - \\epsilon \\le \\mathbf{x} \\le \\mathbf{b} + \\epsilon\\) LE constraints: \\(\\quad \\mathbf{x} \\le \\mathbf{b} \\quad\\) become \\(\\quad \\mathbf{x} \\le \\mathbf{b} + \\epsilon\\) GE constraints: \\(\\quad \\mathbf{x} \\ge \\mathbf{b} \\quad\\) become \\(\\quad \\mathbf{x} \\ge \\mathbf{b} - \\epsilon\\) \\(\\epsilon\\) tolerance specified tolV. argument apply period value (lower upper) bounds specified arguments lower_bound upper_bound problem specs data frame (argument prob_specs_df). .e., tolV affect time series values lower upper bounds, unless specified balancing constraints instead (GE LE constraints problem specs data frame). Default value tolV = 0.0 (tolerance). tolV_temporal, tolP_temporal (optional) Nonnegative real number, NA, specifying tolerance, percentage (tolP_temporal) absolute value (tolV_temporal), implicit temporal aggregation constraints associated binding temporal totals \\(\\left( \\sum_t{x_{,t}} = \\sum_t{y_{,t}} \\right)\\), become: $$\\sum_t{y_{,t}} - \\epsilon_\\text{abs} \\le \\sum_t{x_{,t}} \\le \\sum_t{y_{,t}} + \\epsilon_\\text{abs}$$ $$\\sum_t{y_{,t}} \\left( 1 - \\epsilon_\\text{rel} \\right) \\le \\sum_t{x_{,t}} \\le \\sum_t{y_{,t}} \\left( 1 + \\epsilon_\\text{rel} \\right)$$ \\(\\epsilon_\\text{abs}\\) \\(\\epsilon_\\text{rel}\\) absolute percentage tolerances specified respectively tolV_temporal  tolP_temporal. arguments specified together (one must specified must NA). Example: set tolerance 10 units, specify tolV_temporal = 10, tolP_temporal = NA; set tolerance 1%, specifytolV_temporal = NA, tolP_temporal = 0.01. Default values tolV_temporal = 0.0 tolP_temporal = NA (tolerance). validation_tol (optional) Nonnegative real number specifying tolerance validation balancing results. function verifies final (reconciled) time series values meet constraints, allowing discrepancies value specified argument. warning issued soon one constraint met (discrepancy greater validation_tol). constraints defined \\(\\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u}\\), \\(\\mathbf{l = u}\\) EQ constraints, \\(\\mathbf{l} = -\\infty\\) LE constraints \\(\\mathbf{u} = \\infty\\) GE constraints, constraint discrepancies correspond \\(\\max \\left( 0, \\mathbf{l} - \\mathbf{x}, \\mathbf{x} - \\mathbf{u} \\right)\\), constraint bounds \\(\\mathbf{l}\\) \\(\\mathbf{u}\\) include tolerances, applicable, specified arguments tolV, tolV_temporal tolP_temporal. Default value validation_tol = 0.001. trunc_to_zero_tol (optional) Nonnegative real number specifying tolerance, absolute value, replacing zero (small) values output (reconciled) time series data (output object out_ts). Specify trunc_to_zero_tol = 0 disable truncation zero process reconciled data. Otherwise, specify trunc_to_zero_tol > 0 replace \\(0.0\\) value \\(\\left[ -\\epsilon, \\epsilon \\right]\\) interval, \\(\\epsilon\\) tolerance specified trunc_to_zero_tol. Note final constraint discrepancies (see argument validation_tol) calculated zero truncated reconciled time series values, therefore ensuring accurate validation actual reconciled data returned function. Default value trunc_to_zero_tol = validation_tol. full_sequence (optional) Logical argument specifying whether steps OSQP settings sequence data frame performed . See argument osqp_settings_df vignette(\"osqp-settings-sequence-dataframe\") details topic. Default value full_sequence = FALSE. validation_only (optional) Logical argument specifying whether function perform input data validation . validation_only = TRUE, specified balancing constraints period value (lower upper) bounds constraints validated input time series data, allowing discrepancies value specified argument validation_tol. Otherwise, validation_only = FALSE (default), input data first reconciled resulting (output) data validated. Default value validation_only = FALSE. quiet (optional) Logical argument specifying whether display essential information warnings, errors period (set periods) reconciled. suppress, desired, display balancing period(s) information wrapping tsbalancing() call suppressMessages(). case, proc_grp_df output data frame can used identify (unsuccessful) balancing problems associated warning messages (). Note specifying quiet = TRUE also nullify argument display_level. Default value quiet = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"function returns list seven objects: out_ts: modified version input time series object (\"ts\" \"mts\"; see argument in_ts) resulting reconciled time series values (primary function output). can explicitly coerced another type object appropriate *() function (e.g., tsibble::as_tsibble() coerce tsibble). proc_grp_df: processing group summary data frame, useful identify problems succeeded failed. contains one observation (row) balancing problem following columns: proc_grp (num): processing group id. proc_grp_type (chr): processing group type. Possible values : \"period\"; \"temporal group\". proc_grp_label (chr): string describing processing group following format: \"<year>-<period>\" (single periods) \"<start year>-<start period> - <end year>-<end period>\" (temporal groups) sol_status_val, sol_status (num, chr): solution status numerical (integer) value description string: 1: \"valid initial solution\"; -1: \"invalid initial solution\"; 2: \"valid polished osqp solution\"; -2: \"invalid polished osqp solution\"; 3: \"valid unpolished osqp solution\"; -3: \"invalid unpolished osqp solution\"; -4: \"unsolvable fixed problem\" (invalid initial solution). n_unmet_con (num): number unmet constraints (sum(prob_conf_df$unmet_flag)). max_discr (num): maximum constraint discrepancy (max(prob_conf_df$discr_out)). validation_tol (num): specified tolerance validation purposes (argument validation_tol). sol_type (chr): returned solution type. Possible values : \"initial\" (initial solution, .e., input data values); \"osqp\" (OSQP solution). osqp_attempts (num): number attempts made OSQP (depth achieved solving sequence). osqp_seqno (num): step # solving sequence corresponding returned solution. NA sol_type = \"initial\". osqp_status (chr): OSQP status description string (osqp_sol_info_df$status). NA sol_type = \"initial\". osqp_polished (logi): TRUE returned OSQP solution polished (osqp_sol_info_df$status_polish = 1), FALSE otherwise. NA sol_type = \"initial\". total_solve_time (num): total time, seconds, solving sequence. Column proc_grp constitutes unique key (distinct rows) data frame. Successful balancing problems (problems valid solution) correspond rows sol_status_val > 0 , equivalently, n_unmet_con = 0 max_discr <= validation_tol. initial solution (sol_type = \"initial\") returned ) initial constraint discrepancies, b) problem fixed (values binding) c) beats OSQP solution (smaller total constraint discrepancies). OSQP solving sequence described vignette(\"osqp-settings-sequence-dataframe\"). periods_df: time periods data frame, useful match periods processing groups. contains one observation (row) period input time series object (argument in_ts) following columns: proc_grp (num): processing group id. t (num): time id (1:nrow(in_ts)). time_val (num): time value (stats::time(in_ts)). conceptually corresponds \\(year + (period - 1) / frequency\\). Columns t time_val constitute unique key (distinct rows) data frame. prob_val_df: problem values data frame, useful analyze change diagnostics, .e., initial vs final (reconciled) values. contains one observation (row) value involved balancing problem, following columns: proc_grp (num): processing group id. val_type (chr): problem value type. Possible values : \"period value\"; \"temporal total\". name (chr): time series (variable) name. t (num): time id (1:nrow(in_ts)); id first period temporal group temporal total. time_val (num): time value (stats::time(in_ts)); value first period temporal group temporal total. conceptually corresponds \\(year + (period - 1) / frequency\\). lower_bd, upper_bd (num): period value bounds; always -Inf Inf temporal total. alter (num): alterability coefficient. value_in, value_out (num): initial final (reconciled) values. dif (num): value_out - value_in. rdif (num): dif / value_in; NA value_in = 0. Columns val_type + name + t val_type + name + time_val constitute unique key (distinct rows) data frame. Binding (fixed) problem values correspond rows alter = 0 value_in = 0. Conversely, nonbinding (free) problem values correspond rows alter != 0 value_in != 0. prob_con_df: problem constraints data frame, useful troubleshooting problems failed (identify unmet constraints). contains one observation (row) constraint involved balancing problem, following columns: proc_grp (num): processing group id. con_type (chr): problem constraint type. Possible values : \"balancing constraint\"; \"temporal aggregation constraint\"; \"period value bounds\". balancing constraints specicied user, two types constraints (temporal aggregation constraints period value bounds) automatically added problem function (applicable). name (chr): constraint label time series (variable) name. t (num): time id (1:nrow(in_ts)); id first period temporal group temporal aggregation constraint. time_val (num): time value (stats::time(in_ts)); value first period temporal group temporal aggregation constraint. conceptually corresponds \\(year + (period - 1) / frequency\\). l, u, Ax_in, Ax_out (num): initial final constraint elements \\(\\left( \\mathbf{l} \\le \\mathbf{x} \\le   \\mathbf{u} \\right)\\). discr_in, discr_out (num): initial final constraint discrepancies \\(\\left( \\max \\left( 0, \\mathbf{l} -   \\mathbf{x}, \\mathbf{x} - \\mathbf{u} \\right) \\right)\\). validation_tol (num): specified tolerance validation purposes (argument validation_tol). unmet_flag (logi): TRUE constraint met (discr_out > validation_tol), FALSE otherwise. Columns con_type + name + t con_type + name + time_val constitute unique key (distinct rows) data frame. Constraint bounds \\(\\mathbf{l = u}\\) EQ constraints, \\(\\mathbf{l} = -\\infty\\) LE constraints, \\(\\mathbf{u} = \\infty\\) GE constraints, include tolerances, applicable, specified arguments tolV, tolV_temporal tolP_temporal. osqp_settings_df: OSQP settings data frame. contains one observation (row) problem (processing group) solved OSQP (proc_grp_df$sol_type = \"osqp\"), following columns: proc_grp (num): processing group id. one column corresponding element list returned osqp::GetParams() method applied OSQP solver object (class \"osqp_model\" object returned osqp::osqp()), e.g.: Maximum iterations (max_iter); Primal dual infeasibility tolerances (eps_prim_inf eps_dual_inf); Solution polishing flag (polish); Number scaling iterations (scaling); etc. extra settings specific tsbalancing(): prior_scaling (logi): TRUE problem data scaled (using average free (nonbinding) problem values scaling factor) prior solving OSQP, FALSE otherwise. require_polished (logi): TRUE polished solution OSQP (osqp_sol_info_df$status_polish = 1) required step order end solving sequence, FALSE otherwise. See vignette(\"osqp-settings-sequence-dataframe\") details solving sequence used tsbalancing(). Column proc_grp constitutes unique key (distinct rows) data frame. Visit https://osqp.org/docs/interfaces/solver_settings.html available OSQP settings. Problems (processing groups) initial solution returned (proc_grp_df$sol_type = \"initial\") included data frame. osqp_sol_info_df: OSQP solution information data frame. contains one observation (row) problem (processing group) solved OSQP (proc_grp_df$sol_type = \"osqp\"), following columns: proc_grp (num): processing group id. one column corresponding element info list OSQP solver object (class \"osqp_model\" object returned osqp::osqp()) solved osqp::Solve() method, e.g.: Solution status (status status_val); Polishing status (status_polish); Number iterations (iter); Objective function value (obj_val); Primal dual residuals (pri_res dua_res); Solve time (solve_time); etc. extra information specific tsbalancing(): prior_scaling_factor (num): value scaling factor osqp_settings_df$prior_scaling = TRUE (prior_scaling_factor = 1.0 otherwise). obj_val_ori_prob (num): original balancing problem's objective function value, OSQP objective function value (obj_val) original scale (osqp_settings_df$prior_scaling = TRUE) plus constant term original balancing problem's objective function, .e., obj_val_ori_prob = obj_val * prior_scaling_factor + <constant term>, <constant term> corresponds \\(\\mathbf{y}^{\\mathrm{T}} W \\mathbf{y}\\). See section Details definition vector \\(\\mathbf{y}\\), matrix \\(W\\) , generally speaking, complete expression balancing problem's objective function. Column proc_grp constitutes unique key (distinct rows) data frame. Visit https://osqp.org information OSQP. Problems (processing groups) initial solution returned (proc_grp_df$sol_type = \"initial\") included data frame. Note \"data.frame\" objects returned function can explicitly coerced types objects appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"function solves one balancing problem per processing group (see section Processing groups details). balancing problems quadratic minimization problem following form: $$\\displaystyle \\begin{aligned} & \\underset{\\mathbf{x}}{\\text{minimize}} & & \\mathbf{\\left( y - x \\right)}^{\\mathrm{T}} W \\mathbf{\\left( y - x \\right)} \\\\ & \\text{subject } & & \\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u} \\end{aligned} $$ \\(\\mathbf{y}\\) vector initial problem values, .e., initial time series period values , applicable, temporal totals; \\(\\mathbf{x}\\) final (reconciled) version vector \\(\\mathbf{y}\\); matrix \\(W = \\mathrm{diag} \\left( \\mathbf{w} \\right)\\) vector \\(\\mathbf{w}\\) elements \\(w_i = \\left\\{     \\begin{array}{cl}       0 & \\text{} |c_i y_i| = 0 \\\\       \\frac{1}{|c_i y_i|} & \\text{otherwise}     \\end{array} \\right.     \\), \\(c_i\\) alterability coefficient problem value \\(y_i\\) cases corresponding \\(|c_i y_i|     = 0\\) fixed problem values (binding period values temporal totals); matrix \\(\\) vectors \\(\\mathbf{l}\\) \\(\\mathbf{u}\\) specify balancing constraints, implicit temporal total aggregation constraints (applicable), period value (upper lower) bounds well \\(x_i = y_i\\) constraints fixed \\(y_i\\) values \\(\\left( \\left| c_i y_i \\right| = 0 \\right)\\). practice, objective function problem solved OSQP excludes constant term \\(\\mathbf{y}^{\\mathrm{T}} W \\mathbf{y}\\), therefore corresponding \\(\\mathbf{x}^{\\mathrm{T}} W \\mathbf{x} - 2 \\left( \\mathbf{w} \\mathbf{y} \\right)^{\\mathrm{T}} \\mathbf{x}\\), fixed \\(y_i\\) values \\(\\left( \\left| c_i y_i \\right| = 0 \\right)\\) removed problem, adjusting constraints accordingly, .e.: rows corresponding \\(x_i = y_i\\) constraints fixed \\(y_i\\) values removed \\(\\), \\( \\mathbf{l}\\) \\(\\mathbf{u}\\); columns corresponding fixed \\(y_i\\) values removed \\(\\) appropriately adjusting \\( \\mathbf{l}\\) \\(\\mathbf{u}\\).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"alterability-coefficients","dir":"Reference","previous_headings":"","what":"Alterability Coefficients","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"Alterability coefficients nonnegative numbers change relative cost modifying initial problem value. changing actual objective function minimize, allow generation wide range solutions. Since appear denominator objective function (matrix \\(W\\)), larger alterability coefficient less costly modify problem value (period value temporal total) , conversely, smaller alterability coefficient costly becomes. results problem values larger alterability coefficients proportionally changing ones smaller alterability coefficients. Alterability coefficients \\(0.0\\) define fixed (binding) problem values alterability coefficients greater \\(0.0\\) define free (nonbinding) values. default alterability coefficients \\(0.0\\) temporal totals (argument alter_temporal) \\(1.0\\) period values (arguments alter_pos, alter_neg, alter_mix). common case aggregation table raking problems, period values marginal totals (time series coefficient \\(-1\\) balancing constraints) usually binding (specified alter_neg = 0) period values component series (time series coefficient \\(1\\) balancing constraints) usually nonbinding (specified alter_pos > 0, e.g., alter_pos = 1). Almost binding problem values (e.g., marginal totals temporal totals) can obtained practice specifying small (almost \\(0.0\\)) alterability coefficients relative (nonbinding) problem values. Temporal total preservation refers fact temporal totals, applicable, usually kept “close possible” initial value. Pure preservation achieved default binding temporal totals change minimized nonbinding temporal totals (accordance set alterability coefficients).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"validation-and-troubleshooting","dir":"Reference","previous_headings":"","what":"Validation and troubleshooting","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"Successful balancing problems (problems valid solution) sol_status_val > 0 , equivalently, n_unmet_con = 0 max_discr <= validation_tol output proc_grp_df data frame. Troubleshooting unsuccessful balancing problems necessarily straightforward. Following suggestions: Investigate failed constraints (unmet_flag = TRUE , equivalently, discr_out > validation_tol output prob_con_df data frame) make sure cause empty solution space (infeasible problem). Change OSQP solving sequence. E.g., try: argument full_sequence = TRUE argument osqp_settings_df = alternate_osqp_sequence arguments osqp_settings_df = alternate_osqp_sequence full_sequence = TRUE See vignette(\"osqp-settings-sequence-dataframe\") details topic. Increase (review) validation_tol value. Although may sound like cheating, default validation_tol value (\\(1 \\times 10^{-3}\\)) may actually small balancing problems involve large values (e.g., billions) , conversely, large small problem values (e.g, \\(< 1.0\\)). Multiplying average scale problem data machine tolerance (.Machine$double.eps) gives approximation average size discrepancies tsbalancing() able handle (distinguish \\(0\\)) probably constitute absolute lower bound argument validation_tol. practice, reasonable validation_tol value likely \\(1 \\times 10^3\\) \\(1 \\times 10^6\\) times larger lower bound. Address constraints redundancy. Multi-dimensional aggregation table raking problems -specified (involve redundant constraints) totals dimensions data cube binding (fixed) constraint defined . Redundancy also occurs implicit temporal aggregation constraints single- multi-dimensional aggregation table raking problems binding (fixed) temporal totals. -specification generally issue tsbalancing() input data contradictory regards redundant constraints, .e., inconsistencies (discrepancies) associated redundant constraints input data negligible (reasonably small relative scale problem data). Otherwise, may lead unsuccessful balancing problems tsbalancing(). Possible solutions include: Resolve (reduce) discrepancies associated redundant constraints input data. Select one marginal total every dimension, one, data cube remove corresponding balancing constraints problem. done implicit temporal aggregation constraints. Select one marginal total every dimension, one, data cube make nonbinding (alterability coefficient , say, \\(1.0\\)). (3) temporal totals one inner-cube component series (make nonbinding). Make marginal totals every dimension, one, data cube amlost binding, .e., specify small alterability coefficients (say \\(1 \\times 10^{-6}\\)) compared inner-cube component series. (5) temporal totals inner-cube component series (small alterability coefficients, e.g., argument alter_temporal). Use tsraking() (applicable), handles inconsistencies using Moore-Penrose inverse (uniform distribution among binding totals). Solutions (2) (7) considered discrepancies associated redundant constraints input data reasonably small distributed among omitted nonbinding totals tsbalancing() binding totals tsraking(). Otherwise, one first investigate solution (1) . Relax bounds problem constraints, e.g.: argument tolV balancing constraints; arguments tolV_temporal tolP_temporal implicit temporal aggregation constraints; arguments lower_bound upper_bound.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"processing-groups","dir":"Reference","previous_headings":"","what":"Processing groups","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"set periods given reconciliation (raking balancing) problem called processing group either corresponds : single period period--period processing , preserving temporal totals, individual periods incomplete temporal group (e.g., incomplete year) set periods complete temporal group (e.g., complete year) preserving temporal totals. total number processing groups (total number reconciliation problems) depends set periods input time series object (argument in_ts) value arguments temporal_grp_periodicity temporal_grp_start. Common scenarios include temporal_grp_periodicity = 1 (default) period-period processing without temporal total preservation temporal_grp_periodicity = frequency(in_ts) preservation annual totals (calendar years default). Argument temporal_grp_start allows specification types (non-calendar) years. E.g., fiscal years starting April correspond temporal_grp_start = 4 monthly data temporal_grp_start = 2 quarterly data. Preserving quarterly totals monthly data correspond temporal_grp_periodicity = 3. default, temporal groups covering year (.e., corresponding temporal_grp_periodicity > frequency(in_ts) start year multiple  ceiling(temporal_grp_periodicity / frequency(in_ts)). E.g., biennial groups corresponding temporal_grp_periodicity = 2 * frequency(in_ts) start even year default. behaviour can changed argument temporal_grp_start. E.g., preservation biennial totals starting odd year instead even year (default) corresponds temporal_grp_start = frequency(in_ts) + 1 (along temporal_grp_periodicity = 2 * frequency(in_ts)). See gs.build_proc_grps() Examples common processing group scenarios.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"comparing-tsraking-and-tsbalancing-","dir":"Reference","previous_headings":"","what":"Comparing tsraking() and tsbalancing()","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"tsraking() limited one- two-dimensional aggregation table raking problems (temporal total preservation required) tsbalancing() handles general balancing problems (e.g., higher dimensional raking problems, nonnegative solutions, general linear equality inequality constraints opposed aggregation rules , etc.). tsraking() returns generalized least squared solution Dagum Cholette regression-based raking model (Dagum Cholette 2006) tsbalancing() solves corresponding quadratic minimization problem using numerical solver. cases, convergence minimum achieved tsbalancing() solution matches (exact) tsraking() least square solution. may case, however, convergence achieved reasonable number iterations. said , rare occasions tsbalancing() solution significantly differ tsraking() solution. tsbalancing() usually faster tsraking(), especially large raking problems, generally sensitive presence (small) inconsistencies input data associated redundant constraints fully specified (-specified) raking problems. tsraking() handles inconsistencies using Moore-Penrose inverse (uniform distribution among binding totals). tsbalancing() accommodates specification sparse problems reduced form. true case tsraking() aggregation rules must always fully specified since complete data cube without missing data expected input (every single inner-cube component series must contribute dimensions cube, .e., every single outer-cube marginal total series). tools handle negative values input data differently default. solutions raking problems obtained tsbalancing() tsraking() identical input data points positive, differ data points negative (unless argument Vmat_option = 2 specified tsraking()). tsbalancing() tsraking() allow preservation temporal totals, time management incorporated tsraking(). example, construction processing groups (sets periods raking problem) left user tsraking() separate calls must submitted processing group (raking problem). helper function tsraking_driver() comes handy tsraking(). tsbalancing() returns set series input time series object tsraking() returns set series involved raking problem plus specified argument id (correspond subset input series).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"Dagum, E. B. P. Cholette (2006). Benchmarking, Temporal Distribution Reconciliation Methods Time Series. Springer-Verlag, New York, Lecture Notes Statistics, Vol. 186. Ferland, M., S. Fortier J. Bérubé (2016). \"Mathematical Optimization Approach Balancing Time Series: Statistics Canada’s GSeriesTSBalancing\". JSM Proceedings, Business Economic Statistics Section. Alexandria, VA: American Statistical Association. 2292-2306. Ferland, M. (2018). \"Time Series Balancing Quadratic Problem — Hessian matrix vector linear objective function coefficients\". Internal document. Statistics Canada, Ottawa, Canada. Quenneville, B. S. Fortier (2012). \"Restoring Accounting Constraints Time Series – Methods Software Statistical Agency\". Economic Time Series: Modeling Seasonality. Chapman & Hall, New York. SAS Institute Inc. (2015). \"LP Procedure Sparse Data Input Format\". SAS/\\(^\\circledR\\) 14.1 User's Guide: Mathematical Programming Legacy Procedures. https://support.sas.com/documentation/cdl/en/ormplpug/68158/HTML/default/viewer.htm#ormplpug_lp_details03.htm Statistics Canada (2016). \"GSeriesTSBalancing Macro\". G-Series 2.0 User Guide. Statistics Canada, Ottawa, Canada. Statistics Canada (2018). Theory Application Reconciliation (Course code 0437). Statistics Canada, Ottawa, Canada. Stellato, B., G. Banjac, P. Goulart et al. (2020). \"OSQP: operator splitting solver quadratic programs\". Math. Prog. Comp. 12, 637–672 (2020). https://doi.org/10.1007/s12532-020-00179-2","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/tsbalancing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore cross-sectional (contemporaneous) linear constraints — tsbalancing","text":"","code":"########### # Example 1: In this first example, the objective is to balance a following simple  #            accounting table (`Profits = Revenues – Expenses`) for 5 quarters  #            without modifying `Profits` where `Revenues >= 0` and `Expenses >= 0`.  # Problem specifications my_specs1 <- data.frame(type = c(\"EQ\", rep(NA, 3),                                   \"alter\", NA,                                   \"lowerBd\", NA, NA),                         col = c(NA, \"Revenues\", \"Expenses\", \"Profits\",                                  NA, \"Profits\",                                  NA, \"Revenues\", \"Expenses\"),                         row = c(rep(\"Accounting Rule\", 4),                                  rep(\"Alterability Coefficient\", 2),                                  rep(\"Lower Bound\", 3)),                         coef = c(NA, 1, -1, -1,                                  NA, 0,                                  NA, 0, 0)) my_specs1 #>      type      col                      row coef #> 1      EQ     <NA>          Accounting Rule   NA #> 2    <NA> Revenues          Accounting Rule    1 #> 3    <NA> Expenses          Accounting Rule   -1 #> 4    <NA>  Profits          Accounting Rule   -1 #> 5   alter     <NA> Alterability Coefficient   NA #> 6    <NA>  Profits Alterability Coefficient    0 #> 7 lowerBd     <NA>              Lower Bound   NA #> 8    <NA> Revenues              Lower Bound    0 #> 9    <NA> Expenses              Lower Bound    0  # Problem data my_series1 <- ts(matrix(c( 15,  10,  10,                             4,   8,  -1,                           250, 250,   5,                             8,  12,   0,                             0,  45, -55),                         ncol = 3,                         byrow = TRUE,                         dimnames = list(NULL, c(\"Revenues\", \"Expenses\", \"Profits\"))),                  start = c(2022, 1),                  frequency = 4)  # Reconcile the data out_balanced1 <- tsbalancing(in_ts = my_series1,                              problem_specs_df = my_specs1,                              display_level = 3) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsbalancing() function: #>     in_ts                    = my_series1 #>     problem_specs_df         = my_specs1 #>     temporal_grp_periodicity = 1 (default) #>     temporal_grp_start       (ignored) #>     osqp_settings_df         = default_osqp_sequence (default) #>     display_level            = 3 #>     alter_pos                = 1 (default) #>     alter_neg                = 1 (default) #>     alter_mix                = 1 (default) #>     alter_temporal           (ignored) #>     lower_bound              = -Inf (default) #>     upper_bound              = Inf (default) #>     tolV                     = 0 (default) #>     tolV_temporal            (ignored) #>     (*)validation_tol        = 0.001 (default) #>     (*)trunc_to_zero_tol     = validation_tol (default) #>     (*)validation_only       = FALSE (default) #>     (*)quiet                 = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Balancing Problem Elements #> ========================== #>  #>  #>   Balancing Constraints (1) #>   ------------------------- #>  #>   Accounting Rule: #>     Revenues - Expenses - Profits == 0 #>  #>  #>   Time Series Info #>   ---------------- #>  #>         name lowerBd                 upperBd           alter                 #>   1 Revenues       0 (problem specs)     Inf (default)     1 (default)       #>   2 Expenses       0 (problem specs)     Inf (default)     1 (default)       #>   3  Profits    -Inf (default)           Inf (default)     0 (problem specs) #>  #>  #>  #> Balancing period [2022-1] #> ========================= #>   Initial solution: #>     - Maximum discrepancy = 5 #>     - Total discrepancy   = 5 #>   Try to find a better solution with OSQP. #>  #>   ----------------------------------------------------------------- #>              OSQP v0.6.3  -  Operator Splitting QP Solver #>                 (c) Bartolomeo Stellato,  Goran Banjac #>           University of Oxford  -  Stanford University 2021 #>   ----------------------------------------------------------------- #>   problem:  variables n = 2, constraints m = 3 #>             nnz(P) + nnz(A) = 6 #>   settings: linear system solver = qdldl, #>             eps_abs = 1.0e-06, eps_rel = 1.0e-06, #>             eps_prim_inf = 1.0e-07, eps_dual_inf = 1.0e-07, #>             rho = 1.00e-01 (adaptive), #>             sigma = 1.00e-09, alpha = 1.60, max_iter = 4000 #>             check_termination: on (interval 25), #>             scaling: off, scaled_termination: off #>             warm start: on, polish: on, time_limit: off #>    #>   iter  objective    pri res    dua res    rho        time #>      1  -1.3898e+00   7.94e-01   8.11e+01   1.00e-01   6.86e-05s #>     50  -1.9200e+00   9.38e-11   5.19e-10   1.00e-01   1.31e-04s #>   plsh  -1.9200e+00   1.11e-16   2.22e-16  ---------   2.07e-04s #>    #>   status:               solved #>   solution polish:      successful #>   number of iterations: 50 #>   optimal objective:    -1.9200 #>   run time:             2.07e-04s #>   optimal rho estimate: 5.49e-02 #>    #>   OSQP iteration 1: #>     - Maximum discrepancy = 0 #>     - Total discrepancy   = 0 #>   Valid solution (maximum discrepancy <= 0.001 = `validation_tol`). #>   Required polished solution achieved. #>  #>   -------------- #>   Problem Values #>   -------------- #>        name t time_val lower_bd upper_bd alter value_in value_out dif rdif #>    Revenues 1     2022        0      Inf     1       15        18   3  0.2 #>    Expenses 1     2022        0      Inf     1       10         8  -2 -0.2 #>     Profits 1     2022     -Inf      Inf     0       10        10   0  0.0 #>  #>   ---------------------------------- #>   Problem Constraints (l <= Ax <= u) #>   ---------------------------------- #>   Balancing Constraints #>   --------------------- #>               name t time_val  l  u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Accounting Rule 1     2022 10 10     5     10        5         0          0.001      FALSE #>   Period Value Bounds #>   ------------------- #>        name t time_val l   u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Revenues 1     2022 0 Inf    15     18        0         0          0.001      FALSE #>    Expenses 1     2022 0 Inf    10      8        0         0          0.001      FALSE #>  #>  #>  #> Balancing period [2022-2] #> ========================= #>   Initial solution: #>     - Maximum discrepancy = 3 #>     - Total discrepancy   = 3 #>   Try to find a better solution with OSQP. #>  #>   ----------------------------------------------------------------- #>              OSQP v0.6.3  -  Operator Splitting QP Solver #>                 (c) Bartolomeo Stellato,  Goran Banjac #>           University of Oxford  -  Stanford University 2021 #>   ----------------------------------------------------------------- #>   problem:  variables n = 2, constraints m = 3 #>             nnz(P) + nnz(A) = 6 #>   settings: linear system solver = qdldl, #>             eps_abs = 1.0e-06, eps_rel = 1.0e-06, #>             eps_prim_inf = 1.0e-07, eps_dual_inf = 1.0e-07, #>             rho = 1.00e-01 (adaptive), #>             sigma = 1.00e-09, alpha = 1.60, max_iter = 4000 #>             check_termination: on (interval 25), #>             scaling: off, scaled_termination: off #>             warm start: on, polish: on, time_limit: off #>    #>   iter  objective    pri res    dua res    rho        time #>      1  -1.2816e+00   1.57e-01   1.77e+01   1.00e-01   5.64e-05s #>     50  -1.8750e+00   1.33e-11   1.11e-10   1.00e-01   1.31e-04s #>   plsh  -1.8750e+00   2.78e-17   0.00e+00  ---------   2.08e-04s #>    #>   status:               solved #>   solution polish:      successful #>   number of iterations: 50 #>   optimal objective:    -1.8750 #>   run time:             2.08e-04s #>   optimal rho estimate: 5.47e-02 #>    #>   OSQP iteration 1: #>     - Maximum discrepancy = 0 #>     - Total discrepancy   = 0 #>   Valid solution (maximum discrepancy <= 0.001 = `validation_tol`). #>   Required polished solution achieved. #>  #>   -------------- #>   Problem Values #>   -------------- #>        name t time_val lower_bd upper_bd alter value_in value_out dif  rdif #>    Revenues 2  2022.25        0      Inf     1        4         5   1  0.25 #>    Expenses 2  2022.25        0      Inf     1        8         6  -2 -0.25 #>     Profits 2  2022.25     -Inf      Inf     0       -1        -1   0  0.00 #>  #>   ---------------------------------- #>   Problem Constraints (l <= Ax <= u) #>   ---------------------------------- #>   Balancing Constraints #>   --------------------- #>               name t time_val  l  u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Accounting Rule 2  2022.25 -1 -1    -4     -1        3         0          0.001      FALSE #>   Period Value Bounds #>   ------------------- #>        name t time_val l   u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Revenues 2  2022.25 0 Inf     4      5        0         0          0.001      FALSE #>    Expenses 2  2022.25 0 Inf     8      6        0         0          0.001      FALSE #>  #>  #>  #> Balancing period [2022-3] #> ========================= #>   Initial solution: #>     - Maximum discrepancy = 5 #>     - Total discrepancy   = 5 #>   Try to find a better solution with OSQP. #>  #>   ----------------------------------------------------------------- #>              OSQP v0.6.3  -  Operator Splitting QP Solver #>                 (c) Bartolomeo Stellato,  Goran Banjac #>           University of Oxford  -  Stanford University 2021 #>   ----------------------------------------------------------------- #>   problem:  variables n = 2, constraints m = 3 #>             nnz(P) + nnz(A) = 6 #>   settings: linear system solver = qdldl, #>             eps_abs = 1.0e-06, eps_rel = 1.0e-06, #>             eps_prim_inf = 1.0e-07, eps_dual_inf = 1.0e-07, #>             rho = 1.00e-01 (adaptive), #>             sigma = 1.00e-09, alpha = 1.60, max_iter = 4000 #>             check_termination: on (interval 25), #>             scaling: off, scaled_termination: off #>             warm start: on, polish: on, time_limit: off #>    #>   iter  objective    pri res    dua res    rho        time #>      1  -1.4512e+00   2.00e-02   3.05e+00   1.00e-01   6.81e-05s #>     50  -1.9998e+00   1.70e-12   1.29e-11   1.00e-01   1.31e-04s #>   plsh  -1.9998e+00   1.73e-17   1.73e-17  ---------   1.97e-04s #>    #>   status:               solved #>   solution polish:      successful #>   number of iterations: 50 #>   optimal objective:    -1.9998 #>   run time:             1.97e-04s #>   optimal rho estimate: 5.13e-02 #>    #>   OSQP iteration 1: #>     - Maximum discrepancy = 0 #>     - Total discrepancy   = 0 #>   Valid solution (maximum discrepancy <= 0.001 = `validation_tol`). #>   Required polished solution achieved. #>  #>   -------------- #>   Problem Values #>   -------------- #>        name t time_val lower_bd upper_bd alter value_in value_out  dif  rdif #>    Revenues 3   2022.5        0      Inf     1      250     252.5  2.5  0.01 #>    Expenses 3   2022.5        0      Inf     1      250     247.5 -2.5 -0.01 #>     Profits 3   2022.5     -Inf      Inf     0        5       5.0  0.0  0.00 #>  #>   ---------------------------------- #>   Problem Constraints (l <= Ax <= u) #>   ---------------------------------- #>   Balancing Constraints #>   --------------------- #>               name t time_val l u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Accounting Rule 3   2022.5 5 5     0      5        5         0          0.001      FALSE #>   Period Value Bounds #>   ------------------- #>        name t time_val l   u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Revenues 3   2022.5 0 Inf   250  252.5        0         0          0.001      FALSE #>    Expenses 3   2022.5 0 Inf   250  247.5        0         0          0.001      FALSE #>  #>  #>  #> Balancing period [2022-4] #> ========================= #>   Initial solution: #>     - Maximum discrepancy = 4 #>     - Total discrepancy   = 4 #>   Try to find a better solution with OSQP. #>  #>   ----------------------------------------------------------------- #>              OSQP v0.6.3  -  Operator Splitting QP Solver #>                 (c) Bartolomeo Stellato,  Goran Banjac #>           University of Oxford  -  Stanford University 2021 #>   ----------------------------------------------------------------- #>   problem:  variables n = 2, constraints m = 3 #>             nnz(P) + nnz(A) = 6 #>   settings: linear system solver = qdldl, #>             eps_abs = 1.0e-06, eps_rel = 1.0e-06, #>             eps_prim_inf = 1.0e-07, eps_dual_inf = 1.0e-07, #>             rho = 1.00e-01 (adaptive), #>             sigma = 1.00e-09, alpha = 1.60, max_iter = 4000 #>             check_termination: on (interval 25), #>             scaling: off, scaled_termination: off #>             warm start: on, polish: on, time_limit: off #>    #>   iter  objective    pri res    dua res    rho        time #>      1  -1.3898e+00   6.04e-03   1.05e+00   1.00e-01   5.36e-05s #>     25  -1.9200e+00   5.09e-08   5.35e-07   1.00e-01   1.12e-04s #>   plsh  -1.9200e+00   0.00e+00   1.11e-16  ---------   1.76e-04s #>    #>   status:               solved #>   solution polish:      successful #>   number of iterations: 25 #>   optimal objective:    -1.9200 #>   run time:             1.76e-04s #>   optimal rho estimate: 4.88e-02 #>    #>   OSQP iteration 1: #>     - Maximum discrepancy = 0 #>     - Total discrepancy   = 0 #>   Valid solution (maximum discrepancy <= 0.001 = `validation_tol`). #>   Required polished solution achieved. #>  #>   -------------- #>   Problem Values #>   -------------- #>        name t time_val lower_bd upper_bd alter value_in value_out  dif rdif #>    Revenues 4  2022.75        0      Inf     1        8       9.6  1.6  0.2 #>    Expenses 4  2022.75        0      Inf     1       12       9.6 -2.4 -0.2 #>     Profits 4  2022.75     -Inf      Inf     0        0       0.0  0.0   NA #>  #>   ---------------------------------- #>   Problem Constraints (l <= Ax <= u) #>   ---------------------------------- #>   Balancing Constraints #>   --------------------- #>               name t time_val l u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Accounting Rule 4  2022.75 0 0    -4      0        4         0          0.001      FALSE #>   Period Value Bounds #>   ------------------- #>        name t time_val l   u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Revenues 4  2022.75 0 Inf     8    9.6        0         0          0.001      FALSE #>    Expenses 4  2022.75 0 Inf    12    9.6        0         0          0.001      FALSE #>  #>  #>  #> Balancing period [2023-1] #> ========================= #>   Initial solution: #>     - Maximum discrepancy = 10 #>     - Total discrepancy   = 10 #>   Try to find a better solution with OSQP. #>  #>   ----------------------------------------------------------------- #>              OSQP v0.6.3  -  Operator Splitting QP Solver #>                 (c) Bartolomeo Stellato,  Goran Banjac #>           University of Oxford  -  Stanford University 2021 #>   ----------------------------------------------------------------- #>   problem:  variables n = 1, constraints m = 2 #>             nnz(P) + nnz(A) = 3 #>   settings: linear system solver = qdldl, #>             eps_abs = 1.0e-06, eps_rel = 1.0e-06, #>             eps_prim_inf = 1.0e-07, eps_dual_inf = 1.0e-07, #>             rho = 1.00e-01 (adaptive), #>             sigma = 1.00e-09, alpha = 1.60, max_iter = 4000 #>             check_termination: on (interval 25), #>             scaling: off, scaled_termination: off #>             warm start: on, polish: on, time_limit: off #>    #>   iter  objective    pri res    dua res    rho        time #>      1  -6.1701e-02   1.19e+00   1.21e+02   1.00e-01   6.38e-05s #>     50  -9.5062e-01   1.37e-10   1.41e-10   1.00e-01   1.28e-04s #>   plsh  -9.5062e-01   0.00e+00   0.00e+00  ---------   1.94e-04s #>    #>   status:               solved #>   solution polish:      successful #>   number of iterations: 50 #>   optimal objective:    -0.9506 #>   run time:             1.94e-04s #>   optimal rho estimate: 1.39e-01 #>    #>   OSQP iteration 1: #>     - Maximum discrepancy = 7.105427e-15 #>     - Total discrepancy   = 7.105427e-15 #>   Valid solution (maximum discrepancy <= 0.001 = `validation_tol`). #>   Required polished solution achieved. #>  #>   -------------- #>   Problem Values #>   -------------- #>        name t time_val lower_bd upper_bd alter value_in value_out dif      rdif #>    Revenues 5     2023        0      Inf     1        0         0   0        NA #>    Expenses 5     2023        0      Inf     1       45        55  10 0.2222222 #>     Profits 5     2023     -Inf      Inf     0      -55       -55   0 0.0000000 #>  #>   ---------------------------------- #>   Problem Constraints (l <= Ax <= u) #>   ---------------------------------- #>   Balancing Constraints #>   --------------------- #>               name t time_val   l   u Ax_in Ax_out discr_in    discr_out validation_tol unmet_flag #>    Accounting Rule 5     2023 -55 -55   -45    -55       10 7.105427e-15          0.001      FALSE #>   Period Value Bounds #>   ------------------- #>        name t time_val l   u Ax_in Ax_out discr_in discr_out validation_tol unmet_flag #>    Expenses 5     2023 0 Inf    45     55        0         0          0.001      FALSE #>   # Initial data my_series1 #>         Revenues Expenses Profits #> 2022 Q1       15       10      10 #> 2022 Q2        4        8      -1 #> 2022 Q3      250      250       5 #> 2022 Q4        8       12       0 #> 2023 Q1        0       45     -55  # Reconciled data out_balanced1$out_ts #>         Revenues Expenses Profits #> 2022 Q1     18.0      8.0      10 #> 2022 Q2      5.0      6.0      -1 #> 2022 Q3    252.5    247.5       5 #> 2022 Q4      9.6      9.6       0 #> 2023 Q1      0.0     55.0     -55  # Check for invalid solutions any(out_balanced1$proc_grp_df$sol_status_val < 0) #> [1] FALSE  # Display the maximum output constraint discrepancies out_balanced1$proc_grp_df[, c(\"proc_grp_label\", \"max_discr\")] #>   proc_grp_label    max_discr #> 1         2022-1 0.000000e+00 #> 2         2022-2 0.000000e+00 #> 3         2022-3 0.000000e+00 #> 4         2022-4 0.000000e+00 #> 5         2023-1 7.105427e-15   # The solution returned by `tsbalancing()` corresponds to equal proportional changes  # (pro-rating) and is related to the default alterability coefficients of 1. Equal  # absolute changes could be obtained instead by specifying alterability coefficients  # equal to the inverse of the initial values.  # # Let’s do this for the processing group 2022Q2 (`timeVal = 2022.25`), with the default  # displayed level of information (`display_level = 1`).   my_specs1b <- rbind(cbind(my_specs1,                            data.frame(timeVal = rep(NA_real_, nrow(my_specs1)))),                     data.frame(type = rep(NA, 2),                                col = c(\"Revenues\", \"Expenses\"),                                row = rep(\"Alterability Coefficient\", 2),                                coef = c(0.25, 0.125),                                timeVal = rep(2022.25, 2))) my_specs1b #>       type      col                      row   coef timeVal #> 1       EQ     <NA>          Accounting Rule     NA      NA #> 2     <NA> Revenues          Accounting Rule  1.000      NA #> 3     <NA> Expenses          Accounting Rule -1.000      NA #> 4     <NA>  Profits          Accounting Rule -1.000      NA #> 5    alter     <NA> Alterability Coefficient     NA      NA #> 6     <NA>  Profits Alterability Coefficient  0.000      NA #> 7  lowerBd     <NA>              Lower Bound     NA      NA #> 8     <NA> Revenues              Lower Bound  0.000      NA #> 9     <NA> Expenses              Lower Bound  0.000      NA #> 10    <NA> Revenues Alterability Coefficient  0.250 2022.25 #> 11    <NA> Expenses Alterability Coefficient  0.125 2022.25  out_balanced1b <- tsbalancing(in_ts = my_series1,                               problem_specs_df = my_specs1b) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsbalancing() function: #>     in_ts                    = my_series1 #>     problem_specs_df         = my_specs1b #>     temporal_grp_periodicity = 1 (default) #>     temporal_grp_start       (ignored) #>     osqp_settings_df         = default_osqp_sequence (default) #>     display_level            = 1 (default) #>     alter_pos                = 1 (default) #>     alter_neg                = 1 (default) #>     alter_mix                = 1 (default) #>     alter_temporal           (ignored) #>     lower_bound              = -Inf (default) #>     upper_bound              = Inf (default) #>     tolV                     = 0 (default) #>     tolV_temporal            (ignored) #>     (*)validation_tol        = 0.001 (default) #>     (*)trunc_to_zero_tol     = validation_tol (default) #>     (*)validation_only       = FALSE (default) #>     (*)quiet                 = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Balancing Problem Elements #> ========================== #>  #>  #>   Balancing Constraints (1) #>   ------------------------- #>  #>   Accounting Rule: #>     Revenues - Expenses - Profits == 0 #>  #>  #>   Time Series Info #>   ---------------- #>  #>         name lowerBd                 upperBd           alter                   #>   1 Revenues       0 (problem specs)     Inf (default)     1 * (default)       #>   2 Expenses       0 (problem specs)     Inf (default)     1 * (default)       #>   3  Profits    -Inf (default)           Inf (default)     0   (problem specs) #>  #>   * indicates cases where period-specific values (`timeVal` is not `NA`) are specified in the problem specs data frame. #>  #>  #>  #> Balancing period [2022-1] #> ========================= #>  #>  #> Balancing period [2022-2] #> ========================= #>  #>  #> Balancing period [2022-3] #> ========================= #>  #>  #> Balancing period [2022-4] #> ========================= #>  #>  #> Balancing period [2023-1] #> =========================  # Display the initial 2022Q2 values and both solutions cbind(data.frame(Status = c(\"initial\", \"pro-rating\", \"equal change\")),       rbind(as.data.frame(my_series1[2, , drop = FALSE]),              as.data.frame(out_balanced1$out_ts[2, , drop = FALSE]),             as.data.frame(out_balanced1b$out_ts[2, , drop = FALSE])),       data.frame(Accounting_discr = c(my_series1[2, 1] - my_series1[2, 2] -                                          my_series1[2, 3],                                       out_balanced1$out_ts[2, 1] -                                          out_balanced1$out_ts[2, 2] -                                          out_balanced1$out_ts[2, 3],                                       out_balanced1b$out_ts[2, 1] -                                          out_balanced1b$out_ts[2, 2] -                                          out_balanced1b$out_ts[2, 3]),                  RelChg_Rev = c(NA,                                  out_balanced1$out_ts[2, 1] / my_series1[2, 1] - 1,                                 out_balanced1b$out_ts[2, 1] / my_series1[2, 1] - 1),                  RelChg_Exp = c(NA,                                  out_balanced1$out_ts[2, 2] / my_series1[2, 2] - 1,                                 out_balanced1b$out_ts[2, 2] / my_series1[2, 2] - 1),                  AbsChg_Rev = c(NA,                                  out_balanced1$out_ts[2, 1] - my_series1[2, 1],                                 out_balanced1b$out_ts[2, 1] - my_series1[2, 1]),                  AbsChg_Exp = c(NA,                                  out_balanced1$out_ts[2, 2] - my_series1[2, 2],                                 out_balanced1b$out_ts[2, 2] - my_series1[2, 2]))) #>         Status Revenues Expenses Profits Accounting_discr RelChg_Rev RelChg_Exp #> 1      initial      4.0      8.0      -1               -3         NA         NA #> 2   pro-rating      5.0      6.0      -1                0      0.250    -0.2500 #> 3 equal change      5.5      6.5      -1                0      0.375    -0.1875 #>   AbsChg_Rev AbsChg_Exp #> 1         NA         NA #> 2        1.0       -2.0 #> 3        1.5       -1.5   ########### # Example 2: In this second example, consider the simulated data on quarterly  #            vehicle sales by region (West, Centre and East), along with a national  #            total for the three regions, and by type of vehicles (cars, trucks and  #            a total that may include other types of vehicles). The input data correspond  #            to directly seasonally adjusted data that have been benchmarked to the  #            annual totals of the corresponding unadjusted time series data as part  #            of the seasonal adjustment process (e.g., with the FORCE spec in the  #            X-13ARIMA-SEATS software).  # #            The objective is to reconcile the regional sales to the national sales  #            without modifying the latter while ensuring that the sum of the sales of  #            cars and trucks do not exceed 95% of the sales for all types of vehicles  #            in any quarter. For illustrative purposes, we assume that the sales of  #            trucks in the Centre region for the 2nd quarter of 2022 cannot be modified.  # Problem specifications my_specs2 <- data.frame(      type = c(\"EQ\", rep(NA, 4),            \"EQ\", rep(NA, 4),            \"EQ\", rep(NA, 4),            \"LE\", rep(NA, 3),            \"LE\", rep(NA, 3),            \"LE\", rep(NA, 3),            \"alter\", rep(NA, 4)),      col = c(NA, \"West_AllTypes\", \"Centre_AllTypes\", \"East_AllTypes\", \"National_AllTypes\",            NA, \"West_Cars\", \"Centre_Cars\", \"East_Cars\", \"National_Cars\",            NA, \"West_Trucks\", \"Centre_Trucks\", \"East_Trucks\", \"National_Trucks\",            NA, \"West_Cars\", \"West_Trucks\", \"West_AllTypes\",            NA, \"Centre_Cars\", \"Centre_Trucks\", \"Centre_AllTypes\",            NA, \"East_Cars\", \"East_Trucks\", \"East_AllTypes\",           NA, \"National_AllTypes\", \"National_Cars\", \"National_Trucks\", \"Centre_Trucks\"),      row = c(rep(\"National Total - All Types\", 5),           rep(\"National Total - Cars\", 5),           rep(\"National Total - Trucks\", 5),           rep(\"West Region Sum\", 4),           rep(\"Center Region Sum\", 4),           rep(\"East Region Sum\", 4),           rep(\"Alterability Coefficient\", 5)),      coef = c(NA, 1, 1, 1, -1,            NA, 1, 1, 1, -1,            NA, 1, 1, 1, -1,            NA, 1, 1, -.95,            NA, 1, 1, -.95,            NA, 1, 1, -.95,            NA, 0, 0, 0, 0),      time_val = c(rep(NA, 31), 2022.25))  # Beginning and end of the specifications data frame head(my_specs2, n = 10) #>    type               col                        row coef time_val #> 1    EQ              <NA> National Total - All Types   NA       NA #> 2  <NA>     West_AllTypes National Total - All Types    1       NA #> 3  <NA>   Centre_AllTypes National Total - All Types    1       NA #> 4  <NA>     East_AllTypes National Total - All Types    1       NA #> 5  <NA> National_AllTypes National Total - All Types   -1       NA #> 6    EQ              <NA>      National Total - Cars   NA       NA #> 7  <NA>         West_Cars      National Total - Cars    1       NA #> 8  <NA>       Centre_Cars      National Total - Cars    1       NA #> 9  <NA>         East_Cars      National Total - Cars    1       NA #> 10 <NA>     National_Cars      National Total - Cars   -1       NA tail(my_specs2) #>     type               col                      row  coef time_val #> 27  <NA>     East_AllTypes          East Region Sum -0.95       NA #> 28 alter              <NA> Alterability Coefficient    NA       NA #> 29  <NA> National_AllTypes Alterability Coefficient  0.00       NA #> 30  <NA>     National_Cars Alterability Coefficient  0.00       NA #> 31  <NA>   National_Trucks Alterability Coefficient  0.00       NA #> 32  <NA>     Centre_Trucks Alterability Coefficient  0.00  2022.25  # Problem data my_series2 <- ts(   matrix(c(43, 49, 47, 136, 20, 18, 12, 53, 20, 22, 26, 61,            40, 45, 42, 114, 16, 16, 19, 44, 21, 26, 21, 59,            35, 47, 40, 133, 14, 15, 16, 50, 19, 25, 19, 71,            44, 44, 45, 138, 19, 20, 14, 52, 21, 18, 27, 74,            46, 48, 55, 135, 16, 15, 19, 51, 27, 25, 28, 54),          ncol = 12,          byrow = TRUE,          dimnames = list(NULL,                           c(\"West_AllTypes\", \"Centre_AllTypes\", \"East_AllTypes\",                             \"National_AllTypes\", \"West_Cars\", \"Centre_Cars\",                             \"East_Cars\", \"National_Cars\", \"West_Trucks\",                             \"Centre_Trucks\", \"East_Trucks\", \"National_Trucks\"))),   start = c(2022, 1),   frequency = 4)  # Reconcile without displaying the function header and enforce nonnegative data out_balanced2 <- tsbalancing(   in_ts                    = my_series2,   problem_specs_df         = my_specs2,   temporal_grp_periodicity = frequency(my_series2),   lower_bound              = 0,   quiet                    = TRUE) #>  #>  #> Balancing periods [2022-1 - 2022-4] #> =================================== #>  #>  #> Balancing period [2023-1] #> =========================  # Initial data my_series2 #>         West_AllTypes Centre_AllTypes East_AllTypes National_AllTypes West_Cars #> 2022 Q1            43              49            47               136        20 #> 2022 Q2            40              45            42               114        16 #> 2022 Q3            35              47            40               133        14 #> 2022 Q4            44              44            45               138        19 #> 2023 Q1            46              48            55               135        16 #>         Centre_Cars East_Cars National_Cars West_Trucks Centre_Trucks #> 2022 Q1          18        12            53          20            22 #> 2022 Q2          16        19            44          21            26 #> 2022 Q3          15        16            50          19            25 #> 2022 Q4          20        14            52          21            18 #> 2023 Q1          15        19            51          27            25 #>         East_Trucks National_Trucks #> 2022 Q1          26              61 #> 2022 Q2          21              59 #> 2022 Q3          19              71 #> 2022 Q4          27              74 #> 2023 Q1          28              54  # Reconciled data out_balanced2$out_ts #>         West_AllTypes Centre_AllTypes East_AllTypes National_AllTypes West_Cars #> 2022 Q1      42.10895        47.63734      46.25371               136  21.15646 #> 2022 Q2      35.31121        41.40859      37.28019               114  14.00517 #> 2022 Q3      38.89464        50.58071      43.52465               133  15.24054 #> 2022 Q4      45.68520        45.37335      46.94145               138  18.59783 #> 2023 Q1      41.67785        43.48993      49.83221               135  16.32000 #>         Centre_Cars East_Cars National_Cars West_Trucks Centre_Trucks #> 2022 Q1    19.13355  12.70999            53    18.56134      18.59359 #> 2022 Q2    13.33816  16.65666            44    16.61497      26.00000 #> 2022 Q3    16.84858  17.91088            50    21.70936      27.22926 #> 2022 Q4    19.67970  13.72247            52    24.11433      19.17715 #> 2023 Q1    15.30000  19.38000            51    18.22500      16.87500 #>         East_Trucks National_Trucks #> 2022 Q1    23.84507              61 #> 2022 Q2    16.38503              59 #> 2022 Q3    22.06138              71 #> 2022 Q4    30.70852              74 #> 2023 Q1    18.90000              54  # Check for invalid solutions any(out_balanced2$proc_grp_df$sol_status_val < 0) #> [1] FALSE  # Display the maximum output constraint discrepancies out_balanced2$proc_grp_df[, c(\"proc_grp_label\", \"max_discr\")] #>    proc_grp_label    max_discr #> 1 2022-1 - 2022-4 2.842171e-14 #> 2          2023-1 0.000000e+00   ########### # Example 3: Reproduce the `tsraking_driver()` 2nd example with `tsbalancing()`  #            (1-dimensional raking problem with annual total preservation).  # `tsraking()` metadata my_metadata3 <- data.frame(series = c(\"cars_alb\", \"cars_sask\", \"cars_man\"),                            total1 = rep(\"cars_tot\", 3)) my_metadata3 #>      series   total1 #> 1  cars_alb cars_tot #> 2 cars_sask cars_tot #> 3  cars_man cars_tot  # `tsbalancing()` problem specifications my_specs3 <- rkMeta_to_blSpecs(my_metadata3) my_specs3 #>     type       col                         row coef timeVal #> 1     EQ      <NA> Marginal Total 1 (cars_tot)   NA      NA #> 2   <NA>  cars_alb Marginal Total 1 (cars_tot)    1      NA #> 3   <NA> cars_sask Marginal Total 1 (cars_tot)    1      NA #> 4   <NA>  cars_man Marginal Total 1 (cars_tot)    1      NA #> 5   <NA>  cars_tot Marginal Total 1 (cars_tot)   -1      NA #> 6  alter      <NA>   Period Value Alterability   NA      NA #> 7   <NA>  cars_alb   Period Value Alterability    1      NA #> 8   <NA> cars_sask   Period Value Alterability    1      NA #> 9   <NA>  cars_man   Period Value Alterability    1      NA #> 10  <NA>  cars_tot   Period Value Alterability    0      NA  # Problem data my_series3 <- ts(matrix(c(14, 18, 14, 58,                           17, 14, 16, 44,                           14, 19, 18, 58,                           20, 18, 12, 53,                           16, 16, 19, 44,                           14, 15, 16, 50,                           19, 20, 14, 52,                           16, 15, 19, 51),                         ncol = 4,                         byrow = TRUE,                         dimnames = list(NULL, c(\"cars_alb\", \"cars_sask\",                                                 \"cars_man\", \"cars_tot\"))),                  start = c(2019, 2),                  frequency = 4)  # Reconcile the data with `tsraking()` (through `tsraking_driver()`) out_raked3 <- tsraking_driver(in_ts = my_series3,                               metadata_df = my_metadata3,                               temporal_grp_periodicity = frequency(my_series3),                               quiet = TRUE) #>  #>  #> Raking period [2019-2] #> ====================== #>  #>  #> Raking period [2019-3] #> ====================== #>  #>  #> Raking period [2019-4] #> ====================== #>  #>  #> Raking periods [2020-1 - 2020-4] #> ================================ #>  #>  #> Raking period [2021-1] #> ======================  # Reconcile the data with `tsbalancing()` out_balanced3 <- tsbalancing(in_ts = my_series3,                              problem_specs_df = my_specs3,                              temporal_grp_periodicity = frequency(my_series3),                              quiet = TRUE) #>  #>  #> Balancing period [2019-2] #> ========================= #>  #>  #> Balancing period [2019-3] #> ========================= #>  #>  #> Balancing period [2019-4] #> ========================= #>  #>  #> Balancing periods [2020-1 - 2020-4] #> =================================== #>  #>  #> Balancing period [2021-1] #> =========================  # Initial data my_series3 #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2       14        18       14       58 #> 2019 Q3       17        14       16       44 #> 2019 Q4       14        19       18       58 #> 2020 Q1       20        18       12       53 #> 2020 Q2       16        16       19       44 #> 2020 Q3       14        15       16       50 #> 2020 Q4       19        20       14       52 #> 2021 Q1       16        15       19       51  # Both sets of reconciled data out_raked3 #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 17.65217  22.69565 17.65217       58 #> 2019 Q3 15.91489  13.10638 14.97872       44 #> 2019 Q4 15.92157  21.60784 20.47059       58 #> 2020 Q1 21.15283  19.04513 12.80204       53 #> 2020 Q2 13.74700  13.75373 16.49927       44 #> 2020 Q3 15.50782  16.62184 17.87034       50 #> 2020 Q4 18.59234  19.57931 13.82835       52 #> 2021 Q1 16.32000  15.30000 19.38000       51 out_balanced3$out_ts #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 17.65217  22.69565 17.65217       58 #> 2019 Q3 15.91489  13.10638 14.97872       44 #> 2019 Q4 15.92157  21.60784 20.47059       58 #> 2020 Q1 21.15283  19.04513 12.80204       53 #> 2020 Q2 13.74700  13.75373 16.49927       44 #> 2020 Q3 15.50782  16.62184 17.87034       50 #> 2020 Q4 18.59234  19.57931 13.82835       52 #> 2021 Q1 16.32000  15.30000 19.38000       51  # Check for invalid `tsbalancing()` solutions any(out_balanced3$proc_grp_df$sol_status_val < 0) #> [1] FALSE  # Display the maximum output constraint discrepancies from the `tsbalancing()` solutions out_balanced3$proc_grp_df[, c(\"proc_grp_label\", \"max_discr\")] #>    proc_grp_label    max_discr #> 1          2019-2 0.000000e+00 #> 2          2019-3 0.000000e+00 #> 3          2019-4 0.000000e+00 #> 4 2020-1 - 2020-4 7.105427e-15 #> 5          2021-1 0.000000e+00  # Confirm that both solutions (`tsraking() and `tsbalancing()`) are the same all.equal(out_raked3, out_balanced3$out_ts) #> [1] TRUE"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsDF_to_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","title":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","text":"Convert (non-stacked) time series data frame (benchmarking() stock_benchmarking() data format) \"ts\" (\"mts\") object. function useful convert benchmarked data frame returned call benchmarking() stock_benchmarking() \"ts\" object, one several series benchmarked non -group processing mode. Stacked time series data frames associated executions -group mode must first unstacked unstack_tsDF().","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsDF_to_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","text":"","code":"tsDF_to_ts(   ts_df,   frequency,   yr_cName = \"year\",   per_cName = \"period\" )"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsDF_to_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","text":"ts_df (mandatory) Data frame, object coerced one, converted. frequency (mandatory) Integer specifying frequency time series converted. frequency time series corresponds maximum number periods year (12 monthly data, 4 quarterly data, 1 annual data). yr_cName, per_cName (optional) Strings specifying name numeric variables (columns) input data frame contain data point year period identifiers. Default values yr_cName = \"year\" per_cName   = \"period\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsDF_to_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","text":"function returns time series object (\"ts\" \"mts\"), can explicitly coerced another type object appropriate *() function (e.g., tsibble::as_tsibble() coerce tsibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/tsDF_to_ts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reciprocal function of ts_to_tsDF() — tsDF_to_ts","text":"","code":"# Initial quarterly time series (indicator series to be benchmarked) qtr_ts <- ts(c(1.9, 2.4, 3.1, 2.2, 2.0, 2.6, 3.4, 2.4, 2.3),              start = c(2015, 1), frequency = 4)  # Annual time series (benchmarks) ann_ts <- ts(c(10.3, 10.2), start = 2015, frequency = 1)   # Proportional benchmarking out_bench <- benchmarking(ts_to_tsDF(qtr_ts),                           ts_to_bmkDF(ann_ts, ind_frequency = 4),                           rho = 0.729, lambda = 1, biasOption = 3,                           quiet = TRUE)  # Initial and final (benchmarked) quarterly time series (\"ts\" objects) qtr_ts #>      Qtr1 Qtr2 Qtr3 Qtr4 #> 2015  1.9  2.4  3.1  2.2 #> 2016  2.0  2.6  3.4  2.4 #> 2017  2.3                tsDF_to_ts(out_bench$series, frequency = 4) #>          Qtr1     Qtr2     Qtr3     Qtr4 #> 2015 2.049326 2.601344 3.337638 2.311691 #> 2016 2.021090 2.554801 3.292193 2.331915 #> 2017 2.268017                              # Proportional end-of-year stock benchmarking - multiple (3) series processed  # with argument `by` (in BY-group mode) qtr_mts <- ts.union(ser1 = qtr_ts,     ser2 = qtr_ts * 100, ser3 = qtr_ts * 10) ann_mts <- ts.union(ser1 = ann_ts / 4, ser2 = ann_ts * 25,  ser3 = ann_ts * 2.5) out_bench2 <- stock_benchmarking(stack_tsDF(ts_to_tsDF(qtr_mts)),                                  stack_bmkDF(ts_to_bmkDF(                                    ann_mts, ind_frequency = 4,                                    discrete_flag = TRUE, alignment = \"e\")),                                  rho = 0.729, lambda = 1, biasOption = 3,                                  by = \"series\",                                  quiet = TRUE) #>  #> Benchmarking by-group 1 (series=ser1) #> ===================================== #>  #> Benchmarking by-group 2 (series=ser2) #> ===================================== #>  #> Benchmarking by-group 3 (series=ser3) #> =====================================  # Initial and final (benchmarked) quarterly time series (\"mts\" objects) qtr_mts #>         ser1 ser2 ser3 #> 2015 Q1  1.9  190   19 #> 2015 Q2  2.4  240   24 #> 2015 Q3  3.1  310   31 #> 2015 Q4  2.2  220   22 #> 2016 Q1  2.0  200   20 #> 2016 Q2  2.6  260   26 #> 2016 Q3  3.4  340   34 #> 2016 Q4  2.4  240   24 #> 2017 Q1  2.3  230   23 tsDF_to_ts(unstack_tsDF(out_bench2$series), frequency = 4) #>             ser1     ser2     ser3 #> 2015 Q1 2.172021 217.2021 21.72021 #> 2015 Q2 2.784446 278.4446 27.84446 #> 2015 Q3 3.633922 363.3922 36.33922 #> 2015 Q4 2.575000 257.5000 25.75000 #> 2016 Q1 2.298694 229.8694 22.98694 #> 2016 Q2 2.903718 290.3718 29.03718 #> 2016 Q3 3.685986 368.5986 36.85986 #> 2016 Q4 2.550000 255.0000 25.50000 #> 2017 Q1 2.437793 243.7793 24.37793"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"Replication G-Series 2.0 SAS\\(^\\circledR\\) TSRAKING procedure (PROC TSRAKING). See G-Series 2.0 documentation details (Statistics Canada 2016). function restore cross-sectional aggregation constraints system time series. aggregation constraints may come 1 2-dimensional table. Optionally, temporal constraints can also preserved. tsraking() usually called practice tsraking_driver() order reconcile periods time series system single function call.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"","code":"tsraking(   data_df,   metadata_df,   alterability_df = NULL,   alterSeries = 1,   alterTotal1 = 0,   alterTotal2 = 0,   alterAnnual = 0,   tolV = 0.001,   tolP = NA,   warnNegResult = TRUE,   tolN = -0.001,   id = NULL,   verbose = FALSE,    # New in G-Series 3.0   Vmat_option = 1,   warnNegInput = TRUE,   quiet = FALSE )"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"data_df (mandatory) Data frame, object coerced one, contains time series data reconciled. must minimally contain variables corresponding component series cross-sectional control totals specified metadata data frame (argument metadata_df). one observation (period) provided, sum provided component series values also preserved part implicit temporal constraints. metadata_df (mandatory) Data frame, object coerced one, describes cross-sectional aggregation constraints (additivity rules) raking problem. Two character variables must included metadata data frame: series total1. Two variables optional: total2 (character) alterAnnual (numeric). values variable series represent variable names component series input time series data frame (argument data_df). Similarly, values variables total1 total2 represent variable names 1st 2nd dimension cross-sectional control totals input time series data frame. Variable alterAnnual contains alterability coefficient temporal constraint associated component series. specified, latter override default alterability coefficient specified argument alterAnnual. alterability_df (optional) Data frame, object coerced one, NULL, contains alterability coefficients variables. must correspond component series cross-sectional control total, , variable name must exist input time series data frame (argument data_df). values alterability coefficients override default alterability coefficients specified arguments alterSeries, alterTotal1 alterTotal2. input time series data frame contains several observations alterability coefficients data frame contains one, alterability coefficients used (repeated) observations input time series data frame. Alternatively, alterability coefficients data frame may contain many observations input time series data frame. Default value alterability_df = NULL (default alterability coefficients). alterSeries (optional) Nonnegative real number specifying default alterability coefficient component series values. apply component series alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterSeries = 1.0 (nonbinding component series values). alterTotal1 (optional) Nonnegative real number specifying default alterability coefficient 1st dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal1 = 0.0 (binding 1st dimension cross-sectional control totals) alterTotal2 (optional) Nonnegative real number specifying default alterability coefficient 2nd dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal2 = 0.0 (binding 2nd dimension cross-sectional control totals). alterAnnual (optional) Nonnegative real number specifying default alterability coefficient component series temporal constraints (e.g., annual totals). apply component series alterability coefficients already specified metadata data frame (argument metadata_df). Default value alterAnnual = 0.0 (binding temporal control totals). tolV, tolP (optional) Nonnegative real number, NA, specifying tolerance, absolute value percentage, used performing ultimate test case binding totals (alterability coefficient \\(0.0\\) temporal cross-sectional control totals). test compares input binding control totals ones calculated reconciled (output) component series. Arguments tolV tolP specified together (one must specified must NA). Example: set tolerance 10 units, specify tolV = 10, tolP = NA; set tolerance 1%, specify tolV = NA, tolP = 0.01. Default values tolV = 0.001 tolP = NA. warnNegResult (optional) Logical argument specifying whether warning message generated negative value created function reconciled (output) series smaller threshold specified argument tolN. Default value warnNegResult = TRUE. tolN (optional) Negative real number specifying threshold identification negative values. value considered negative smaller threshold. Default value tolN = -0.001. id (optional) String vector (minimum length 1), NULL, specifying name additional variables transferred input time series data frame (argument data_df) output time series data frame, object returned function (see section Value). default, output series data frame contains variables listed metadata data frame (argument metadata_df). Default value id = NULL. verbose (optional) Logical argument specifying whether information intermediate steps execution time (real time, CPU time) displayed. Note specifying argument quiet = TRUE nullify argument verbose. Default value verbose = FALSE. Vmat_option (optional) Specification option variance matrices (\\(V_e\\) \\(V_\\epsilon\\); see section Details): See Ferland (2016) subsection Arguments Vmat_option warnNegInput section Details information. Default value Vmat_option = 1. warnNegInput (optional) Logical argument specifying whether warning message generated negative value smaller threshold specified argument tolN found input time series data frame (argument data_df). Default value warnNegInput = TRUE. quiet (optional) Logical argument specifying whether display essential information warnings errors. Specifying quiet = TRUE also nullify argument verbose equivalent wrapping tsraking() call suppressMessages(). Default value quiet = FALSE.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"function returns data frame containing reconciled component series, reconciled cross-sectional control totals variables specified  argument id. Note \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"function returns generalized least squared solution specific, simple variant general regression-based raking model proposed Dagum Cholette (Dagum Cholette 2006). model, matrix form, : $$\\displaystyle \\begin{bmatrix} x \\\\ g \\end{bmatrix} = \\begin{bmatrix} \\\\ G \\end{bmatrix} \\theta + \\begin{bmatrix} e \\\\ \\varepsilon \\end{bmatrix} $$ \\(x\\) vector initial component series values. \\(\\theta\\) vector final (reconciled) component series values. \\(e \\sim \\left( 0, V_e \\right)\\) vector measurement errors \\(x\\) covariance matrix \\(V_e = \\mathrm{diag} \\left( c_x x \\right)\\), \\(V_e = \\mathrm{diag} \\left( \\left| c_x x \\right| \\right)\\) argument Vmat_option = 2, \\(c_x\\) vector alterability coefficients \\(x\\). \\(g\\) vector initial control totals, including component series temporal totals (applicable). \\(\\varepsilon \\sim (0, V_\\varepsilon)\\) vector measurement errors \\(g\\) covariance matrix \\(V_\\varepsilon = \\mathrm{diag} \\left( c_g g \\right)\\), \\(V_\\varepsilon = \\mathrm{diag} \\left( \\left| c_g g \\right| \\right)\\) argument Vmat_option = 2, \\(c_g\\) vector alterability coefficients \\(g\\). \\(G\\) matrix aggregation constraints, including implicit temporal constraints (applicable). generalized least squared solution : $$\\displaystyle \\hat{\\theta} = x + V_e G^{\\mathrm{T}} \\left( G V_e G^{\\mathrm{T}} + V_\\varepsilon \\right)^+ \\left( g - G x \\right) $$ \\(^{+}\\) designates Moore-Penrose inverse matrix \\(\\). tsraking() solves single raking problem, .e., either single period time series system, single temporal group (e.g., periods given year) temporal total preservation required. Several call tsraking() therefore necessary order reconcile periods time series system. tsraking_driver() can achieve single call: conveniently determines required set raking problems solved internally generates individual calls tsraking().","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"alterability-coefficients","dir":"Reference","previous_headings":"","what":"Alterability Coefficients","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"Alterability coefficients \\(c_x\\) \\(c_g\\) conceptually represent measurement errors associated input component series values \\(x\\) control totals \\(g\\) respectively. nonnegative real numbers , practice, specify extent initial value can modified relation values. Alterability coefficients \\(0.0\\) define fixed (binding) values alterability coefficients greater \\(0.0\\) define free (nonbinding) values. Increasing alterability coefficient intial value results changes value reconciled (output) data , conversely, less changes decreasing alterability coefficient. default alterability coefficients \\(1.0\\) component series values \\(0.0\\) cross-sectional control totals , applicable, component series temporal totals. default alterability coefficients result proportional allocation discrepancies component series. Setting component series alterability coefficients inverse component series initial values result uniform allocation discrepancies instead. Almost binding totals can obtained practice specifying small (almost \\(0.0\\)) alterability coefficients relative (nonbinding) component series. Temporal total preservation refers fact temporal totals, applicable, usually kept “close possible” initial value. Pure preservation achieved default binding temporal totals change minimized nonbinding temporal totals (accordance set alterability coefficients).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"arguments-vmat-option-and-warnneginput","dir":"Reference","previous_headings":"","what":"Arguments Vmat_option and warnNegInput","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"arguments allow alternative handling negative values input data, similar tsbalancing(). default values correspond G-Series 2.0 behaviour (SAS\\(^\\circledR\\) PROC TSRAKING) equivalent options defined. latter developed \"nonnegative input data \" mind, similar SAS\\(^\\circledR\\) PROC BENCHMARKING G-Series 2.0 allow negative values either proportional benchmarking, explains \"suspicious use proportional raking\" warning presence negative values PROC TSRAKING G-Series 2.0 warnNegInput = TRUE (default). However, (proportional) raking presence negative values generally works well Vmat_option = 2 produces reasonable, intuitive solutions. E.g., default Vmat_option = 1 fails solving constraint + B = C input data = 2, B = -2, C = 1 default alterability coefficients, Vmat_option = 2 returns (intuitive) solution = 2.5, B = -1.5, C = 1 (25% increase B). See Ferland (2016) details.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"treatment-of-missing-na-values","dir":"Reference","previous_headings":"","what":"Treatment of Missing (NA) Values","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"Missing values input time series data frame (argument data_df) alterability coefficients data frame (argument alterability_df) raking problem data (variables listed metadata data frame argument metadata_df) generate error message stop function execution.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"comparing-tsraking-and-tsbalancing-","dir":"Reference","previous_headings":"","what":"Comparing tsraking() and tsbalancing()","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"tsraking() limited one- two-dimensional aggregation table raking problems (temporal total preservation required) tsbalancing() handles general balancing problems (e.g., higher dimensional raking problems, nonnegative solutions, general linear equality inequality constraints opposed aggregation rules , etc.). tsraking() returns generalized least squared solution Dagum Cholette regression-based raking model (Dagum Cholette 2006) tsbalancing() solves corresponding quadratic minimization problem using numerical solver. cases, convergence minimum achieved tsbalancing() solution matches (exact) tsraking() least square solution. may case, however, convergence achieved reasonable number iterations. said , rare occasions tsbalancing() solution significantly differ tsraking() solution. tsbalancing() usually faster tsraking(), especially large raking problems, generally sensitive presence (small) inconsistencies input data associated redundant constraints fully specified (-specified) raking problems. tsraking() handles inconsistencies using Moore-Penrose inverse (uniform distribution among binding totals). tsbalancing() accommodates specification sparse problems reduced form. true case tsraking() aggregation rules must always fully specified since complete data cube without missing data expected input (every single inner-cube component series must contribute dimensions cube, .e., every single outer-cube marginal total series). tools handle negative values input data differently default. solutions raking problems obtained tsbalancing() tsraking() identical input data points positive, differ data points negative (unless argument Vmat_option = 2 specified tsraking()). tsbalancing() tsraking() allow preservation temporal totals, time management incorporated tsraking(). example, construction processing groups (sets periods raking problem) left user tsraking() separate calls must submitted processing group (raking problem). helper function tsraking_driver() comes handy tsraking(). tsbalancing() returns set series input time series object tsraking() returns set series involved raking problem plus specified argument id (correspond subset input series).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"Bérubé, J. S. Fortier (2009). \"PROC TSRAKING: -house SAS\\(^\\circledR\\) procedure balancing time series\". JSM Proceedings, Business Economic Statistics Section. Alexandria, VA: American Statistical Association. Dagum, E. B. P. Cholette (2006). Benchmarking, Temporal Distribution Reconciliation Methods Time Series. Springer-Verlag, New York, Lecture Notes Statistics, Vol. 186. Ferland, M. (2016). \"Negative Values PROC TSRAKING\". Internal document. Statistics Canada, Ottawa, Canada. Fortier, S. B. Quenneville (2009). \"Reconciliation Balancing Accounts Time Series\". JSM Proceedings, Business Economic Statistics Section. Alexandria, VA: American Statistical Association. Quenneville, B. S. Fortier (2012). \"Restoring Accounting Constraints Time Series – Methods Software Statistical Agency\". Economic Time Series: Modeling Seasonality. Chapman & Hall, New York. Statistics Canada (2016). \"TSRAKING Procedure\". G-Series 2.0 User Guide. Statistics Canada, Ottawa, Canada. Statistics Canada (2018). Theory Application Reconciliation (Course code 0437). Statistics Canada, Ottawa, Canada.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore cross-sectional (contemporaneous) aggregation constraints — tsraking","text":"","code":"########### # Example 1: Simple 1-dimensional raking problem where the values of `cars` and `vans` #            must sum up to the value of `total`.  # Problem metadata my_metadata1 <- data.frame(series = c(\"cars\", \"vans\"),                            total1 = c(\"total\", \"total\")) my_metadata1 #>   series total1 #> 1   cars  total #> 2   vans  total  # Problem data my_series1 <- data.frame(cars = 25, vans = 5, total = 40)  # Reconcile the data out_raked1 <- tsraking(my_series1, my_metadata1) #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = my_series1 #>     metadata_df     = my_metadata1 #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>   # Initial data my_series1 #>   cars vans total #> 1   25    5    40  # Reconciled data out_raked1 #>       cars     vans total #> 1 33.33333 6.666667    40  # Check the output cross-sectional constraint all.equal(rowSums(out_raked1[c(\"cars\", \"vans\")]), out_raked1$total) #> [1] TRUE  # Check the control total (fixed) all.equal(my_series1$total, out_raked1$total) #> [1] TRUE   ########### # Example 2: 2-dimensional raking problem similar to the 1st example but adding #            regional sales for the 3 prairie provinces (Alb., Sask. and Man.) #            and where the sales of vans in Sask. are non-alterable #            (alterability coefficient = 0), with `quiet = TRUE` to avoid #            displaying the function header.  # Problem metadata my_metadata2 <- data.frame(series = c(\"cars_alb\", \"cars_sask\", \"cars_man\",                                       \"vans_alb\", \"vans_sask\", \"vans_man\"),                            total1 = c(rep(\"cars_total\", 3),                                       rep(\"vans_total\", 3)),                            total2 = rep(c(\"alb_total\", \"sask_total\", \"man_total\"), 2)) my_metadata2 #>      series     total1     total2 #> 1  cars_alb cars_total  alb_total #> 2 cars_sask cars_total sask_total #> 3  cars_man cars_total  man_total #> 4  vans_alb vans_total  alb_total #> 5 vans_sask vans_total sask_total #> 6  vans_man vans_total  man_total  # Problem data my_series2 <- data.frame(cars_alb = 12, cars_sask = 14, cars_man = 13,                          vans_alb = 20, vans_sask = 20, vans_man = 24,                          alb_total = 30, sask_total = 31, man_total = 32,                          cars_total = 40, vans_total = 53)  # Reconciled data out_raked2 <- tsraking(my_series2, my_metadata2,                        alterability_df = data.frame(vans_sask = 0),                        quiet = TRUE)  # Initial data my_series2 #>   cars_alb cars_sask cars_man vans_alb vans_sask vans_man alb_total sask_total #> 1       12        14       13       20        20       24        30         31 #>   man_total cars_total vans_total #> 1        32         40         53  # Reconciled data out_raked2 #>   cars_alb cars_sask cars_man vans_alb vans_sask vans_man alb_total sask_total #> 1 14.31298        11 14.68702 15.68702        20 17.31298        30         31 #>   man_total cars_total vans_total #> 1        32         40         53  # Check the output cross-sectional constraints all.equal(rowSums(out_raked2[c(\"cars_alb\", \"cars_sask\", \"cars_man\")]), out_raked2$cars_total) #> [1] TRUE all.equal(rowSums(out_raked2[c(\"vans_alb\", \"vans_sask\", \"vans_man\")]), out_raked2$vans_total) #> [1] TRUE all.equal(rowSums(out_raked2[c(\"cars_alb\", \"vans_alb\")]), out_raked2$alb_total) #> [1] TRUE all.equal(rowSums(out_raked2[c(\"cars_sask\", \"vans_sask\")]), out_raked2$sask_total) #> [1] TRUE all.equal(rowSums(out_raked2[c(\"cars_man\", \"vans_man\")]), out_raked2$man_total) #> [1] TRUE  # Check the control totals (fixed) tot_cols <- union(unique(my_metadata2$total1), unique(my_metadata2$total2)) all.equal(my_series2[tot_cols], out_raked2[tot_cols]) #> [1] TRUE  # Check the value of vans in Saskatchewan (fixed at 20) all.equal(my_series2$vans_sask, out_raked2$vans_sask) #> [1] TRUE"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for tsraking() — tsraking_driver","title":"Helper function for tsraking() — tsraking_driver","text":"Helper function tsraking() function conveniently determines required set raking problems solved internally generates individual calls tsraking(). especially useful context temporal total (e.g., annual total) preservation individual raking problem either involves single period incomplete temporal groups (e.g., incomplete years) several periods complete temporal groups (e.g., set periods complete year).","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for tsraking() — tsraking_driver","text":"","code":"tsraking_driver(   in_ts,   ...,  # `tsraking()` arguments excluding `data_df`   temporal_grp_periodicity = 1,   temporal_grp_start = 1 )"},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for tsraking() — tsraking_driver","text":"in_ts (mandatory) Time series (\"ts\" \"mts\"), object coerced one, contains time series data reconciled. raking problems' input data (initial solutions). ... Arguments passed tsraking metadata_df (mandatory) Data frame, object coerced one, describes cross-sectional aggregation constraints (additivity rules) raking problem. Two character variables must included metadata data frame: series total1. Two variables optional: total2 (character) alterAnnual (numeric). values variable series represent variable names component series input time series data frame (argument data_df). Similarly, values variables total1 total2 represent variable names 1st 2nd dimension cross-sectional control totals input time series data frame. Variable alterAnnual contains alterability coefficient temporal constraint associated component series. specified, latter override default alterability coefficient specified argument alterAnnual. alterability_df (optional) Data frame, object coerced one, NULL, contains alterability coefficients variables. must correspond component series cross-sectional control total, , variable name must exist input time series data frame (argument data_df). values alterability coefficients override default alterability coefficients specified arguments alterSeries, alterTotal1 alterTotal2. input time series data frame contains several observations alterability coefficients data frame contains one, alterability coefficients used (repeated) observations input time series data frame. Alternatively, alterability coefficients data frame may contain many observations input time series data frame. Default value alterability_df = NULL (default alterability coefficients). alterSeries (optional) Nonnegative real number specifying default alterability coefficient component series values. apply component series alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterSeries = 1.0 (nonbinding component series values). alterTotal1 (optional) Nonnegative real number specifying default alterability coefficient 1st dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal1 = 0.0 (binding 1st dimension cross-sectional control totals) alterTotal2 (optional) Nonnegative real number specifying default alterability coefficient 2nd dimension cross-sectional control totals. apply cross-sectional control totals alterability coefficients already specified alterability coefficients data frame (argument alterability_df). Default value alterTotal2 = 0.0 (binding 2nd dimension cross-sectional control totals). alterAnnual (optional) Nonnegative real number specifying default alterability coefficient component series temporal constraints (e.g., annual totals). apply component series alterability coefficients already specified metadata data frame (argument metadata_df). Default value alterAnnual = 0.0 (binding temporal control totals). tolV,tolP (optional) Nonnegative real number, NA, specifying tolerance, absolute value percentage, used performing ultimate test case binding totals (alterability coefficient \\(0.0\\) temporal cross-sectional control totals). test compares input binding control totals ones calculated reconciled (output) component series. Arguments tolV tolP specified together (one must specified must NA). Example: set tolerance 10 units, specify tolV = 10, tolP = NA; set tolerance 1%, specify tolV = NA, tolP = 0.01. Default values tolV = 0.001 tolP = NA. warnNegResult (optional) Logical argument specifying whether warning message generated negative value created function reconciled (output) series smaller threshold specified argument tolN. Default value warnNegResult = TRUE. tolN (optional) Negative real number specifying threshold identification negative values. value considered negative smaller threshold. Default value tolN = -0.001. id (optional) String vector (minimum length 1), NULL, specifying name additional variables transferred input time series data frame (argument data_df) output time series data frame, object returned function (see section Value). default, output series data frame contains variables listed metadata data frame (argument metadata_df). Default value id = NULL. verbose (optional) Logical argument specifying whether information intermediate steps execution time (real time, CPU time) displayed. Note specifying argument quiet = TRUE nullify argument verbose. Default value verbose = FALSE. Vmat_option (optional) Specification option variance matrices (\\(V_e\\) \\(V_\\epsilon\\); see section Details): See Ferland (2016) subsection Arguments Vmat_option warnNegInput section Details information. Default value Vmat_option = 1. warnNegInput (optional) Logical argument specifying whether warning message generated negative value smaller threshold specified argument tolN found input time series data frame (argument data_df). Default value warnNegInput = TRUE. quiet (optional) Logical argument specifying whether display essential information warnings errors. Specifying quiet = TRUE also nullify argument verbose equivalent wrapping tsraking() call suppressMessages(). Default value quiet = FALSE. temporal_grp_periodicity (optional) Positive integer defining number periods temporal groups totals preserved. E.g., specify temporal_grp_periodicity = 3 monthly time series quarterly total preservation temporal_grp_periodicity = 12 (temporal_grp_periodicity = frequency(in_ts)) annual total preservation. Specifying temporal_grp_periodicity = 1 (default) corresponds period--period processing without temporal total preservation. Default value temporal_grp_periodicity = 1 (period--period processing without temporal total preservation). temporal_grp_start (optional) Integer [1 .. temporal_grp_periodicity] interval specifying starting period (cycle) temporal total preservation. E.g., annual totals corresponding fiscal years defined April March following year specified temporal_grp_start = 4 monthly time series (frequency(in_ts) = 12) temporal_grp_start = 2 quarterly time series (frequency(in_ts) = 4). argument effect period--period processing without temporal total preservation (temporal_grp_periodicity = 1). Default value temporal_grp_start = 1.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for tsraking() — tsraking_driver","text":"function returns time series object (\"ts\" \"mts\") containing reconciled component series, reconciled cross-sectional control totals series specified tsraking() argument id. can explicitly coerced another type object appropriate *() function (e.g., tsibble::as_tsibble() coerce tsibble). Note NULL object returned error occurs data processing start. Otherwise, execution gets far enough data processing start, incomplete object (NA values) returned case errors.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper function for tsraking() — tsraking_driver","text":"function solves one raking problem tsraking() per processing group (see section Processing groups details). mathematical expression raking problem can found Details section tsraking() documentation. alterability coefficients data frame (argument alterability_df) specified tsraking_driver() can either contain: single observation: specified coefficients used periods input time series object (argument in_ts). number observations equal frequency(in_ts): specified coefficients used corresponding cycle input time series object (argument in_ts) periods. Monthly data example: 1st observation January, 2nd observation February, etc.). number observations equal nrow(in_ts): specified coefficients used corresponding periods input time series object (argument in_ts), .e., 1st observation 1st period, 2nd observation 2nd period, etc.). Specifying quiet = TRUE suppress tsraking() messages (e.g., function header) display essential information warnings, errors period (set periods) reconciled. advise wrapping tsraking_driver() function call suppressMessages() suppress display raking period(s) information make troubleshooting difficult case issues individual raking problems. Although tsraking() called *apply() successively reconcile periods input time series (in_ts), using tsraking_driver() advantages, namely: temporal total preservation (period--period processing, without temporal total preservation, possible *apply()); flexibility specification user-defined alterability coefficients (e.g., period-specific values); display period processed (reconciled) console, useful troubleshooting individual raking problems; improved error handling, .e., better management warnings errors occur raking problems (periods); readily returns \"ts\" (\"mts\") object.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"processing-groups","dir":"Reference","previous_headings":"","what":"Processing groups","title":"Helper function for tsraking() — tsraking_driver","text":"set periods given reconciliation (raking balancing) problem called processing group either corresponds : single period period--period processing , preserving temporal totals, individual periods incomplete temporal group (e.g., incomplete year) set periods complete temporal group (e.g., complete year) preserving temporal totals. total number processing groups (total number reconciliation problems) depends set periods input time series object (argument in_ts) value arguments temporal_grp_periodicity temporal_grp_start. Common scenarios include temporal_grp_periodicity = 1 (default) period-period processing without temporal total preservation temporal_grp_periodicity = frequency(in_ts) preservation annual totals (calendar years default). Argument temporal_grp_start allows specification types (non-calendar) years. E.g., fiscal years starting April correspond temporal_grp_start = 4 monthly data temporal_grp_start = 2 quarterly data. Preserving quarterly totals monthly data correspond temporal_grp_periodicity = 3. default, temporal groups covering year (.e., corresponding temporal_grp_periodicity > frequency(in_ts) start year multiple  ceiling(temporal_grp_periodicity / frequency(in_ts)). E.g., biennial groups corresponding temporal_grp_periodicity = 2 * frequency(in_ts) start even year default. behaviour can changed argument temporal_grp_start. E.g., preservation biennial totals starting odd year instead even year (default) corresponds temporal_grp_start = frequency(in_ts) + 1 (along temporal_grp_periodicity = 2 * frequency(in_ts)). See gs.build_proc_grps() Examples common processing group scenarios.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Helper function for tsraking() — tsraking_driver","text":"Statistics Canada (2018). \"Chapter 6: Advanced topics\", Theory Application Reconciliation (Course code 0437), Statistics Canada, Ottawa, Canada.","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/tsraking_driver.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function for tsraking() — tsraking_driver","text":"","code":"# 1-dimensional raking problem where the quarterly sales of cars in the 3 prairie # provinces (Alb., Sask. and Man.) for 8 quarters, from 2019 Q2 to 2021 Q1, must # sum up to the total (`cars_tot`).  # Problem metadata my_metadata <- data.frame(series = c(\"cars_alb\", \"cars_sask\", \"cars_man\"),                           total1 = rep(\"cars_tot\", 3)) my_metadata #>      series   total1 #> 1  cars_alb cars_tot #> 2 cars_sask cars_tot #> 3  cars_man cars_tot  # Problem data my_series <- ts(matrix(c(14, 18, 14, 58,                          17, 14, 16, 44,                          14, 19, 18, 58,                          20, 18, 12, 53,                          16, 16, 19, 44,                          14, 15, 16, 50,                          19, 20, 14, 52,                          16, 15, 19, 51),                        ncol = 4,                        byrow = TRUE,                        dimnames = list(NULL, c(\"cars_alb\", \"cars_sask\",                                                \"cars_man\", \"cars_tot\"))),                 start = c(2019, 2),                 frequency = 4)   ########### # Example 1: Period-by-period processing without temporal total preservation.  # Reconcile the data out_raked1 <- tsraking_driver(my_series, my_metadata) #>  #>  #> Raking period [2019-2] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2019-3] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2019-4] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2020-1] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2020-2] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2020-3] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2020-4] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>  #>  #>  #> Raking period [2021-1] #> ====================== #>  #>  #> --- Package gstest 3.0.0 - (EN) 'G-Series' in 'R' | (FR) 'G-Séries' en 'R' --- #> Created on April 8, 2025, at 3:40:01 PM EDT #> URL: https://ferlmic.github.io/gstest/en/ #>      https://ferlmic.github.io/gstest/fr/ #> Email: g-series@statcan.gc.ca #>  #> tsraking() function: #>     data_df         = <argument 'data_df'> #>     metadata_df     = <argument 'metadata_df'> #>     alterability_df = NULL (default) #>     alterSeries     = 1 (default) #>     alterTotal1     = 0 (default) #>     alterTotal2     = 0 (default) #>     alterAnnual     = 0 (default) #>     tolV            = 0.001 (default) #>     warnNegResult   = TRUE (default) #>     tolN            = -0.001 (default) #>     id              = NULL (default) #>     verbose         = FALSE (default) #>     (*)Vmat_option  = 1 (default) #>     (*)warnNegInput = TRUE (default) #>     (*)quiet        = FALSE (default) #>     (*) indicates new arguments in G-Series 3.0 #>   # Initial data my_series #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2       14        18       14       58 #> 2019 Q3       17        14       16       44 #> 2019 Q4       14        19       18       58 #> 2020 Q1       20        18       12       53 #> 2020 Q2       16        16       19       44 #> 2020 Q3       14        15       16       50 #> 2020 Q4       19        20       14       52 #> 2021 Q1       16        15       19       51  # Reconciled data out_raked1 #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 17.65217  22.69565 17.65217       58 #> 2019 Q3 15.91489  13.10638 14.97872       44 #> 2019 Q4 15.92157  21.60784 20.47059       58 #> 2020 Q1 21.20000  19.08000 12.72000       53 #> 2020 Q2 13.80392  13.80392 16.39216       44 #> 2020 Q3 15.55556  16.66667 17.77778       50 #> 2020 Q4 18.64151  19.62264 13.73585       52 #> 2021 Q1 16.32000  15.30000 19.38000       51  # Check the output cross-sectional constraint all.equal(rowSums(out_raked1[, my_metadata$series]), as.vector(out_raked1[, \"cars_tot\"])) #> [1] TRUE  # Check the control total (fixed) all.equal(my_series[, \"cars_tot\"], out_raked1[, \"cars_tot\"]) #> [1] TRUE   ########### # Example 2: Annual total preservation for year 2020 (period-by-period processing #            for incomplete years 2019 and 2021), with `quiet = TRUE` to avoid #            displaying the function header for all processing groups.  # First, check that the 2020 annual total for the total series (`cars_tot`) and the # sum of the component series (`cars_alb`, `cars_sask` and `cars_man`) matches. # Otherwise, this \"grand total\" discrepancy would first have to be resolved before # calling `tsraking_driver()`. tot2020 <- aggregate.ts(window(my_series, start = c(2020, 1), end = c(2020, 4))) all.equal(as.numeric(tot2020[, \"cars_tot\"]), sum(tot2020[, my_metadata$series])) #> [1] TRUE  # Reconcile the data out_raked2 <- tsraking_driver(in_ts = my_series,                               metadata_df = my_metadata,                               quiet = TRUE,                               temporal_grp_periodicity = frequency(my_series)) #>  #>  #> Raking period [2019-2] #> ====================== #>  #>  #> Raking period [2019-3] #> ====================== #>  #>  #> Raking period [2019-4] #> ====================== #>  #>  #> Raking periods [2020-1 - 2020-4] #> ================================ #>  #>  #> Raking period [2021-1] #> ======================  # Initial data my_series #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2       14        18       14       58 #> 2019 Q3       17        14       16       44 #> 2019 Q4       14        19       18       58 #> 2020 Q1       20        18       12       53 #> 2020 Q2       16        16       19       44 #> 2020 Q3       14        15       16       50 #> 2020 Q4       19        20       14       52 #> 2021 Q1       16        15       19       51  # Reconciled data out_raked2 #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 17.65217  22.69565 17.65217       58 #> 2019 Q3 15.91489  13.10638 14.97872       44 #> 2019 Q4 15.92157  21.60784 20.47059       58 #> 2020 Q1 21.15283  19.04513 12.80204       53 #> 2020 Q2 13.74700  13.75373 16.49927       44 #> 2020 Q3 15.50782  16.62184 17.87034       50 #> 2020 Q4 18.59234  19.57931 13.82835       52 #> 2021 Q1 16.32000  15.30000 19.38000       51  # Check the output cross-sectional constraint all.equal(rowSums(out_raked2[, my_metadata$series]), as.vector(out_raked2[, \"cars_tot\"])) #> [1] TRUE  # Check the output temporal constraints (2020 annual totals for each series) all.equal(tot2020,           aggregate.ts(window(out_raked2, start = c(2020, 1), end = c(2020, 4)))) #> [1] TRUE  # Check the control total (fixed) all.equal(my_series[, \"cars_tot\"], out_raked2[, \"cars_tot\"]) #> [1] TRUE   ########### # Example 3: Annual total preservation for fiscal years defined from April to March #            (2019Q2-2020Q1 and 2020Q2-2021Q1).  # Calculate the fiscal year totals (as an annual \"ts\" object) fiscalYr_tot <- ts(rbind(aggregate.ts(window(my_series,                                              start = c(2019, 2),                                              end = c(2020, 1))),                          aggregate.ts(window(my_series,                                              start = c(2020, 2),                                              end = c(2021, 1)))),                    start = 2019,                    frequency = 1)  # Discrepancies in both fiscal year totals (total series vs. sum of the component series) as.numeric(fiscalYr_tot[, \"cars_tot\"]) - rowSums(fiscalYr_tot[, my_metadata$series]) #> [1] 19 -2   # 3a) Reconcile the fiscal year totals (rake the fiscal year totals of the component series #     to those of the total series). new_fiscalYr_tot <- tsraking_driver(in_ts = fiscalYr_tot,                                     metadata_df = my_metadata,                                     quiet = TRUE) #>  #>  #> Raking period [2019] #> ==================== #>  #>  #> Raking period [2020] #> ====================  # Confirm that the previous discrepancies are now \"gone\" (are both zero) as.numeric(new_fiscalYr_tot[, \"cars_tot\"]) - rowSums(new_fiscalYr_tot[, my_metadata$series]) #> [1] 0 0  # 3b) Benchmark the quarterly component series to these new (coherent) fiscal year totals. out_bench <- benchmarking(series_df = ts_to_tsDF(my_series[, my_metadata$series]),                           benchmarks_df = ts_to_bmkDF(                             new_fiscalYr_tot[, my_metadata$series],                             ind_frequency = frequency(my_series),                                                          # Fiscal years starting on Q2 (April)                             bmk_interval_start = 2),                                                      rho = 0.729,                           lambda = 1,                           biasOption = 2,                           allCols = TRUE,                           quiet = TRUE) #>  #> Benchmarking indicator series [cars_alb] with benchmarks [cars_alb] #> ------------------------------------------------------------------- #>  #> Benchmarking indicator series [cars_sask] with benchmarks [cars_sask] #> --------------------------------------------------------------------- #>  #> Benchmarking indicator series [cars_man] with benchmarks [cars_man] #> ------------------------------------------------------------------- my_new_ser <- tsDF_to_ts(cbind(out_bench$series, cars_tot = my_series[, \"cars_tot\"]),                          frequency = frequency(my_series))  # 3c) Reconcile the quarterly data with preservation of fiscal year totals. out_raked3 <- tsraking_driver(in_ts = my_new_ser,                               metadata_df = my_metadata,                               temporal_grp_periodicity = frequency(my_series),                                                              # Fiscal years starting on Q2 (April)                               temporal_grp_start = 2,                                                              quiet = TRUE) #>  #>  #> Raking periods [2019-2 - 2020-1] #> ================================ #>  #>  #> Raking periods [2020-2 - 2021-1] #> ================================  # Initial data my_series #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2       14        18       14       58 #> 2019 Q3       17        14       16       44 #> 2019 Q4       14        19       18       58 #> 2020 Q1       20        18       12       53 #> 2020 Q2       16        16       19       44 #> 2020 Q3       14        15       16       50 #> 2020 Q4       19        20       14       52 #> 2021 Q1       16        15       19       51  # With coherent fiscal year totals my_new_ser #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 15.40737  19.84939 15.41097       58 #> 2019 Q3 18.90614  15.54094 17.78267       44 #> 2019 Q4 15.45221  20.98489 19.84697       58 #> 2020 Q1 21.60026  19.38252 12.83568       53 #> 2020 Q2 16.44068  16.41619 19.39307       44 #> 2020 Q3 13.91243  14.89512 15.85700       50 #> 2020 Q4 18.49133  19.47043 13.65082       52 #> 2021 Q1 15.50230  14.55494 18.41569       51  # Reconciled data out_raked3 #>         cars_alb cars_sask cars_man cars_tot #> 2019 Q2 17.77916  22.53212 17.68872       58 #> 2019 Q3 16.07232  12.91959 15.00808       44 #> 2019 Q4 16.06497  21.42285 20.51217       58 #> 2020 Q1 21.44952  18.88317 12.66732       53 #> 2020 Q2 13.84015  13.79962 16.36024       44 #> 2020 Q3 15.57114  16.65292 17.77593       50 #> 2020 Q4 18.62985  19.59265 13.77750       52 #> 2021 Q1 16.30560  15.29149 19.40291       51  # Check the output cross-sectional constraint all.equal(rowSums(out_raked3[, my_metadata$series]), as.vector(out_raked3[, \"cars_tot\"])) #> [1] TRUE  # Check the output temporal constraints (both fiscal year totals for all series) all.equal(rbind(aggregate.ts(window(my_new_ser, start = c(2019, 2), end = c(2020, 1))),                 aggregate.ts(window(my_new_ser, start = c(2020, 2), end = c(2021, 1)))),           rbind(aggregate.ts(window(out_raked3, start = c(2019, 2), end = c(2020, 1))),                 aggregate.ts(window(out_raked3, start = c(2020, 2), end = c(2021, 1))))) #> [1] TRUE  # Check the control total (fixed) all.equal(my_series[, \"cars_tot\"], out_raked3[, \"cars_tot\"]) #> [1] TRUE"},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_bmkDF.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a ","title":"Convert a ","text":"Convert \"ts\" (\"mts\") object benchmarks data frame benchmarking functions five variables (columns): four (4) benchmark coverage one (1) benchmark time series discrete benchmarks (anchor points covering single period indicator series, e.g., end year stocks), specify discrete_flag = TRUE alignment = \"b\", \"e\" \"m\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_bmkDF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a ","text":"","code":"ts_to_bmkDF(   in_ts,   ind_frequency,   discrete_flag = FALSE,   alignment = \"b\",   bmk_interval_start = 1,   startYr_cName = \"startYear\",   startPer_cName = \"startPeriod\",   endYr_cName = \"endYear\",   endPer_cName = \"endPeriod\",   val_cName = \"value\" )"},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_bmkDF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a ","text":"in_ts (mandatory) Time series (\"ts\" \"mts\"), object coerced one, converted. ind_frequency (mandatory) Integer specifying frequency indicator (high frequency) series benchmarks (low frequency series) related . frequency time series corresponds maximum number periods year (e.g., 12 monthly data, 4 quarterly data, 1 annual data). discrete_flag (optional) Logical argument specifying whether benchmarks correspond discrete values (anchor points covering single period indicator series, e.g., end year stocks) . discrete_flag = FALSE defines non-discrete benchmarks, .e., benchmarks cover several periods indicator series (e.g. annual benchmarks cover 4 quarters 12 months, quarterly benchmarks cover 3 months, etc.). Default value discrete_flag = FALSE. alignment (optional) Character identifying alignment discrete benchmarks (argument discrete_flag = TRUE) benchmark (low frequency series) interval coverage window: alignment = \"b\": beginning benchmark interval window (first period) alignment = \"e\": end benchmark interval window (last period) alignment = \"m\": middle benchmark interval window (middle period) argument effect non-discrete benchmarks (discrete_flag = FALSE). Default value alignment = \"b\". bmk_interval_start (optional) Integer [1 .. ind_frequency] interval specifying period (cycle) indicator (high frequency) series benchmark (low frequency series) interval window starts. E.g., annual benchmarks corresponding fiscal years defined April March following year specified bmk_interval_start = 4 monthly indicator series (ind_frequency = 12) bmk_interval_start = 2 quarterly indicator series (ind_frequency = 4). Default value bmk_interval_start = 1. startYr_cName, startPer_cName, endYr_cName, endPer_cName (optional) Strings specifying name numeric variables (columns) output data frame define benchmarks coverage, .e., starting ending year period (cycle) identifiers. Default values startYr_cName = \"startYear\", startPer_cName = \"startPeriod\" endYr_cName = \"endYear\" endPer_cName   = \"endPeriod\". val_cName (optional) String specifying name numeric variable (column) output data frame contain benchmark values. argument effect \"mts\" objects (benchmark variable names automatically inherited \"mts\" object). Default value val_cName = \"value\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_bmkDF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a ","text":"function returns data frame five variables: Benchmark coverage starting year, type numeric (see argument startYr_cName) Benchmark coverage starting period (cycle), type numeric (see argument startPer_cName) Benchmark coverage ending year, type numeric (see argument endtYr_cName) Benchmark coverage ending period (cycle), type numeric (see argument endPer_cName) One (\"ts\" object) many (\"mts\" object) benchmark data variable(s), type numeric (see argument val_cName) Note: function returns \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_bmkDF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a ","text":"","code":"# Annual and quarterly time series my_ann_ts <- ts(1:5 * 100, start = 2019, frequency = 1) my_ann_ts #> Time Series: #> Start = 2019  #> End = 2023  #> Frequency = 1  #> [1] 100 200 300 400 500 my_qtr_ts <- ts(my_ann_ts, frequency = 4) my_qtr_ts #>   Qtr1 Qtr2 Qtr3 Qtr4 #> 1  100  200  300  400 #> 2  500                  # Annual benchmarks for a monthly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 12) #>   startYear startPeriod endYear endPeriod value #> 1      2019           1    2019        12   100 #> 2      2020           1    2020        12   200 #> 3      2021           1    2021        12   300 #> 4      2022           1    2022        12   400 #> 5      2023           1    2023        12   500  # Annual benchmarks for a quarterly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 4) #>   startYear startPeriod endYear endPeriod value #> 1      2019           1    2019         4   100 #> 2      2020           1    2020         4   200 #> 3      2021           1    2021         4   300 #> 4      2022           1    2022         4   400 #> 5      2023           1    2023         4   500  # Quarterly benchmarks for a monthly indicator series ts_to_bmkDF(my_qtr_ts, ind_frequency = 12) #>   startYear startPeriod endYear endPeriod value #> 1         1           1       1         3   100 #> 2         1           4       1         6   200 #> 3         1           7       1         9   300 #> 4         1          10       1        12   400 #> 5         2           1       2         3   500  # Start of year stocks for a quarterly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 4,              discrete_flag = TRUE) #>   startYear startPeriod endYear endPeriod value #> 1      2019           1    2019         1   100 #> 2      2020           1    2020         1   200 #> 3      2021           1    2021         1   300 #> 4      2022           1    2022         1   400 #> 5      2023           1    2023         1   500  # End of quarter stocks for a monthly indicator series ts_to_bmkDF(my_qtr_ts, ind_frequency = 12,              discrete_flag = TRUE, alignment = \"e\") #>   startYear startPeriod endYear endPeriod value #> 1         1           3       1         3   100 #> 2         1           6       1         6   200 #> 3         1           9       1         9   300 #> 4         1          12       1        12   400 #> 5         2           3       2         3   500  # April to March annual benchmarks for a ... # ... monthly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 12,              bmk_interval_start = 4) #>   startYear startPeriod endYear endPeriod value #> 1      2019           4    2020         3   100 #> 2      2020           4    2021         3   200 #> 3      2021           4    2022         3   300 #> 4      2022           4    2023         3   400 #> 5      2023           4    2024         3   500 # ... quarterly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 4,              bmk_interval_start = 2) #>   startYear startPeriod endYear endPeriod value #> 1      2019           2    2020         1   100 #> 2      2020           2    2021         1   200 #> 3      2021           2    2022         1   300 #> 4      2022           2    2023         1   400 #> 5      2023           2    2024         1   500  # End-of-year (April to March) stocks for a ... # ... monthly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 12,              discrete_flag = TRUE, alignment = \"e\", bmk_interval_start = 4) #>   startYear startPeriod endYear endPeriod value #> 1      2020           3    2020         3   100 #> 2      2021           3    2021         3   200 #> 3      2022           3    2022         3   300 #> 4      2023           3    2023         3   400 #> 5      2024           3    2024         3   500 # ... quarterly indicator series ts_to_bmkDF(my_ann_ts, ind_frequency = 4,             discrete_flag = TRUE, alignment = \"e\", bmk_interval_start = 2) #>   startYear startPeriod endYear endPeriod value #> 1      2020           1    2020         1   100 #> 2      2021           1    2021         1   200 #> 3      2022           1    2022         1   300 #> 4      2023           1    2023         1   400 #> 5      2024           1    2024         1   500  # Custom name for the benchmark data variable (column) ts_to_bmkDF(my_ann_ts, ind_frequency = 12,             val_cName = \"bmk_val\") #>   startYear startPeriod endYear endPeriod bmk_val #> 1      2019           1    2019        12     100 #> 2      2020           1    2020        12     200 #> 3      2021           1    2021        12     300 #> 4      2022           1    2022        12     400 #> 5      2023           1    2023        12     500  # Multiple time series: argument `val_cName` ignored # (the \"mts\" object column names are always used) ts_to_bmkDF(ts.union(ser1 = my_ann_ts, ser2 = my_ann_ts / 10), ind_frequency = 12,             val_cName = \"useless_column_name\") #>   startYear startPeriod endYear endPeriod ser1 ser2 #> 1      2019           1    2019        12  100   10 #> 2      2020           1    2020        12  200   20 #> 3      2021           1    2021        12  300   30 #> 4      2022           1    2022        12  400   40 #> 5      2023           1    2023        12  500   50"},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_tsDF.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a ","title":"Convert a ","text":"Convert \"ts\" (\"mts\") object time series data frame benchmarking functions three variables (columns): two (2) data point identification (year period) one (1) time series","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_tsDF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a ","text":"","code":"ts_to_tsDF(   in_ts,   yr_cName = \"year\",   per_cName = \"period\",   val_cName = \"value\" )"},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_tsDF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a ","text":"in_ts (mandatory) Time series (\"ts\" \"mts\"), object coerced one, converted. yr_cName, per_cName (optional) Strings specifying name numeric variables (columns) output data frame contain data point year period identifiers. Default values yr_cName = \"year\" per_cName   = \"period\". val_cName (optional) String specifying name numeric variable (column) output data frame contain data point value. argument effect \"mts\" objects (time series data variable names automatically inherited \"mts\" object). Default value val_cName = \"value\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_tsDF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a ","text":"function returns data frame three variables: Data point year, type numeric (see argument startYr_cName) Data point period, type numeric (see argument startPer_cName) One (\"ts\" object) many (\"mts\" object) time series data variable(s), type numeric (see argument val_cName) Note: function returns \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/ts_to_tsDF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a ","text":"","code":"# Quarterly time series my_ts <- ts(1:10 * 100, start = 2019, frequency = 4) my_ts #>      Qtr1 Qtr2 Qtr3 Qtr4 #> 2019  100  200  300  400 #> 2020  500  600  700  800 #> 2021  900 1000             # With the default variable (column) names ts_to_tsDF(my_ts) #>    year period value #> 1  2019      1   100 #> 2  2019      2   200 #> 3  2019      3   300 #> 4  2019      4   400 #> 5  2020      1   500 #> 6  2020      2   600 #> 7  2020      3   700 #> 8  2020      4   800 #> 9  2021      1   900 #> 10 2021      2  1000  # Using a custom name for the time series data variable (column) ts_to_tsDF(my_ts, val_cName = \"ser_val\") #>    year period ser_val #> 1  2019      1     100 #> 2  2019      2     200 #> 3  2019      3     300 #> 4  2019      4     400 #> 5  2020      1     500 #> 6  2020      2     600 #> 7  2020      3     700 #> 8  2020      4     800 #> 9  2021      1     900 #> 10 2021      2    1000   # Multiple time series: argument `val_cName` ignored # (the \"mts\" object column names are always used) ts_to_tsDF(ts.union(ser1 = my_ts,                     ser2 = my_ts / 10),             val_cName = \"useless_column_name\") #>    year period ser1 ser2 #> 1  2019      1  100   10 #> 2  2019      2  200   20 #> 3  2019      3  300   30 #> 4  2019      4  400   40 #> 5  2020      1  500   50 #> 6  2020      2  600   60 #> 7  2020      3  700   70 #> 8  2020      4  800   80 #> 9  2021      1  900   90 #> 10 2021      2 1000  100"},{"path":"https://ferlmic.github.io/gstest/en/reference/unstack_tsDF.html","id":null,"dir":"Reference","previous_headings":"","what":"Reciprocal function of stack_tsDF() — unstack_tsDF","title":"Reciprocal function of stack_tsDF() — unstack_tsDF","text":"Convert stacked (tall) multivariate time series data frame (benchmarking() stock_benchmarking() data format) non-stacked (wide) multivariate time series data frame. function, combined tsDF_to_ts(), useful convert benchmarked data frame returned call benchmarking() stock_benchmarking() back \"mts\" object, multiple series benchmarked -group processing mode.","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/unstack_tsDF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reciprocal function of stack_tsDF() — unstack_tsDF","text":"","code":"unstack_tsDF(   ts_df,   ser_cName = \"series\",   yr_cName = \"year\",   per_cName = \"period\",   val_cName = \"value\" )"},{"path":"https://ferlmic.github.io/gstest/en/reference/unstack_tsDF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reciprocal function of stack_tsDF() — unstack_tsDF","text":"ts_df (mandatory) Data frame, object coerced one, contains multivariate time series data unstacked. ser_cName (optional) String specifying name character variable (column) input time series data frame contains series identifier (time series variable names output data frame). Default value ser_cName = \"series\". yr_cName, per_cName (optional) Strings specifying name numeric variables (columns) input time series data frame contain data point year period identifiers. variables transferred output data frame names. Default values yr_cName = \"year\" per_cName   = \"period\". val_cName (optional) String specifying name numeric variable (column) input time series data frame contains data point values. Default value val_cName = \"value\".","code":""},{"path":"https://ferlmic.github.io/gstest/en/reference/unstack_tsDF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reciprocal function of stack_tsDF() — unstack_tsDF","text":"function returns data frame three variables: Data point year, type numeric (see argument yr_cName) Data point period, type numeric (see argument per_cName) One time series data variable distinct value input data frame variable specified argument ser_cName, type numeric (see arguments ser_cName val_cName) Note: function returns \"data.frame\" object can explicitly coerced another type object appropriate *() function (e.g., tibble::as_tibble() coerce tibble).","code":""},{"path":[]},{"path":"https://ferlmic.github.io/gstest/en/reference/unstack_tsDF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reciprocal function of stack_tsDF() — unstack_tsDF","text":"","code":"# Proportional benchmarking for multiple (3) quarterly series processed with  # argument `by` (in BY-group mode)  ind_vec <- c(1.9, 2.4, 3.1, 2.2, 2.0, 2.6, 3.4, 2.4, 2.3) ind_df <- ts_to_tsDF(ts(data.frame(ser1 = ind_vec,                                    ser2 = ind_vec * 100,                                    ser3 = ind_vec * 10),                         start = c(2015, 1), frequency = 4))  bmk_vec <- c(10.3, 10.2) bmk_df <- ts_to_bmkDF(ts(data.frame(ser1 = bmk_vec,                                     ser2 = bmk_vec * 100,                                     ser3 = bmk_vec * 10),                           start = 2015, frequency = 1),                       ind_frequency = 4)  out_bench <- benchmarking(stack_tsDF(ind_df),                           stack_bmkDF(bmk_df),                           rho = 0.729, lambda = 1, biasOption = 3,                           by = \"series\",                           quiet = TRUE) #>  #> Benchmarking by-group 1 (series=ser1) #> ===================================== #>  #> Benchmarking by-group 2 (series=ser2) #> ===================================== #>  #> Benchmarking by-group 3 (series=ser3) #> =====================================  # Initial and final (benchmarked) quarterly time series data frames ind_df #>   year period ser1 ser2 ser3 #> 1 2015      1  1.9  190   19 #> 2 2015      2  2.4  240   24 #> 3 2015      3  3.1  310   31 #> 4 2015      4  2.2  220   22 #> 5 2016      1  2.0  200   20 #> 6 2016      2  2.6  260   26 #> 7 2016      3  3.4  340   34 #> 8 2016      4  2.4  240   24 #> 9 2017      1  2.3  230   23 unstack_tsDF(out_bench$series) #>   year period     ser1     ser2     ser3 #> 1 2015      1 2.049326 204.9326 20.49326 #> 2 2015      2 2.601344 260.1344 26.01344 #> 3 2015      3 3.337638 333.7638 33.37638 #> 4 2015      4 2.311691 231.1691 23.11691 #> 5 2016      1 2.021090 202.1090 20.21090 #> 6 2016      2 2.554801 255.4801 25.54801 #> 7 2016      3 3.292193 329.2193 32.92193 #> 8 2016      4 2.331915 233.1915 23.31915 #> 9 2017      1 2.268017 226.8017 22.68017"},{"path":"https://ferlmic.github.io/gstest/en/SECURITY.html","id":null,"dir":"","previous_headings":"","what":"Security","title":"Security","text":"post security issues public repository! Security vulnerabilities must reported email g-series@statcan.gc.ca","code":""},{"path":"https://ferlmic.github.io/gstest/en/SECURITY.html","id":"sécurité","dir":"","previous_headings":"","what":"Sécurité","title":"Security","text":"Ne publiez aucun problème de sécurité sur le dépôt publique! Les vulnérabilités de sécurité doivent être signalées par courriel à g-series@statcan.gc.ca","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"gstest-300","dir":"Changelog","previous_headings":"","what":"gstest 3.0.0","title":"gstest 3.0.0","text":"(G-Series 3.0 R) Initial release G-Series R (package gstest). New functionality (stock_benchmarking()) designed benchmarking stocks using cubic spline interpolation approach. Improvements already existing functionalities: new options allowing proportional benchmarking (lambda != 0) presence negative values input data; flat indicator series zeros now allowed additive benchmarking (lambda = 0). optional alternative handling negative values input data (handling tsbalancing()); helper function (tsraking_driver()) simplify reconciliation several periods single function call. customizable solving sequence (multiple attempts solving problem opposed single attempt); improved solution validation process information (output data frames) available help troubleshooting invalid solutions; optional input data validation process (without attempting solve problem, .e., resolve discrepancies, ). New utility functions help using core functions, e.g.; producing benchmarking plots; converting reconciliation problem metadata (tsrasking() tsbalancing()); manipulating time series data (prepare convert input output data objects).","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"version-200","dir":"Changelog","previous_headings":"","what":"Version 2.0.0","title":"Version 2.0.0","text":"(G-Series 2.0 SAS®, contact g-series@statcan.gc.ca) New GSeriesTSBalancing macro.","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"version-140","dir":"Changelog","previous_headings":"","what":"Version 1.4.0","title":"Version 1.4.0","text":"(G-Series 1.04 SAS®, contact g-series@statcan.gc.ca) Name change: Forillon becomes G-Series. Introduction alterability coefficients PROC BENCHMARKING (rho <  1). New statement PROC BENCHMARKING. New options WARNNEGRESULT|NOWARNNEGRESULT TOLNEGRESULT= PROC BENCHMARKING PROC TSRAKING.","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"version-130","dir":"Changelog","previous_headings":"","what":"Version 1.3.0","title":"Version 1.3.0","text":"(Forillon 1.03 SAS®, contact g-series@statcan.gc.ca) New VAR statements PROC BENCHMARKING.","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"version-120","dir":"Changelog","previous_headings":"","what":"Version 1.2.0","title":"Version 1.2.0","text":"(Forillon 1.02 SAS®, contact g-series@statcan.gc.ca) Addition PROC TSRAKING.","code":""},{"path":"https://ferlmic.github.io/gstest/en/news/index.html","id":"version-110","dir":"Changelog","previous_headings":"","what":"Version 1.1.0","title":"Version 1.1.0","text":"(Forillon 1.01 SAS®, contact g-series@statcan.gc.ca) Initial release PROC BENCHMARKING.","code":""}]
